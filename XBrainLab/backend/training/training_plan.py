from __future__ import annotations

import datetime
import time
import traceback
from enum import Enum

import numpy as np
import torch
import torch.utils.data as torch_data

from XBrainLab.backend.utils.logger import logger

# ... (Previous imports remain, but remove captum/sklearn if unused locally)
# Actually, maintain clean imports:
from ..dataset import Dataset
from ..utils import set_seed, validate_type
from ..visualization import supported_saliency_methods
from .evaluator import Evaluator
from .model_holder import ModelHolder
from .option import TrainingEvaluation, TrainingOption
from .record import RecordKey, TrainRecord, TrainRecordKey


class SharedMemoryDataset(torch_data.Dataset):
    """Dataset that references original data to save RAM/VRAM."""

    def __init__(
        self, data: np.ndarray, labels: np.ndarray, indices: np.ndarray, device: str
    ):
        self.data = data
        self.labels = labels
        self.indices = indices
        self.device = device

    def __len__(self):
        return len(self.indices)

    def __getitem__(self, idx):
        real_idx = self.indices[idx]
        # Data is transferred to device only when accessed (saves VRAM)
        x = torch.from_numpy(self.data[real_idx]).float().to(self.device)
        y = torch.tensor(self.labels[real_idx]).long().to(self.device)
        return x, y


def to_holder(
    data: np.ndarray,
    labels: np.ndarray,
    indices: np.ndarray,
    dev: str,
    bs: int,
    shuffle: bool = False,
) -> torch_data.DataLoader | None:
    """Convert data to torch dataloader using SharedMemoryDataset"""

    if len(indices) == 0:
        return None

    # Use SharedMemoryDataset to avoid copying numpy arrays (saves RAM)
    # and to load to GPU on-the-fly (saves VRAM).
    dataset = SharedMemoryDataset(data, labels, indices, dev)

    dataloader = torch_data.DataLoader(dataset, batch_size=bs, shuffle=shuffle)
    return dataloader


class Status(Enum):
    """Utility class for training status"""

    DONE = "Finished"
    PENDING = "Pending"
    INIT = "Initializing {}"
    EVAL = "Evaluating {}"
    TRAIN = "Training {}"


class TrainingPlanHolder:
    """class for storing training plan

    Contains repetition of training plan,
        each training plan is a :class:`TrainRecord` object

    Attributes:
        model_holder: :class:`ModelHolder` object
            Model holder
        dataset: :class:`Dataset` object
            Dataset for the training plan
        option: :class:`TrainingOption` object
            Training option
        train_record_list: List[:class:`TrainRecord`]
            List of training record generated by the training plan,
                used for storing training result
        interrupt: bool
            Whether the training is interrupted
        error: str | None
            Error message
        status: str
            Training status
    """

    def __init__(
        self,
        model_holder: ModelHolder,
        dataset: Dataset,
        option: TrainingOption,
        saliency_params: dict | None,
    ):
        self.model_holder = model_holder
        self.dataset = dataset
        self.option = option

        if not saliency_params:
            logger.warning("No saliency parameter is set, using default parameters.")
            params = {"nt_samples": 5, "nt_samples_batch_size": None, "stdevs": 1.0}
            saliency_params = dict.fromkeys(supported_saliency_methods, params)
        self.saliency_params: dict = saliency_params

        self.check_data()

        # Generate unique plan ID (timestamp) to avoid directory collision
        self.plan_id = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")

        self.train_record_list = []
        self.interrupt = False
        self.error: str | None = None
        self.status = Status.PENDING.value
        for i in range(self.option.repeat_num):
            seed = set_seed(seed=None)
            try:
                model = self.model_holder.get_model(
                    self.dataset.get_epoch_data().get_model_args()
                )
            except (RuntimeError, ValueError) as e:
                # Catch both RuntimeError (from PyTorch) and ValueError (from our
                # validation)
                if "Output size is too small" in str(
                    e
                ) or "Epoch duration is too short" in str(e):
                    model_name = self.model_holder.target_model.__name__
                    raise ValueError(
                        f"Failed to create model '{model_name}': {e!s}"
                    ) from e
                raise
            self.train_record_list.append(
                TrainRecord(
                    repeat=i,
                    dataset=self.dataset,
                    model=model,
                    option=self.option,
                    seed=seed,
                    plan_id=self.plan_id,
                )
            )

    def check_data(self) -> None:
        """Check whether the training plan is valid"""
        if self.dataset is None:
            raise ValueError("dataset cannot be None")
        if not self.dataset.get_epoch_data():
            raise ValueError("No valid training setting is generated")
        if not self.option:
            raise ValueError("No valid training setting is generated")
        if not self.model_holder:
            raise ValueError("No valid model is selected")

        validate_type(self.model_holder, ModelHolder, "model_holder")
        validate_type(self.dataset, Dataset, "dataset")
        validate_type(self.option, TrainingOption, "option")
        self.option.validate()

    # interact
    def train(self) -> None:
        """Train the model"""
        try:
            for i in range(self.option.repeat_num):
                self.status = Status.INIT.value.format(
                    self.train_record_list[i].get_name()
                )
                train_record = self.train_record_list[i]
                train_record.resume()
                self.train_one_repeat(train_record)
                train_record.pause()
            if self.is_finished():
                self.status = Status.DONE.value
            else:
                self.status = Status.PENDING.value
        except Exception as e:
            traceback.print_exc()
            self.error = str(e)
            self.status = Status.PENDING.value

    def get_loader(
        self,
    ) -> tuple[
        torch_data.DataLoader | None,
        torch_data.DataLoader | None,
        torch_data.DataLoader | None,
    ]:
        """Return the data loader for training, validation and testing"""
        bs = self.option.bs
        dev = self.option.get_device()

        # Access full data once (Reference)
        full_data = self.dataset.get_epoch_data().get_data()
        full_labels = self.dataset.get_epoch_data().get_label_list()

        # Get indices from masks
        train_idx = np.where(self.dataset.train_mask)[0]
        val_idx = np.where(self.dataset.val_mask)[0]
        test_idx = np.where(self.dataset.test_mask)[0]

        train_holder: torch_data.DataLoader | None = to_holder(
            full_data, full_labels, train_idx, dev, bs, True
        )
        val_holder: torch_data.DataLoader | None = to_holder(
            full_data, full_labels, val_idx, dev, bs
        )
        test_holder: torch_data.DataLoader | None = to_holder(
            full_data, full_labels, test_idx, dev, bs
        )
        return train_holder, val_holder, test_holder

    def get_eval_pair(
        self,
        train_record: TrainRecord,
        val_loader: torch_data.DataLoader | None,
        test_loader: torch_data.DataLoader | None,
    ) -> tuple[torch.nn.Module | None, torch_data.DataLoader | None]:
        """Return the model and data loader for evaluation based on given option"""
        target_model = target_loader = None
        target_model = self.model_holder.get_model(
            self.dataset.get_epoch_data().get_model_args()
        ).to(self.option.get_device())
        target_loader = test_loader or val_loader
        if self.option.evaluation_option == TrainingEvaluation.VAL_LOSS:
            model = getattr(train_record, f"best_val_{RecordKey.LOSS}_model")
            if model:
                target_model.load_state_dict(model)
            else:
                target_model = None
        elif self.option.evaluation_option == TrainingEvaluation.TEST_ACC:
            model = getattr(train_record, f"best_test_{RecordKey.ACC}_model")
            if model:
                target_model.load_state_dict(model)
            else:
                target_model = None
        elif self.option.evaluation_option == TrainingEvaluation.TEST_AUC:
            model = getattr(train_record, f"best_test_{RecordKey.AUC}_model")
            if model:
                target_model.load_state_dict(model)
            else:
                target_model = None
        elif self.option.evaluation_option == TrainingEvaluation.LAST_EPOCH:
            target_model.load_state_dict(train_record.model.state_dict())
        else:
            raise NotImplementedError
        if target_model:
            target_model = target_model.eval()
        return target_model, target_loader

    def train_one_repeat(self, train_record: TrainRecord) -> None:
        """Train one repetition of the training plan

        Args:
            train_record: Training record for storing training result
        """
        if train_record.is_finished():
            return
        # init
        model = train_record.get_training_model(device=self.option.get_device())
        train_loader, val_loader, test_loader = self.get_loader()
        if self.option.epoch > 0 and not train_loader:
            raise ValueError("No Training Data")
        optimizer = train_record.optim
        criterion = train_record.criterion
        self.status = Status.TRAIN.value.format(train_record.get_name())
        # train one epoch
        while train_record.epoch < self.option.epoch:
            if self.interrupt:
                break
            if train_loader is None:
                raise ValueError("train_loader cannot be None during training loop")
            self.train_one_epoch(
                model,
                train_loader,
                val_loader,
                test_loader,
                optimizer,
                criterion,
                train_record,
            )

        if train_record.epoch == self.option.epoch:
            self.status = Status.EVAL.value.format(train_record.get_name())
            target, target_loader = self.get_eval_pair(
                train_record, val_loader, test_loader
            )

            # Fallback: If no validation/test data, use training data for
            # evaluation/visualization
            if not target_loader and train_loader:
                target_loader = train_loader
                if not target:
                    target = train_record.model
                    target.eval()

            if target and target_loader:
                eval_record = Evaluator.evaluate_with_saliency(
                    target, target_loader, self.saliency_params
                )
                train_record.set_eval_record(eval_record)

        train_record.export_checkpoint()

    def train_one_epoch(
        self,
        model: torch.nn.Module,
        train_loader: torch_data.DataLoader,
        val_loader: torch_data.DataLoader | None,
        test_loader: torch_data.DataLoader | None,
        optimizer: torch.optim.Optimizer,
        criterion: torch.nn.Module,
        train_record: TrainRecord,
    ) -> None:
        """Train one epoch of the training plan.

        Args:
            model (torch.nn.Module): The model to train.
            train_loader (torch_data.DataLoader): Data loader for training set.
            val_loader (torch_data.DataLoader | None): Data loader for validation set.
            test_loader (torch_data.DataLoader | None): Data loader for test set.
            optimizer (torch.optim.Optimizer): Optimizer for backpropagation.
            criterion (torch.nn.Module): Loss function.
            train_record (TrainRecord): Record to store training statistics.
        """
        start_time = time.time()
        model.train()

        # 1. Train Batch Loop
        running_loss, correct, total_count, y_true, y_pred = self._train_batch_loop(
            model, train_loader, optimizer, criterion
        )
        if self.interrupt:
            return

        # 2. Compute Metrics (AUC) using Evaluator
        train_auc = Evaluator.compute_auc(y_true, y_pred)

        # 3. Update Records
        running_loss /= len(train_loader)
        train_acc = correct / total_count * 100

        self._update_train_records(
            train_record,
            running_loss,
            train_acc,
            train_auc,
            optimizer.param_groups[0]["lr"],
            time.time() - start_time,
        )

        # 4. Validation & Test
        if val_loader:
            test_result = Evaluator.test_model(model, val_loader, criterion)
            train_record.update_eval(test_result)

        if test_loader:
            test_result = Evaluator.test_model(model, test_loader, criterion)
            train_record.update_test(test_result)

        train_record.step()

        if (
            self.option.checkpoint_epoch
            and train_record.get_epoch() % self.option.checkpoint_epoch == 0
        ):
            train_record.export_checkpoint()

        # CLEAR VRAM to prevent linear memory growth
        torch.cuda.empty_cache()

    def _train_batch_loop(self, model, train_loader, optimizer, criterion):
        """Execute the inner training loop for one epoch.

        Args:
            model: The model to train.
            train_loader: DataLoader for training data.
            optimizer: Optimizer instance.
            criterion: Loss function.

        Returns:
            tuple: (running_loss, correct_count, total_count, y_true, y_pred)
        """
        running_loss = 0.0
        correct = 0.0
        total_count = 0
        y_true, y_pred = None, None

        for inputs, labels in train_loader:
            if self.interrupt:
                break
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            correct += (outputs.argmax(axis=1) == labels).float().sum().item()
            if y_true is None or y_pred is None:
                y_true = labels.detach().cpu()
                y_pred = outputs.detach().cpu()
            else:
                y_true = torch.cat((y_true, labels.detach().cpu()))
                y_pred = torch.cat((y_pred, outputs.detach().cpu()))
            total_count += len(labels)
            running_loss += loss.item()

        return running_loss, correct, total_count, y_true, y_pred

    def _update_train_records(self, train_record, loss, acc, auc, lr, duration):
        """Update training statistics."""
        train_record.update_train(
            {
                RecordKey.LOSS: loss,
                RecordKey.ACC: acc,
                RecordKey.AUC: auc,
            }
        )
        train_record.update_statistic(
            {
                TrainRecordKey.LR: lr,
                TrainRecordKey.TIME: duration,
            }
        )

    def set_interrupt(self) -> None:
        """Set the interrupt flag"""
        self.interrupt = True

    def clear_interrupt(self) -> None:
        """Clear the interrupt flag and error status"""
        self.error = None
        self.interrupt = False

    # getter
    def get_name(self) -> str:
        """Return the name of the training plan"""
        return self.dataset.get_name()

    def get_dataset(self) -> Dataset:
        """Get the dataset of the training plan"""
        return self.dataset

    def get_plans(self) -> list[TrainRecord]:
        """Get the training records of the training plan"""
        return self.train_record_list

    def get_saliency_params(self) -> dict:
        """Return the saliency computation parameters"""
        return self.saliency_params

    # setter
    def set_saliency_params(self, saliency_params: dict) -> None:
        """Set the saliency computation parameters"""
        self.saliency_params = saliency_params
        for i in range(self.option.repeat_num):
            train_record = self.train_record_list[i]
            _, val_loader, test_loader = self.get_loader()
            target, target_loader = self.get_eval_pair(
                train_record, val_loader, test_loader
            )
            if target is not None and target_loader is not None:  # model is trained
                eval_record = Evaluator.evaluate_with_saliency(
                    target, target_loader, self.saliency_params
                )
                self.train_record_list[i].set_eval_record(eval_record)

    # status
    def get_training_status(self) -> str:
        """Return the training status"""
        if self.error:
            return self.error
        return self.status

    def get_training_repeat(self) -> int:
        """Return the index of the current training repetition"""
        for i in range(self.option.repeat_num):
            if not self.train_record_list[i].is_finished():
                break
        return i

    def get_training_epoch(self) -> int:
        """Return the current epoch of the training plan"""
        return self.train_record_list[self.get_training_repeat()].get_epoch()

    def get_training_evaluation(self) -> tuple:
        """Return the evaluation result of the training plan

        Return:
            Tuple of lr, train_loss, train_acc, train_auc, val_loss, val_acc
        """
        record = self.train_record_list[self.get_training_repeat()]

        lr: float | str = "-"
        train_loss: float | str = "-"
        train_acc: float | str = "-"
        train_auc: float | str = "-"
        val_loss: float | str = "-"
        val_acc: float | str = "-"
        val_auc: float | str = "-"
        if len(record.train[TrainRecordKey.LR]) > 0:
            lr = record.train[TrainRecordKey.LR][-1]
        if len(record.train[TrainRecordKey.LOSS]) > 0:
            train_loss = record.train[TrainRecordKey.LOSS][-1]
        if len(record.train[TrainRecordKey.AUC]) > 0:
            train_auc = record.train[TrainRecordKey.AUC][-1]
        if len(record.train[TrainRecordKey.ACC]) > 0:
            train_acc = record.train[TrainRecordKey.ACC][-1]
        if len(record.val[RecordKey.LOSS]) > 0:
            val_loss = record.val[RecordKey.LOSS][-1]
        if len(record.val[RecordKey.ACC]) > 0:
            val_acc = record.val[RecordKey.ACC][-1]
        if len(record.val[RecordKey.AUC]) > 0:
            val_auc = record.val[RecordKey.AUC][-1]
        return lr, train_loss, train_acc, train_auc, val_loss, val_acc, val_auc

    def is_finished(self) -> bool:
        """Return whether the training plan is finished"""
        return self.train_record_list[-1].is_finished()

    def get_epoch_progress_text(self) -> str:
        """Return the progress text of the training plan"""
        total = 0
        for train_record in self.train_record_list:
            total += train_record.get_epoch()
        return f"{total} / {self.option.epoch * self.option.repeat_num}"

    def get_best_performance(self) -> float:
        """Return the best accuracy achieved during training"""
        record = self.train_record_list[self.get_training_repeat()]
        # Check validation accuracy first
        best_val_acc = record.best_record.get(f"best_val_{RecordKey.ACC}", -1)
        if best_val_acc != -1:
            return best_val_acc
        # Fallback to test accuracy
        best_test_acc = record.best_record.get(f"best_test_{RecordKey.ACC}", -1)
        if best_test_acc != -1:
            return best_test_acc
        # Fallback to current accuracy if no best recorded (e.g. early epoch)
        if len(record.val[RecordKey.ACC]) > 0:
            return record.val[RecordKey.ACC][-1]
        return 0.0
