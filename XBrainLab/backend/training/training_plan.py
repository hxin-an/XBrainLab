"""Training plan management, including data loading, training loops, and evaluation."""

from __future__ import annotations

import datetime
import threading
from enum import Enum

import numpy as np
import torch
import torch.utils.data as torch_data

from XBrainLab.backend.utils.logger import logger

# ... (Previous imports remain, but remove captum/sklearn if unused locally)
# Actually, maintain clean imports:
from ..dataset import Dataset
from ..utils import set_seed, validate_type
from ..visualization import supported_saliency_methods
from .evaluator import Evaluator
from .model_holder import ModelHolder
from .option import TrainingEvaluation, TrainingOption
from .record import RecordKey, TrainRecord, TrainRecordKey


class SharedMemoryDataset(torch_data.Dataset):
    """A PyTorch Dataset that references shared numpy arrays to save RAM/VRAM.

    Data is transferred to the target device only when accessed via
    ``__getitem__``, avoiding upfront copies of the full dataset.

    Attributes:
        data: Full data array shared across all splits.
        labels: Full label array shared across all splits.
        indices: Array of indices into ``data`` and ``labels`` for this split.
        device: Target PyTorch device string (e.g., ``'cpu'`` or ``'cuda:0'``).

    """

    def __init__(
        self,
        data: np.ndarray,
        labels: np.ndarray,
        indices: np.ndarray,
        device: str,
    ):
        """Initialize the shared memory dataset.

        Args:
            data: Full data array of shape ``(N, ...)``, shared across splits.
            labels: Full label array of shape ``(N,)``.
            indices: Integer array of sample indices for this split.
            device: Target PyTorch device string.

        """
        self.data = data
        self.labels = labels
        self.indices = indices
        self.device = device

    def __len__(self):
        """Return the number of samples in this split.

        Returns:
            The number of indices in this dataset split.

        """
        return len(self.indices)

    def __getitem__(self, idx):
        """Retrieve a single sample and transfer it to the target device.

        Args:
            idx: Index into :attr:`indices`.

        Returns:
            A tuple of ``(input_tensor, label_tensor)`` on the target device.

        """
        real_idx = self.indices[idx]
        # Data is transferred to device only when accessed (saves VRAM)
        x = torch.from_numpy(self.data[real_idx]).float().to(self.device)
        y = torch.tensor(self.labels[real_idx]).long().to(self.device)
        return x, y


def to_holder(
    data: np.ndarray,
    labels: np.ndarray,
    indices: np.ndarray,
    dev: str,
    bs: int,
    shuffle: bool = False,
) -> torch_data.DataLoader | None:
    """Convert data arrays into a PyTorch DataLoader using shared memory.

    Args:
        data: Full data array of shape ``(N, ...)``.
        labels: Full label array of shape ``(N,)``.
        indices: Integer array of sample indices for this split.
        dev: Target PyTorch device string.
        bs: Batch size.
        shuffle: Whether to shuffle the data. Defaults to ``False``.

    Returns:
        A :class:`torch.utils.data.DataLoader` wrapping a
        :class:`SharedMemoryDataset`, or ``None`` if ``indices`` is empty.

    """
    if len(indices) == 0:
        return None

    # Use SharedMemoryDataset to avoid copying numpy arrays (saves RAM)
    # and to load to GPU on-the-fly (saves VRAM).
    dataset = SharedMemoryDataset(data, labels, indices, dev)

    dataloader = torch_data.DataLoader(dataset, batch_size=bs, shuffle=shuffle)
    return dataloader


class Status(Enum):
    """Enumeration of training plan execution states.

    Attributes:
        DONE: Training has completed.
        PENDING: Training has not started yet.
        INIT: Initializing a specific training repeat.
        EVAL: Evaluating a specific training repeat.
        TRAIN: Training a specific repeat.

    """

    DONE = "Finished"
    PENDING = "Pending"
    INIT = "Initializing {}"
    EVAL = "Evaluating {}"
    TRAIN = "Training {}"


class TrainingPlanHolder:
    """class for storing training plan

    Contains repetition of training plan,
        each training plan is a :class:`TrainRecord` object

    Attributes:
        model_holder: :class:`ModelHolder` object
            Model holder
        dataset: :class:`Dataset` object
            Dataset for the training plan
        option: :class:`TrainingOption` object
            Training option
        train_record_list: List[:class:`TrainRecord`]
            List of training record generated by the training plan,
                used for storing training result
        interrupt: bool
            Whether the training is interrupted
        error: str | None
            Error message
        status: str
            Training status

    """

    def __init__(
        self,
        model_holder: ModelHolder,
        dataset: Dataset,
        option: TrainingOption,
        saliency_params: dict | None,
    ):
        """Initialize the training plan holder.

        Creates :class:`TrainRecord` instances for each repetition, each with
        a fresh model and random seed.

        Args:
            model_holder: Holder containing the model class and parameters.
            dataset: Dataset providing training, validation, and test splits.
            option: Training configuration options.
            saliency_params: Parameters for saliency computation methods.
                If ``None`` or empty, default parameters are used.

        Raises:
            ValueError: If the dataset, option, or model holder is invalid,
                or if model creation fails due to incompatible parameters.

        """
        self.model_holder = model_holder
        self.dataset = dataset
        self.option = option

        if not saliency_params:
            logger.warning("No saliency parameter is set, using default parameters.")
            params = {"nt_samples": 5, "nt_samples_batch_size": None, "stdevs": 1.0}
            saliency_params = dict.fromkeys(supported_saliency_methods, params)
        self.saliency_params: dict = saliency_params

        self.check_data()

        # Generate unique plan ID (timestamp) to avoid directory collision
        self.plan_id = datetime.datetime.now().strftime("%Y%m%d-%H%M%S")

        self.train_record_list = []
        self._interrupt = threading.Event()
        self.error: str | None = None
        self.status = Status.PENDING.value
        for i in range(self.option.repeat_num):
            seed = set_seed(seed=None)
            try:
                model = self.model_holder.get_model(
                    self.dataset.get_epoch_data().get_model_args(),
                )
            except (RuntimeError, ValueError) as e:
                # Catch both RuntimeError (from PyTorch) and ValueError (from our
                # validation)
                if "Output size is too small" in str(
                    e,
                ) or "Epoch duration is too short" in str(e):
                    model_name = self.model_holder.target_model.__name__
                    raise ValueError(
                        f"Failed to create model '{model_name}': {e!s}",
                    ) from e
                raise
            self.train_record_list.append(
                TrainRecord(
                    repeat=i,
                    dataset=self.dataset,
                    model=model,
                    option=self.option,
                    seed=seed,
                    plan_id=self.plan_id,
                ),
            )

    def check_data(self) -> None:
        """Validate that the training plan has valid dataset, option, and model.

        Raises:
            ValueError: If any required component is ``None`` or invalid.
            TypeError: If components are not of the expected types.

        """
        if self.dataset is None:
            raise ValueError("dataset cannot be None")
        if not self.dataset.get_epoch_data():
            raise ValueError("No valid training setting is generated")
        if not self.option:
            raise ValueError("No valid training setting is generated")
        if not self.model_holder:
            raise ValueError("No valid model is selected")

        validate_type(self.model_holder, ModelHolder, "model_holder")
        validate_type(self.dataset, Dataset, "dataset")
        validate_type(self.option, TrainingOption, "option")
        self.option.validate()

    # interact
    def train(self) -> None:
        """Execute the full training process for all repetitions.

        Iterates through each :class:`TrainRecord` and trains it. On completion,
        updates the status to ``DONE`` or ``PENDING``. On exception, stores the
        error message.
        """
        try:
            for i in range(self.option.repeat_num):
                self.status = Status.INIT.value.format(
                    self.train_record_list[i].get_name(),
                )
                train_record = self.train_record_list[i]
                train_record.resume()
                self.train_one_repeat(train_record)
                train_record.pause()
            if self.is_finished():
                self.status = Status.DONE.value
            else:
                self.status = Status.PENDING.value
        except Exception as e:
            logger.error("Training plan execution failed: %s", e, exc_info=True)
            self.error = str(e)
            self.status = Status.PENDING.value
        finally:
            # Ensure GPU models are moved back to CPU to prevent VRAM leaks
            for tr in self.train_record_list:
                self._safe_move_to_cpu(tr)
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

    @staticmethod
    def _safe_move_to_cpu(train_record):
        """Move a training record's model to CPU, logging failures."""
        try:
            train_record.model.cpu()
        except RuntimeError:
            logger.debug("Failed to move model to CPU", exc_info=True)

    def get_loader(
        self,
    ) -> tuple[
        torch_data.DataLoader | None,
        torch_data.DataLoader | None,
        torch_data.DataLoader | None,
    ]:
        """Create data loaders for training, validation, and testing splits.

        Returns:
            A tuple of ``(train_loader, val_loader, test_loader)``. Any loader
            may be ``None`` if the corresponding split has no samples.

        """
        bs = self.option.bs
        dev = self.option.get_device()

        # Access full data once (Reference)
        full_data = self.dataset.get_epoch_data().get_data()
        full_labels = self.dataset.get_epoch_data().get_label_list()

        # Get indices from masks
        train_idx = np.where(self.dataset.train_mask)[0]
        val_idx = np.where(self.dataset.val_mask)[0]
        test_idx = np.where(self.dataset.test_mask)[0]

        train_holder: torch_data.DataLoader | None = to_holder(
            full_data,
            full_labels,
            train_idx,
            dev,
            bs,
            True,
        )
        val_holder: torch_data.DataLoader | None = to_holder(
            full_data,
            full_labels,
            val_idx,
            dev,
            bs,
        )
        test_holder: torch_data.DataLoader | None = to_holder(
            full_data,
            full_labels,
            test_idx,
            dev,
            bs,
        )
        return train_holder, val_holder, test_holder

    def get_eval_pair(
        self,
        train_record: TrainRecord,
        val_loader: torch_data.DataLoader | None,
        test_loader: torch_data.DataLoader | None,
    ) -> tuple[torch.nn.Module | None, torch_data.DataLoader | None]:
        """Select the best model and data loader for final evaluation.

        The model selection depends on the configured
        :attr:`option.evaluation_option` strategy.

        Args:
            train_record: The training record containing best model state dicts.
            val_loader: Validation data loader, or ``None``.
            test_loader: Test data loader, or ``None``.

        Returns:
            A tuple of ``(model, data_loader)`` for evaluation. Either may be
            ``None`` if no suitable model or data is available.

        Raises:
            NotImplementedError: If the evaluation option is not recognized.

        """
        target_loader = test_loader or val_loader

        # Determine the state_dict to load before allocating the model on GPU
        if self.option.evaluation_option == TrainingEvaluation.VAL_LOSS:
            state = getattr(train_record, f"best_val_{RecordKey.LOSS}_model")
        elif self.option.evaluation_option == TrainingEvaluation.TEST_ACC:
            state = getattr(train_record, f"best_test_{RecordKey.ACC}_model")
        elif self.option.evaluation_option == TrainingEvaluation.TEST_AUC:
            state = getattr(train_record, f"best_test_{RecordKey.AUC}_model")
        elif self.option.evaluation_option == TrainingEvaluation.LAST_EPOCH:
            state = train_record.model.state_dict()
        else:
            raise NotImplementedError

        if not state:
            return None, target_loader

        # Only create the model on GPU once we know we have a valid state_dict
        target_model = self.model_holder.get_model(
            self.dataset.get_epoch_data().get_model_args(),
        ).to(self.option.get_device())
        target_model.load_state_dict(state)
        target_model = target_model.eval()
        return target_model, target_loader

    def train_one_repeat(self, train_record: TrainRecord) -> None:
        """Train one repetition of the training plan

        Args:
            train_record: Training record for storing training result

        """
        if train_record.is_finished():
            return
        # init
        model = train_record.get_training_model(device=self.option.get_device())
        train_loader, val_loader, test_loader = self.get_loader()
        if self.option.epoch > 0 and not train_loader:
            raise ValueError("No Training Data")
        optimizer = train_record.optim
        criterion = train_record.criterion
        self.status = Status.TRAIN.value.format(train_record.get_name())
        # train one epoch
        while train_record.epoch < self.option.epoch:
            if self._interrupt.is_set():
                break
            if train_loader is None:
                raise ValueError("train_loader cannot be None during training loop")
            self.train_one_epoch(
                model,
                train_loader,
                val_loader,
                test_loader,
                optimizer,
                criterion,
                train_record,
            )

        if train_record.epoch == self.option.epoch:
            self.status = Status.EVAL.value.format(train_record.get_name())
            target, target_loader = self.get_eval_pair(
                train_record,
                val_loader,
                test_loader,
            )

            # Fallback: If no validation/test data, use training data for
            # evaluation/visualization
            if not target_loader and train_loader:
                target_loader = train_loader
                if not target:
                    target = train_record.model
                    target.eval()

            if target and target_loader:
                eval_record = Evaluator.evaluate_with_saliency(
                    target,
                    target_loader,
                    self.saliency_params,
                )
                train_record.set_eval_record(eval_record)

        train_record.export_checkpoint()

    def train_one_epoch(
        self,
        model: torch.nn.Module,
        train_loader: torch_data.DataLoader,
        val_loader: torch_data.DataLoader | None,
        test_loader: torch_data.DataLoader | None,
        optimizer: torch.optim.Optimizer,
        criterion: torch.nn.Module,
        train_record: TrainRecord,
    ) -> None:
        """Train one epoch of the training plan.

        Delegates to :class:`~.epoch_runner.EpochRunner` which
        encapsulates the batch-loop → metrics → eval → checkpoint
        sequence.

        Args:
            model (torch.nn.Module): The model to train.
            train_loader (torch_data.DataLoader): Data loader for training set.
            val_loader (torch_data.DataLoader | None): Data loader for validation set.
            test_loader (torch_data.DataLoader | None): Data loader for test set.
            optimizer (torch.optim.Optimizer): Optimizer for backpropagation.
            criterion (torch.nn.Module): Loss function.
            train_record (TrainRecord): Record to store training statistics.

        """
        from .epoch_runner import EpochRunner

        runner = EpochRunner(
            interrupt=self._interrupt,
            checkpoint_epoch=self.option.checkpoint_epoch,
        )
        runner.run(
            model,
            train_loader,
            val_loader,
            test_loader,
            optimizer,
            criterion,
            train_record,
        )

    @property
    def interrupt(self) -> bool:
        """Whether an interrupt has been requested (thread-safe)."""
        return self._interrupt.is_set()

    def set_interrupt(self) -> None:
        """Set the interrupt flag to stop training after the current batch."""
        self._interrupt.set()

    def clear_interrupt(self) -> None:
        """Clear the interrupt flag and reset the error status."""
        self.error = None
        self._interrupt.clear()

    # getter
    def get_name(self) -> str:
        """Return the name of the training plan (derived from the dataset).

        Returns:
            The dataset name string.

        """
        return self.dataset.get_name()

    def get_dataset(self) -> Dataset:
        """Return the dataset associated with this training plan.

        Returns:
            The :class:`Dataset` instance.

        """
        return self.dataset

    def get_plans(self) -> list[TrainRecord]:
        """Return all training records (one per repetition).

        Returns:
            List of :class:`TrainRecord` instances.

        """
        return self.train_record_list

    def get_saliency_params(self) -> dict:
        """Return the saliency computation parameters.

        Returns:
            Dictionary of saliency method parameters.

        """
        return self.saliency_params

    # setter
    def set_saliency_params(self, saliency_params: dict) -> None:
        """Set new saliency parameters and re-evaluate all finished repeats.

        Args:
            saliency_params: New dictionary of saliency method parameters.

        """
        self.saliency_params = saliency_params
        _, val_loader, test_loader = self.get_loader()
        for i in range(self.option.repeat_num):
            train_record = self.train_record_list[i]
            target, target_loader = self.get_eval_pair(
                train_record,
                val_loader,
                test_loader,
            )
            if target is not None and target_loader is not None:  # model is trained
                eval_record = Evaluator.evaluate_with_saliency(
                    target,
                    target_loader,
                    self.saliency_params,
                )
                self.train_record_list[i].set_eval_record(eval_record)

    # status
    def get_training_status(self) -> str:
        """Return the current training status or error message.

        Returns:
            The error message if an error occurred, otherwise the status string.

        """
        if self.error:
            return self.error
        return self.status

    def get_training_repeat(self) -> int:
        """Return the index of the current (or next unfinished) training repetition.

        Returns:
            Zero-based index of the current training repetition.

        """
        for i in range(self.option.repeat_num):
            if not self.train_record_list[i].is_finished():
                return i
        return max(self.option.repeat_num - 1, 0)

    def get_training_epoch(self) -> int:
        """Return the current epoch of the active training repetition.

        Returns:
            The epoch count for the current repetition.

        """
        return self.train_record_list[self.get_training_repeat()].get_epoch()

    def get_training_evaluation(self) -> tuple:
        """Return current evaluation metrics for the active training repetition.

        Returns:
            A tuple of ``(lr, train_loss, train_acc, train_auc, val_loss,
            val_acc, val_auc)``. Values default to ``'-'`` if unavailable.

        """
        record = self.train_record_list[self.get_training_repeat()]

        lr: float | str = "-"
        train_loss: float | str = "-"
        train_acc: float | str = "-"
        train_auc: float | str = "-"
        val_loss: float | str = "-"
        val_acc: float | str = "-"
        val_auc: float | str = "-"
        if len(record.train[TrainRecordKey.LR]) > 0:
            lr = record.train[TrainRecordKey.LR][-1]
        if len(record.train[TrainRecordKey.LOSS]) > 0:
            train_loss = record.train[TrainRecordKey.LOSS][-1]
        if len(record.train[TrainRecordKey.AUC]) > 0:
            train_auc = record.train[TrainRecordKey.AUC][-1]
        if len(record.train[TrainRecordKey.ACC]) > 0:
            train_acc = record.train[TrainRecordKey.ACC][-1]
        if len(record.val[RecordKey.LOSS]) > 0:
            val_loss = record.val[RecordKey.LOSS][-1]
        if len(record.val[RecordKey.ACC]) > 0:
            val_acc = record.val[RecordKey.ACC][-1]
        if len(record.val[RecordKey.AUC]) > 0:
            val_auc = record.val[RecordKey.AUC][-1]
        return lr, train_loss, train_acc, train_auc, val_loss, val_acc, val_auc

    def is_finished(self) -> bool:
        """Check whether all training repetitions have completed.

        Returns:
            ``True`` if the last repetition's training record is finished.

        """
        return self.train_record_list[-1].is_finished()

    def get_epoch_progress_text(self) -> str:
        """Return a progress string showing completed vs. total epochs.

        Returns:
            A string formatted as ``'completed / total'``.

        """
        total = 0
        for train_record in self.train_record_list:
            total += train_record.get_epoch()
        return f"{total} / {self.option.epoch * self.option.repeat_num}"

    def get_best_performance(self) -> float:
        """Return the best accuracy achieved during training.

        Checks validation accuracy first, then test accuracy, then the most
        recent validation accuracy. Falls back to ``0.0``.

        Returns:
            The best accuracy value as a float.

        """
        record = self.train_record_list[self.get_training_repeat()]
        # Check validation accuracy first
        best_val_acc = record.best_record.get(f"best_val_{RecordKey.ACC}", -1)
        if best_val_acc != -1:
            return best_val_acc
        # Fallback to test accuracy
        best_test_acc = record.best_record.get(f"best_test_{RecordKey.ACC}", -1)
        if best_test_acc != -1:
            return best_test_acc
        # Fallback to current accuracy if no best recorded (e.g. early epoch)
        if len(record.val[RecordKey.ACC]) > 0:
            return record.val[RecordKey.ACC][-1]
        return 0.0
