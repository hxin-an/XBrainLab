"""Study module providing the central state container for an XBrainLab experiment."""

from .controller.dataset_controller import DatasetController
from .controller.evaluation_controller import EvaluationController
from .controller.preprocess_controller import PreprocessController
from .controller.training_controller import TrainingController
from .controller.visualization_controller import VisualizationController
from .data_manager import DataManager
from .dataset import Dataset, DatasetGenerator, DataSplittingConfig, Epochs
from .load_data import Raw, RawDataLoader
from .preprocessor import PreprocessBase
from .training import ModelHolder, Trainer, TrainingOption, TrainingPlanHolder
from .utils import validate_type
from .utils.logger import logger


class Study:
    """Class for storing required info a study.

    Attributes:
        loaded_data_list: list[:class:`XBrainLab.backend.load_data.Raw`].
            The raw data result loaded by
            :class:`XBrainLab.backend.load_data.RawDataLoader`.
        preprocessed_data_list: list[:class:`XBrainLab.backend.load_data.Raw`].
            The preprocessed data result generated by
                sequences of
                :class:`XBrainLab.backend.preprocessor.base.PreprocessBase`.
        epoch_data: :class:`XBrainLab.backend.dataset.Epochs` or None.
            The epoch data generated from list of
            :class:`XBrainLab.backend.load_data.Raw`.
        datasets: list[:class:`XBrainLab.backend.dataset.Dataset`].
            The datasets generated from
            :class:`XBrainLab.backend.dataset.DatasetGenerator`.
        model_holder: :class:`XBrainLab.backend.training.ModelHolder` or None.
            The model with parameters.
        training_option: :class:`XBrainLab.backend.training.TrainingOption` or None.
            The training option.
        trainer: :class:`XBrainLab.backend.training.Trainer` or None.
            The model trainer.
    """

    def __init__(self) -> None:
        self.data_manager = DataManager()

        # training
        self.model_holder: ModelHolder | None = None
        self.training_option: TrainingOption | None = None
        self.trainer: Trainer | None = None
        # visualization
        self.saliency_params: dict | None = None

        # Controller cache for singleton-like access
        self._controllers: dict = {}

        logger.info("Study initialized (with DataManager)")

    # --- DataManager Delegation Properties ---
    # NOTE: Setters write directly to DataManager attributes for backward
    # compatibility and test convenience. Production code should use the
    # dedicated set_* / clean_* methods which include validation.

    @property
    def loaded_data_list(self) -> list[Raw]:
        return self.data_manager.loaded_data_list

    @loaded_data_list.setter
    def loaded_data_list(self, value: list[Raw]) -> None:
        self.data_manager.loaded_data_list = value

    @property
    def preprocessed_data_list(self) -> list[Raw]:
        return self.data_manager.preprocessed_data_list

    @preprocessed_data_list.setter
    def preprocessed_data_list(self, value: list[Raw]) -> None:
        self.data_manager.preprocessed_data_list = value

    @property
    def epoch_data(self) -> Epochs | None:
        return self.data_manager.epoch_data

    @epoch_data.setter
    def epoch_data(self, value: Epochs | None) -> None:
        self.data_manager.epoch_data = value

    @property
    def datasets(self) -> list[Dataset]:
        return self.data_manager.datasets

    @datasets.setter
    def datasets(self, value: list[Dataset]) -> None:
        self.data_manager.datasets = value

    @property
    def dataset_generator(self):
        return self.data_manager.dataset_generator

    @dataset_generator.setter
    def dataset_generator(self, value):
        self.data_manager.dataset_generator = value

    @property
    def dataset_locked(self) -> bool:
        return self.data_manager.dataset_locked

    # --- Controller Access ---
    def get_controller(self, controller_type: str):
        """Get or create a cached controller instance.

        Args:
            controller_type: One of ``"dataset"``, ``"preprocess"``,
                ``"training"``, ``"evaluation"``, or ``"visualization"``.

        Returns:
            The controller instance for the given type.

        Raises:
            ValueError: If the controller type is unknown.
        """
        if controller_type not in self._controllers:
            if controller_type == "dataset":
                self._controllers[controller_type] = DatasetController(self)
            elif controller_type == "preprocess":
                self._controllers[controller_type] = PreprocessController(self)
            elif controller_type == "training":
                self._controllers[controller_type] = TrainingController(self)
            elif controller_type == "evaluation":
                self._controllers[controller_type] = EvaluationController(self)
            elif controller_type == "visualization":
                self._controllers[controller_type] = VisualizationController(self)
            else:
                raise ValueError(f"Unknown controller type: {controller_type}")
        return self._controllers[controller_type]

    # step 1 - load data
    def get_raw_data_loader(self) -> RawDataLoader:
        """Get the raw data loader instance from DataManager."""
        return self.data_manager.get_raw_data_loader()

    def backup_loaded_data(self) -> None:
        """Backup the currently loaded data list via DataManager."""
        self.data_manager.backup_loaded_data()

    def set_loaded_data_list(
        self, loaded_data_list: list[Raw], force_update: bool = False
    ) -> None:
        """Set loaded data list in DataManager.

        Cleans trainer first since new raw data invalidates it.
        """
        self.clean_trainer(force_update=force_update)
        self.data_manager.set_loaded_data_list(loaded_data_list, force_update)

    # step 2 - preprocess
    def set_preprocessed_data_list(
        self, preprocessed_data_list: list[Raw], force_update: bool = False
    ) -> None:
        """Set preprocessed data list in DataManager."""
        self.data_manager.set_preprocessed_data_list(
            preprocessed_data_list, force_update
        )

    def reset_preprocess(self, force_update=False) -> None:
        """Reset preprocessing via DataManager."""
        self.data_manager.reset_preprocess(force_update)

    def preprocess(self, preprocessor: type[PreprocessBase], **kwargs) -> None:
        """Apply a preprocessing step via DataManager.

        Args:
            preprocessor: The preprocessor class to apply.
            **kwargs: Keyword arguments forwarded to the preprocessor.
        """
        self.data_manager.preprocess(preprocessor, **kwargs)

    # step 3 - split data for training
    def get_datasets_generator(self, config: DataSplittingConfig) -> DatasetGenerator:
        """Create a dataset generator based on current epoch data.

        Args:
            config: Data splitting configuration.

        Returns:
            A dataset generator ready to produce train/val/test splits.

        Raises:
            ValueError: If no epoch data is available.
        """
        if not self.epoch_data:
            raise ValueError("No valid epoch data is generated")
        validate_type(config, DataSplittingConfig, "config")
        return DatasetGenerator(self.epoch_data, config)

    def set_datasets(self, datasets: list[Dataset], force_update: bool = False) -> None:
        """Set datasets in DataManager and clean trainer."""
        # Clean trainer is Study responsibility as it holds trainer
        self.clean_trainer(force_update=force_update)
        self.data_manager.set_datasets(datasets, force_update)

    # step 4 - training config
    def set_training_option(
        self, training_option: TrainingOption, force_update: bool = False
    ) -> None:
        """Set training option.

        Args:
            training_option: The training option to set.
            force_update: Whether to force update.
        """
        validate_type(training_option, TrainingOption, "training_option")
        # Do not clean trainer here to allow multi-experiment history
        self.training_option = training_option

    def set_model_holder(
        self, model_holder: ModelHolder, force_update: bool = False
    ) -> None:
        """Set model holder.

        Args:
            model_holder: The model holder to set.
            force_update: Whether to force update.
        """
        validate_type(model_holder, ModelHolder, "model_holder")
        # Do not clean trainer here to allow multi-experiment history
        self.model_holder = model_holder

    def generate_plan(self, force_update: bool = False, append: bool = False) -> None:
        """Generate training plan based on current configuration.

        Args:
            force_update: Whether to clear existing plan.
            append: Whether to append to existing plan.
        """
        if not append:
            self.clean_trainer(force_update=force_update)

        if not self.datasets:
            raise ValueError("No valid dataset is generated")
        if not self.training_option:
            raise ValueError("No valid training option is generated")
        if not self.model_holder:
            raise ValueError("No valid model holder is generated")

        training_plan_holders = []
        option = self.training_option
        model_holder = self.model_holder
        datasets = self.datasets
        training_plan_holders = [
            TrainingPlanHolder(model_holder, dataset, option, self.saliency_params)
            for dataset in datasets
        ]

        if append and self.trainer:
            self.trainer.add_training_plan_holders(training_plan_holders)
            logger.info("Appended %s training plans", len(training_plan_holders))
        else:
            self.trainer = Trainer(training_plan_holders)
            logger.info("Generated training plan")

    # step 5 - training
    def train(self, interact: bool = False) -> None:
        """Start training process.

        Args:
            interact: Whether to run interactively.
        """
        if not self.trainer:
            raise ValueError("No valid trainer is generated")

        self.trainer.run(interact=interact)
        logger.info("Started training (interact=%s)", interact)

    def stop_training(self) -> None:
        """Stop training execution."""
        if not self.trainer:
            raise ValueError("No valid trainer is generated")
        self.trainer.set_interrupt()
        logger.info("Stopped training")

    def is_training(self) -> bool:
        """Return whether training is currently running."""
        if self.trainer:
            return self.trainer.is_running()
        return False

    # step 6 - evaluation
    def export_output_csv(self, filepath: str, plan_name: str, real_plan_name: str):
        """Export model inference output to csv file.

        Args:
            filepath: Path to save the CSV.
            plan_name: Name of the plan.
            real_plan_name: Real name of the plan.
        """
        if not self.trainer:
            raise ValueError("No valid training plan is generated")
        plan = self.trainer.get_real_training_plan(plan_name, real_plan_name)
        record = plan.get_eval_record()
        if not record:
            raise ValueError("No evaluation record for this training plan")
        record.export_csv(filepath)

    # step 7 - visualization
    def set_channels(self, chs: list[str], positions: list[tuple]) -> None:
        """Set channels and positions for visualization."""
        if not self.epoch_data:
            raise ValueError("No valid epoch data is generated")
        self.epoch_data.set_channels(chs, positions)

    def get_saliency_params(self) -> dict | None:
        """Return parameters for saliency computation."""
        return self.saliency_params

    def set_saliency_params(self, saliency_params) -> None:
        """Set saliency parameters for saliency computation."""
        self.saliency_params = saliency_params
        if self.trainer:
            for training_plan_holder in self.trainer.get_training_plan_holders():
                training_plan_holder.set_saliency_params(saliency_params)

    # --- Clean Workflow ---
    # Study extends DataManager's cleaning by adding trainer awareness.

    def lock_dataset(self) -> None:
        """Lock dataset via DataManager."""
        self.data_manager.lock_dataset()

    def unlock_dataset(self) -> None:
        """Unlock dataset via DataManager."""
        self.data_manager.unlock_dataset()

    def is_locked(self) -> bool:
        """Check if dataset is locked via DataManager."""
        return self.data_manager.is_locked()

    def has_raw_data(self) -> bool:
        """Return whether raw data or downstream state exists (pure query)."""
        return self.data_manager.has_raw_data() or self.has_trainer()

    def has_datasets(self) -> bool:
        """Return whether datasets or a trainer exist (pure query)."""
        return self.data_manager.has_datasets() or self.has_trainer()

    def has_trainer(self) -> bool:
        """Return whether a trainer is configured (pure query)."""
        return self.trainer is not None

    def clean_raw_data(self, force_update: bool = True) -> None:
        """Clean raw data and all downstream state including trainer."""
        self.clean_datasets(force_update=force_update)
        self.data_manager.clean_raw_data(force_update)

    def clean_datasets(self, force_update: bool = True) -> None:
        """Clean datasets and trainer."""
        self.clean_trainer(force_update=force_update)
        self.data_manager.clean_datasets(force_update)

    def clean_trainer(self, force_update: bool = True) -> None:
        """Clean the trainer.

        Args:
            force_update: If ``False``, raises when a trainer exists.
        """
        if not force_update and self.has_trainer():
            raise ValueError(
                "This step has already been done, "
                "all following data will be removed if you reset this step.\n"
                "Please clean_trainer first."
            )
        if self.trainer:
            self.trainer.clean(force_update=force_update)
        self.trainer = None
