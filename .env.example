# --- XBrainLab Configuration ---

# Inference Mode
# Options: "local", "api", "gemini"
# Default: "local" (uses local GPU models)
# INFERENCE_MODE="gemini"

# --- Google Gemini API ---
# Get key from: https://aistudio.google.com/
# Required if inference_mode="gemini"
GEMINI_API_KEY=AIza...
GEMINI_MODEL_NAME=gemini-1.5-flash

# --- OpenAI Compatible API ---
# Support for OpenAI, DeepSeek, vLLM, etc.
# Required if inference_mode="api"

# 1. Official OpenAI
OPENAI_API_KEY=sk-...
OPENAI_BASE_URL=https://api.openai.com/v1
OPENAI_MODEL_NAME=gpt-4o

# 2. DeepSeek (Example)
# OPENAI_API_KEY=sk-ds-...
# OPENAI_BASE_URL=https://api.deepseek.com/v1
# OPENAI_MODEL_NAME=deepseek-chat

# 3. Local vLLM / LocalAI (Example)
# OPENAI_API_KEY=sk-local  (usually ignored but required by SDK)
# OPENAI_BASE_URL=http://localhost:8000/v1
# OPENAI_MODEL_NAME=meta-llama/Llama-3-8b-chat-hf
