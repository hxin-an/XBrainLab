============================= test session starts ==============================
platform linux -- Python 3.9.25, pytest-8.4.2, pluggy-1.6.0 -- /home/hxin/miniconda3/envs/XBrainLab/bin/python
cachedir: .pytest_cache
PyQt6 6.10.1 -- Qt runtime 6.10.1 -- Qt compiled 6.10.0
rootdir: /mnt/data/lab/XBrainlab_with_agent
configfile: pytest.ini
plugins: cov-7.0.0, qt-4.5.0
collecting ... collected 2020 items

XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0-0-value_target_unit0-SplitByType.DISABLE] PASSED [  0%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0-0-value_target_unit0-SplitByType.SESSION] PASSED [  0%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0-0-value_target_unit0-SplitByType.SESSION_IND] PASSED [  0%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0-0-value_target_unit0-SplitByType.TRIAL] PASSED [  0%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0-0-value_target_unit0-SplitByType.TRIAL_IND] PASSED [  0%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0-0-value_target_unit0-SplitByType.SUBJECT] PASSED [  0%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0-0-value_target_unit0-SplitByType.SUBJECT_IND] PASSED [  0%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0-0-value_target_unit0-ValSplitByType.DISABLE] PASSED [  0%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0-0-value_target_unit0-ValSplitByType.SESSION] PASSED [  0%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0-0-value_target_unit0-ValSplitByType.TRIAL] PASSED [  0%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0-0-value_target_unit0-ValSplitByType.SUBJECT] PASSED [  0%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0.0-0.0-value_target_unit1-SplitByType.DISABLE] PASSED [  0%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0.0-0.0-value_target_unit1-SplitByType.SESSION] PASSED [  0%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0.0-0.0-value_target_unit1-SplitByType.SESSION_IND] PASSED [  0%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0.0-0.0-value_target_unit1-SplitByType.TRIAL] PASSED [  0%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0.0-0.0-value_target_unit1-SplitByType.TRIAL_IND] PASSED [  0%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0.0-0.0-value_target_unit1-SplitByType.SUBJECT] PASSED [  0%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0.0-0.0-value_target_unit1-SplitByType.SUBJECT_IND] PASSED [  0%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0.0-0.0-value_target_unit1-ValSplitByType.DISABLE] PASSED [  0%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0.0-0.0-value_target_unit1-ValSplitByType.SESSION] PASSED [  0%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0.0-0.0-value_target_unit1-ValSplitByType.TRIAL] PASSED [  1%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0.0-0.0-value_target_unit1-ValSplitByType.SUBJECT] PASSED [  1%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0.3-0.3-value_target_unit2-SplitByType.DISABLE] PASSED [  1%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0.3-0.3-value_target_unit2-SplitByType.SESSION] PASSED [  1%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0.3-0.3-value_target_unit2-SplitByType.SESSION_IND] PASSED [  1%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0.3-0.3-value_target_unit2-SplitByType.TRIAL] PASSED [  1%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0.3-0.3-value_target_unit2-SplitByType.TRIAL_IND] PASSED [  1%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0.3-0.3-value_target_unit2-SplitByType.SUBJECT] PASSED [  1%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0.3-0.3-value_target_unit2-SplitByType.SUBJECT_IND] PASSED [  1%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0.3-0.3-value_target_unit2-ValSplitByType.DISABLE] PASSED [  1%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0.3-0.3-value_target_unit2-ValSplitByType.SESSION] PASSED [  1%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0.3-0.3-value_target_unit2-ValSplitByType.TRIAL] PASSED [  1%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-0.3-0.3-value_target_unit2-ValSplitByType.SUBJECT] PASSED [  1%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-1-1-value_target_unit3-SplitByType.DISABLE] PASSED [  1%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-1-1-value_target_unit3-SplitByType.SESSION] PASSED [  1%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-1-1-value_target_unit3-SplitByType.SESSION_IND] PASSED [  1%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-1-1-value_target_unit3-SplitByType.TRIAL] PASSED [  1%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-1-1-value_target_unit3-SplitByType.TRIAL_IND] PASSED [  1%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-1-1-value_target_unit3-SplitByType.SUBJECT] PASSED [  1%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-1-1-value_target_unit3-SplitByType.SUBJECT_IND] PASSED [  1%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-1-1-value_target_unit3-ValSplitByType.DISABLE] PASSED [  2%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-1-1-value_target_unit3-ValSplitByType.SESSION] PASSED [  2%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-1-1-value_target_unit3-ValSplitByType.TRIAL] PASSED [  2%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-1-1-value_target_unit3-ValSplitByType.SUBJECT] PASSED [  2%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-1.0-1.0-value_target_unit4-SplitByType.DISABLE] PASSED [  2%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-1.0-1.0-value_target_unit4-SplitByType.SESSION] PASSED [  2%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-1.0-1.0-value_target_unit4-SplitByType.SESSION_IND] PASSED [  2%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-1.0-1.0-value_target_unit4-SplitByType.TRIAL] PASSED [  2%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-1.0-1.0-value_target_unit4-SplitByType.TRIAL_IND] PASSED [  2%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-1.0-1.0-value_target_unit4-SplitByType.SUBJECT] PASSED [  2%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-1.0-1.0-value_target_unit4-SplitByType.SUBJECT_IND] PASSED [  2%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-1.0-1.0-value_target_unit4-ValSplitByType.DISABLE] PASSED [  2%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-1.0-1.0-value_target_unit4-ValSplitByType.SESSION] PASSED [  2%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-1.0-1.0-value_target_unit4-ValSplitByType.TRIAL] PASSED [  2%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-1.0-1.0-value_target_unit4-ValSplitByType.SUBJECT] PASSED [  2%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1.5-value_target_unit5-SplitByType.DISABLE] PASSED [  2%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1.5-value_target_unit5-SplitByType.SESSION] PASSED [  2%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1.5-value_target_unit5-SplitByType.SESSION_IND] PASSED [  2%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1.5-value_target_unit5-SplitByType.TRIAL] PASSED [  2%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1.5-value_target_unit5-SplitByType.TRIAL_IND] PASSED [  2%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1.5-value_target_unit5-SplitByType.SUBJECT] PASSED [  3%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1.5-value_target_unit5-SplitByType.SUBJECT_IND] PASSED [  3%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1.5-value_target_unit5-ValSplitByType.DISABLE] PASSED [  3%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1.5-value_target_unit5-ValSplitByType.SESSION] PASSED [  3%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1.5-value_target_unit5-ValSplitByType.TRIAL] PASSED [  3%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1.5-value_target_unit5-ValSplitByType.SUBJECT] PASSED [  3%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-2-2-value_target_unit6-SplitByType.DISABLE] PASSED [  3%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-2-2-value_target_unit6-SplitByType.SESSION] PASSED [  3%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-2-2-value_target_unit6-SplitByType.SESSION_IND] PASSED [  3%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-2-2-value_target_unit6-SplitByType.TRIAL] PASSED [  3%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-2-2-value_target_unit6-SplitByType.TRIAL_IND] PASSED [  3%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-2-2-value_target_unit6-SplitByType.SUBJECT] PASSED [  3%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-2-2-value_target_unit6-SplitByType.SUBJECT_IND] PASSED [  3%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-2-2-value_target_unit6-ValSplitByType.DISABLE] PASSED [  3%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-2-2-value_target_unit6-ValSplitByType.SESSION] PASSED [  3%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-2-2-value_target_unit6-ValSplitByType.TRIAL] PASSED [  3%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-2-2-value_target_unit6-ValSplitByType.SUBJECT] PASSED [  3%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-2.0-value_target_unit7-SplitByType.DISABLE] PASSED [  3%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-2.0-value_target_unit7-SplitByType.SESSION] PASSED [  3%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-2.0-value_target_unit7-SplitByType.SESSION_IND] PASSED [  3%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-2.0-value_target_unit7-SplitByType.TRIAL] PASSED [  4%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-2.0-value_target_unit7-SplitByType.TRIAL_IND] PASSED [  4%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-2.0-value_target_unit7-SplitByType.SUBJECT] PASSED [  4%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-2.0-value_target_unit7-SplitByType.SUBJECT_IND] PASSED [  4%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-2.0-value_target_unit7-ValSplitByType.DISABLE] PASSED [  4%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-2.0-value_target_unit7-ValSplitByType.SESSION] PASSED [  4%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-2.0-value_target_unit7-ValSplitByType.TRIAL] PASSED [  4%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-2.0-value_target_unit7-ValSplitByType.SUBJECT] PASSED [  4%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-2.0 -value_target_unit8-SplitByType.DISABLE] PASSED [  4%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-2.0 -value_target_unit8-SplitByType.SESSION] PASSED [  4%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-2.0 -value_target_unit8-SplitByType.SESSION_IND] PASSED [  4%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-2.0 -value_target_unit8-SplitByType.TRIAL] PASSED [  4%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-2.0 -value_target_unit8-SplitByType.TRIAL_IND] PASSED [  4%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-2.0 -value_target_unit8-SplitByType.SUBJECT] PASSED [  4%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-2.0 -value_target_unit8-SplitByType.SUBJECT_IND] PASSED [  4%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-2.0 -value_target_unit8-ValSplitByType.DISABLE] PASSED [  4%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-2.0 -value_target_unit8-ValSplitByType.SESSION] PASSED [  4%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-2.0 -value_target_unit8-ValSplitByType.TRIAL] PASSED [  4%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-2.0 -value_target_unit8-ValSplitByType.SUBJECT] PASSED [  4%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-parsed_value9-2 -value_target_unit9-SplitByType.DISABLE] PASSED [  4%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-parsed_value9-2 -value_target_unit9-SplitByType.SESSION] PASSED [  5%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-parsed_value9-2 -value_target_unit9-SplitByType.SESSION_IND] PASSED [  5%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-parsed_value9-2 -value_target_unit9-SplitByType.TRIAL] PASSED [  5%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-parsed_value9-2 -value_target_unit9-SplitByType.TRIAL_IND] PASSED [  5%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-parsed_value9-2 -value_target_unit9-SplitByType.SUBJECT] PASSED [  5%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-parsed_value9-2 -value_target_unit9-SplitByType.SUBJECT_IND] PASSED [  5%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-parsed_value9-2 -value_target_unit9-ValSplitByType.DISABLE] PASSED [  5%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-parsed_value9-2 -value_target_unit9-ValSplitByType.SESSION] PASSED [  5%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-parsed_value9-2 -value_target_unit9-ValSplitByType.TRIAL] PASSED [  5%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-parsed_value9-2 -value_target_unit9-ValSplitByType.SUBJECT] PASSED [  5%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1-value_target_unit10-SplitByType.DISABLE] PASSED [  5%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1-value_target_unit10-SplitByType.SESSION] PASSED [  5%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1-value_target_unit10-SplitByType.SESSION_IND] PASSED [  5%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1-value_target_unit10-SplitByType.TRIAL] PASSED [  5%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1-value_target_unit10-SplitByType.TRIAL_IND] PASSED [  5%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1-value_target_unit10-SplitByType.SUBJECT] PASSED [  5%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1-value_target_unit10-SplitByType.SUBJECT_IND] PASSED [  5%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1-value_target_unit10-ValSplitByType.DISABLE] PASSED [  5%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1-value_target_unit10-ValSplitByType.SESSION] PASSED [  5%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1-value_target_unit10-ValSplitByType.TRIAL] PASSED [  5%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1-value_target_unit10-ValSplitByType.SUBJECT] PASSED [  5%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1 -value_target_unit11-SplitByType.DISABLE] PASSED [  6%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1 -value_target_unit11-SplitByType.SESSION] PASSED [  6%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1 -value_target_unit11-SplitByType.SESSION_IND] PASSED [  6%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1 -value_target_unit11-SplitByType.TRIAL] PASSED [  6%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1 -value_target_unit11-SplitByType.TRIAL_IND] PASSED [  6%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1 -value_target_unit11-SplitByType.SUBJECT] PASSED [  6%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1 -value_target_unit11-SplitByType.SUBJECT_IND] PASSED [  6%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1 -value_target_unit11-ValSplitByType.DISABLE] PASSED [  6%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1 -value_target_unit11-ValSplitByType.SESSION] PASSED [  6%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1 -value_target_unit11-ValSplitByType.TRIAL] PASSED [  6%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1 -value_target_unit11-ValSplitByType.SUBJECT] PASSED [  6%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.0-value_target_unit12-SplitByType.DISABLE] PASSED [  6%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.0-value_target_unit12-SplitByType.SESSION] PASSED [  6%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.0-value_target_unit12-SplitByType.SESSION_IND] PASSED [  6%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.0-value_target_unit12-SplitByType.TRIAL] PASSED [  6%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.0-value_target_unit12-SplitByType.TRIAL_IND] PASSED [  6%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.0-value_target_unit12-SplitByType.SUBJECT] PASSED [  6%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.0-value_target_unit12-SplitByType.SUBJECT_IND] PASSED [  6%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.0-value_target_unit12-ValSplitByType.DISABLE] PASSED [  6%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.0-value_target_unit12-ValSplitByType.SESSION] PASSED [  6%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.0-value_target_unit12-ValSplitByType.TRIAL] PASSED [  7%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.0-value_target_unit12-ValSplitByType.SUBJECT] PASSED [  7%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.0 -value_target_unit13-SplitByType.DISABLE] PASSED [  7%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.0 -value_target_unit13-SplitByType.SESSION] PASSED [  7%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.0 -value_target_unit13-SplitByType.SESSION_IND] PASSED [  7%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.0 -value_target_unit13-SplitByType.TRIAL] PASSED [  7%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.0 -value_target_unit13-SplitByType.TRIAL_IND] PASSED [  7%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.0 -value_target_unit13-SplitByType.SUBJECT] PASSED [  7%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.0 -value_target_unit13-SplitByType.SUBJECT_IND] PASSED [  7%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.0 -value_target_unit13-ValSplitByType.DISABLE] PASSED [  7%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.0 -value_target_unit13-ValSplitByType.SESSION] PASSED [  7%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.0 -value_target_unit13-ValSplitByType.TRIAL] PASSED [  7%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.0 -value_target_unit13-ValSplitByType.SUBJECT] PASSED [  7%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.5-value_target_unit14-SplitByType.DISABLE] PASSED [  7%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.5-value_target_unit14-SplitByType.SESSION] PASSED [  7%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.5-value_target_unit14-SplitByType.SESSION_IND] PASSED [  7%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.5-value_target_unit14-SplitByType.TRIAL] PASSED [  7%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.5-value_target_unit14-SplitByType.TRIAL_IND] PASSED [  7%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.5-value_target_unit14-SplitByType.SUBJECT] PASSED [  7%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.5-value_target_unit14-SplitByType.SUBJECT_IND] PASSED [  7%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.5-value_target_unit14-ValSplitByType.DISABLE] PASSED [  8%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.5-value_target_unit14-ValSplitByType.SESSION] PASSED [  8%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.5-value_target_unit14-ValSplitByType.TRIAL] PASSED [  8%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.5-value_target_unit14-ValSplitByType.SUBJECT] PASSED [  8%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.5 -value_target_unit15-SplitByType.DISABLE] PASSED [  8%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.5 -value_target_unit15-SplitByType.SESSION] PASSED [  8%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.5 -value_target_unit15-SplitByType.SESSION_IND] PASSED [  8%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.5 -value_target_unit15-SplitByType.TRIAL] PASSED [  8%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.5 -value_target_unit15-SplitByType.TRIAL_IND] PASSED [  8%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.5 -value_target_unit15-SplitByType.SUBJECT] PASSED [  8%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.5 -value_target_unit15-SplitByType.SUBJECT_IND] PASSED [  8%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.5 -value_target_unit15-ValSplitByType.DISABLE] PASSED [  8%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.5 -value_target_unit15-ValSplitByType.SESSION] PASSED [  8%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.5 -value_target_unit15-ValSplitByType.TRIAL] PASSED [  8%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None--1.5 -value_target_unit15-ValSplitByType.SUBJECT] PASSED [  8%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-parsed_value16-1 2 3-value_target_unit16-SplitByType.DISABLE] PASSED [  8%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-parsed_value16-1 2 3-value_target_unit16-SplitByType.SESSION] PASSED [  8%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-parsed_value16-1 2 3-value_target_unit16-SplitByType.SESSION_IND] PASSED [  8%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-parsed_value16-1 2 3-value_target_unit16-SplitByType.TRIAL] PASSED [  8%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-parsed_value16-1 2 3-value_target_unit16-SplitByType.TRIAL_IND] PASSED [  8%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-parsed_value16-1 2 3-value_target_unit16-SplitByType.SUBJECT] PASSED [  9%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-parsed_value16-1 2 3-value_target_unit16-SplitByType.SUBJECT_IND] PASSED [  9%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-parsed_value16-1 2 3-value_target_unit16-ValSplitByType.DISABLE] PASSED [  9%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-parsed_value16-1 2 3-value_target_unit16-ValSplitByType.SESSION] PASSED [  9%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-parsed_value16-1 2 3-value_target_unit16-ValSplitByType.TRIAL] PASSED [  9%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-parsed_value16-1 2 3-value_target_unit16-ValSplitByType.SUBJECT] PASSED [  9%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 2 -3-value_target_unit17-SplitByType.DISABLE] PASSED [  9%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 2 -3-value_target_unit17-SplitByType.SESSION] PASSED [  9%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 2 -3-value_target_unit17-SplitByType.SESSION_IND] PASSED [  9%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 2 -3-value_target_unit17-SplitByType.TRIAL] PASSED [  9%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 2 -3-value_target_unit17-SplitByType.TRIAL_IND] PASSED [  9%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 2 -3-value_target_unit17-SplitByType.SUBJECT] PASSED [  9%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 2 -3-value_target_unit17-SplitByType.SUBJECT_IND] PASSED [  9%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 2 -3-value_target_unit17-ValSplitByType.DISABLE] PASSED [  9%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 2 -3-value_target_unit17-ValSplitByType.SESSION] PASSED [  9%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 2 -3-value_target_unit17-ValSplitByType.TRIAL] PASSED [  9%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 2 -3-value_target_unit17-ValSplitByType.SUBJECT] PASSED [  9%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 2 0.3-value_target_unit18-SplitByType.DISABLE] PASSED [  9%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 2 0.3-value_target_unit18-SplitByType.SESSION] PASSED [  9%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 2 0.3-value_target_unit18-SplitByType.SESSION_IND] PASSED [  9%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 2 0.3-value_target_unit18-SplitByType.TRIAL] PASSED [ 10%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 2 0.3-value_target_unit18-SplitByType.TRIAL_IND] PASSED [ 10%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 2 0.3-value_target_unit18-SplitByType.SUBJECT] PASSED [ 10%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 2 0.3-value_target_unit18-SplitByType.SUBJECT_IND] PASSED [ 10%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 2 0.3-value_target_unit18-ValSplitByType.DISABLE] PASSED [ 10%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 2 0.3-value_target_unit18-ValSplitByType.SESSION] PASSED [ 10%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 2 0.3-value_target_unit18-ValSplitByType.TRIAL] PASSED [ 10%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 2 0.3-value_target_unit18-ValSplitByType.SUBJECT] PASSED [ 10%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-e-value_target_unit19-SplitByType.DISABLE] PASSED [ 10%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-e-value_target_unit19-SplitByType.SESSION] PASSED [ 10%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-e-value_target_unit19-SplitByType.SESSION_IND] PASSED [ 10%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-e-value_target_unit19-SplitByType.TRIAL] PASSED [ 10%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-e-value_target_unit19-SplitByType.TRIAL_IND] PASSED [ 10%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-e-value_target_unit19-SplitByType.SUBJECT] PASSED [ 10%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-e-value_target_unit19-SplitByType.SUBJECT_IND] PASSED [ 10%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-e-value_target_unit19-ValSplitByType.DISABLE] PASSED [ 10%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-e-value_target_unit19-ValSplitByType.SESSION] PASSED [ 10%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-e-value_target_unit19-ValSplitByType.TRIAL] PASSED [ 10%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-e-value_target_unit19-ValSplitByType.SUBJECT] PASSED [ 10%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-e -value_target_unit20-SplitByType.DISABLE] PASSED [ 10%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-e -value_target_unit20-SplitByType.SESSION] PASSED [ 10%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-e -value_target_unit20-SplitByType.SESSION_IND] PASSED [ 11%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-e -value_target_unit20-SplitByType.TRIAL] PASSED [ 11%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-e -value_target_unit20-SplitByType.TRIAL_IND] PASSED [ 11%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-e -value_target_unit20-SplitByType.SUBJECT] PASSED [ 11%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-e -value_target_unit20-SplitByType.SUBJECT_IND] PASSED [ 11%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-e -value_target_unit20-ValSplitByType.DISABLE] PASSED [ 11%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-e -value_target_unit20-ValSplitByType.SESSION] PASSED [ 11%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-e -value_target_unit20-ValSplitByType.TRIAL] PASSED [ 11%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-e -value_target_unit20-ValSplitByType.SUBJECT] PASSED [ 11%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 e-value_target_unit21-SplitByType.DISABLE] PASSED [ 11%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 e-value_target_unit21-SplitByType.SESSION] PASSED [ 11%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 e-value_target_unit21-SplitByType.SESSION_IND] PASSED [ 11%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 e-value_target_unit21-SplitByType.TRIAL] PASSED [ 11%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 e-value_target_unit21-SplitByType.TRIAL_IND] PASSED [ 11%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 e-value_target_unit21-SplitByType.SUBJECT] PASSED [ 11%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 e-value_target_unit21-SplitByType.SUBJECT_IND] PASSED [ 11%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 e-value_target_unit21-ValSplitByType.DISABLE] PASSED [ 11%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 e-value_target_unit21-ValSplitByType.SESSION] PASSED [ 11%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 e-value_target_unit21-ValSplitByType.TRIAL] PASSED [ 11%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-1 e-value_target_unit21-ValSplitByType.SUBJECT] PASSED [ 11%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-None-value_target_unit22-SplitByType.DISABLE] PASSED [ 12%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-None-value_target_unit22-SplitByType.SESSION] PASSED [ 12%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-None-value_target_unit22-SplitByType.SESSION_IND] PASSED [ 12%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-None-value_target_unit22-SplitByType.TRIAL] PASSED [ 12%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-None-value_target_unit22-SplitByType.TRIAL_IND] PASSED [ 12%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-None-value_target_unit22-SplitByType.SUBJECT] PASSED [ 12%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-None-value_target_unit22-SplitByType.SUBJECT_IND] PASSED [ 12%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-None-value_target_unit22-ValSplitByType.DISABLE] PASSED [ 12%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-None-value_target_unit22-ValSplitByType.SESSION] PASSED [ 12%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-None-value_target_unit22-ValSplitByType.TRIAL] PASSED [ 12%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.RATIO-None-None-value_target_unit22-ValSplitByType.SUBJECT] PASSED [ 12%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0-0-value_target_unit0-SplitByType.DISABLE] PASSED [ 12%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0-0-value_target_unit0-SplitByType.SESSION] PASSED [ 12%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0-0-value_target_unit0-SplitByType.SESSION_IND] PASSED [ 12%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0-0-value_target_unit0-SplitByType.TRIAL] PASSED [ 12%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0-0-value_target_unit0-SplitByType.TRIAL_IND] PASSED [ 12%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0-0-value_target_unit0-SplitByType.SUBJECT] PASSED [ 12%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0-0-value_target_unit0-SplitByType.SUBJECT_IND] PASSED [ 12%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0-0-value_target_unit0-ValSplitByType.DISABLE] PASSED [ 12%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0-0-value_target_unit0-ValSplitByType.SESSION] PASSED [ 12%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0-0-value_target_unit0-ValSplitByType.TRIAL] PASSED [ 13%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0-0-value_target_unit0-ValSplitByType.SUBJECT] PASSED [ 13%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0.0-0.0-value_target_unit1-SplitByType.DISABLE] PASSED [ 13%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0.0-0.0-value_target_unit1-SplitByType.SESSION] PASSED [ 13%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0.0-0.0-value_target_unit1-SplitByType.SESSION_IND] PASSED [ 13%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0.0-0.0-value_target_unit1-SplitByType.TRIAL] PASSED [ 13%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0.0-0.0-value_target_unit1-SplitByType.TRIAL_IND] PASSED [ 13%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0.0-0.0-value_target_unit1-SplitByType.SUBJECT] PASSED [ 13%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0.0-0.0-value_target_unit1-SplitByType.SUBJECT_IND] PASSED [ 13%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0.0-0.0-value_target_unit1-ValSplitByType.DISABLE] PASSED [ 13%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0.0-0.0-value_target_unit1-ValSplitByType.SESSION] PASSED [ 13%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0.0-0.0-value_target_unit1-ValSplitByType.TRIAL] PASSED [ 13%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0.0-0.0-value_target_unit1-ValSplitByType.SUBJECT] PASSED [ 13%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0.3-0.3-value_target_unit2-SplitByType.DISABLE] PASSED [ 13%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0.3-0.3-value_target_unit2-SplitByType.SESSION] PASSED [ 13%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0.3-0.3-value_target_unit2-SplitByType.SESSION_IND] PASSED [ 13%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0.3-0.3-value_target_unit2-SplitByType.TRIAL] PASSED [ 13%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0.3-0.3-value_target_unit2-SplitByType.TRIAL_IND] PASSED [ 13%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0.3-0.3-value_target_unit2-SplitByType.SUBJECT] PASSED [ 13%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0.3-0.3-value_target_unit2-SplitByType.SUBJECT_IND] PASSED [ 13%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0.3-0.3-value_target_unit2-ValSplitByType.DISABLE] PASSED [ 14%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0.3-0.3-value_target_unit2-ValSplitByType.SESSION] PASSED [ 14%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0.3-0.3-value_target_unit2-ValSplitByType.TRIAL] PASSED [ 14%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-0.3-0.3-value_target_unit2-ValSplitByType.SUBJECT] PASSED [ 14%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-1-1-value_target_unit3-SplitByType.DISABLE] PASSED [ 14%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-1-1-value_target_unit3-SplitByType.SESSION] PASSED [ 14%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-1-1-value_target_unit3-SplitByType.SESSION_IND] PASSED [ 14%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-1-1-value_target_unit3-SplitByType.TRIAL] PASSED [ 14%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-1-1-value_target_unit3-SplitByType.TRIAL_IND] PASSED [ 14%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-1-1-value_target_unit3-SplitByType.SUBJECT] PASSED [ 14%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-1-1-value_target_unit3-SplitByType.SUBJECT_IND] PASSED [ 14%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-1-1-value_target_unit3-ValSplitByType.DISABLE] PASSED [ 14%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-1-1-value_target_unit3-ValSplitByType.SESSION] PASSED [ 14%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-1-1-value_target_unit3-ValSplitByType.TRIAL] PASSED [ 14%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-1-1-value_target_unit3-ValSplitByType.SUBJECT] PASSED [ 14%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-1.0-1.0-value_target_unit4-SplitByType.DISABLE] PASSED [ 14%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-1.0-1.0-value_target_unit4-SplitByType.SESSION] PASSED [ 14%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-1.0-1.0-value_target_unit4-SplitByType.SESSION_IND] PASSED [ 14%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-1.0-1.0-value_target_unit4-SplitByType.TRIAL] PASSED [ 14%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-1.0-1.0-value_target_unit4-SplitByType.TRIAL_IND] PASSED [ 14%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-1.0-1.0-value_target_unit4-SplitByType.SUBJECT] PASSED [ 15%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-1.0-1.0-value_target_unit4-SplitByType.SUBJECT_IND] PASSED [ 15%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-1.0-1.0-value_target_unit4-ValSplitByType.DISABLE] PASSED [ 15%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-1.0-1.0-value_target_unit4-ValSplitByType.SESSION] PASSED [ 15%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-1.0-1.0-value_target_unit4-ValSplitByType.TRIAL] PASSED [ 15%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-1.0-1.0-value_target_unit4-ValSplitByType.SUBJECT] PASSED [ 15%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1.5-value_target_unit5-SplitByType.DISABLE] PASSED [ 15%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1.5-value_target_unit5-SplitByType.SESSION] PASSED [ 15%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1.5-value_target_unit5-SplitByType.SESSION_IND] PASSED [ 15%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1.5-value_target_unit5-SplitByType.TRIAL] PASSED [ 15%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1.5-value_target_unit5-SplitByType.TRIAL_IND] PASSED [ 15%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1.5-value_target_unit5-SplitByType.SUBJECT] PASSED [ 15%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1.5-value_target_unit5-SplitByType.SUBJECT_IND] PASSED [ 15%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1.5-value_target_unit5-ValSplitByType.DISABLE] PASSED [ 15%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1.5-value_target_unit5-ValSplitByType.SESSION] PASSED [ 15%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1.5-value_target_unit5-ValSplitByType.TRIAL] PASSED [ 15%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1.5-value_target_unit5-ValSplitByType.SUBJECT] PASSED [ 15%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-2-2-value_target_unit6-SplitByType.DISABLE] PASSED [ 15%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-2-2-value_target_unit6-SplitByType.SESSION] PASSED [ 15%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-2-2-value_target_unit6-SplitByType.SESSION_IND] PASSED [ 15%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-2-2-value_target_unit6-SplitByType.TRIAL] PASSED [ 15%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-2-2-value_target_unit6-SplitByType.TRIAL_IND] PASSED [ 16%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-2-2-value_target_unit6-SplitByType.SUBJECT] PASSED [ 16%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-2-2-value_target_unit6-SplitByType.SUBJECT_IND] PASSED [ 16%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-2-2-value_target_unit6-ValSplitByType.DISABLE] PASSED [ 16%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-2-2-value_target_unit6-ValSplitByType.SESSION] PASSED [ 16%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-2-2-value_target_unit6-ValSplitByType.TRIAL] PASSED [ 16%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-2-2-value_target_unit6-ValSplitByType.SUBJECT] PASSED [ 16%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-2.0-value_target_unit7-SplitByType.DISABLE] PASSED [ 16%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-2.0-value_target_unit7-SplitByType.SESSION] PASSED [ 16%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-2.0-value_target_unit7-SplitByType.SESSION_IND] PASSED [ 16%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-2.0-value_target_unit7-SplitByType.TRIAL] PASSED [ 16%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-2.0-value_target_unit7-SplitByType.TRIAL_IND] PASSED [ 16%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-2.0-value_target_unit7-SplitByType.SUBJECT] PASSED [ 16%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-2.0-value_target_unit7-SplitByType.SUBJECT_IND] PASSED [ 16%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-2.0-value_target_unit7-ValSplitByType.DISABLE] PASSED [ 16%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-2.0-value_target_unit7-ValSplitByType.SESSION] PASSED [ 16%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-2.0-value_target_unit7-ValSplitByType.TRIAL] PASSED [ 16%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-2.0-value_target_unit7-ValSplitByType.SUBJECT] PASSED [ 16%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-2.0 -value_target_unit8-SplitByType.DISABLE] PASSED [ 16%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-2.0 -value_target_unit8-SplitByType.SESSION] PASSED [ 16%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-2.0 -value_target_unit8-SplitByType.SESSION_IND] PASSED [ 17%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-2.0 -value_target_unit8-SplitByType.TRIAL] PASSED [ 17%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-2.0 -value_target_unit8-SplitByType.TRIAL_IND] PASSED [ 17%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-2.0 -value_target_unit8-SplitByType.SUBJECT] PASSED [ 17%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-2.0 -value_target_unit8-SplitByType.SUBJECT_IND] PASSED [ 17%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-2.0 -value_target_unit8-ValSplitByType.DISABLE] PASSED [ 17%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-2.0 -value_target_unit8-ValSplitByType.SESSION] PASSED [ 17%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-2.0 -value_target_unit8-ValSplitByType.TRIAL] PASSED [ 17%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-2.0 -value_target_unit8-ValSplitByType.SUBJECT] PASSED [ 17%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-parsed_value9-2 -value_target_unit9-SplitByType.DISABLE] PASSED [ 17%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-parsed_value9-2 -value_target_unit9-SplitByType.SESSION] PASSED [ 17%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-parsed_value9-2 -value_target_unit9-SplitByType.SESSION_IND] PASSED [ 17%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-parsed_value9-2 -value_target_unit9-SplitByType.TRIAL] PASSED [ 17%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-parsed_value9-2 -value_target_unit9-SplitByType.TRIAL_IND] PASSED [ 17%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-parsed_value9-2 -value_target_unit9-SplitByType.SUBJECT] PASSED [ 17%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-parsed_value9-2 -value_target_unit9-SplitByType.SUBJECT_IND] PASSED [ 17%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-parsed_value9-2 -value_target_unit9-ValSplitByType.DISABLE] PASSED [ 17%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-parsed_value9-2 -value_target_unit9-ValSplitByType.SESSION] PASSED [ 17%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-parsed_value9-2 -value_target_unit9-ValSplitByType.TRIAL] PASSED [ 17%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-parsed_value9-2 -value_target_unit9-ValSplitByType.SUBJECT] PASSED [ 17%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1-value_target_unit10-SplitByType.DISABLE] PASSED [ 18%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1-value_target_unit10-SplitByType.SESSION] PASSED [ 18%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1-value_target_unit10-SplitByType.SESSION_IND] PASSED [ 18%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1-value_target_unit10-SplitByType.TRIAL] PASSED [ 18%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1-value_target_unit10-SplitByType.TRIAL_IND] PASSED [ 18%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1-value_target_unit10-SplitByType.SUBJECT] PASSED [ 18%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1-value_target_unit10-SplitByType.SUBJECT_IND] PASSED [ 18%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1-value_target_unit10-ValSplitByType.DISABLE] PASSED [ 18%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1-value_target_unit10-ValSplitByType.SESSION] PASSED [ 18%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1-value_target_unit10-ValSplitByType.TRIAL] PASSED [ 18%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1-value_target_unit10-ValSplitByType.SUBJECT] PASSED [ 18%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1 -value_target_unit11-SplitByType.DISABLE] PASSED [ 18%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1 -value_target_unit11-SplitByType.SESSION] PASSED [ 18%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1 -value_target_unit11-SplitByType.SESSION_IND] PASSED [ 18%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1 -value_target_unit11-SplitByType.TRIAL] PASSED [ 18%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1 -value_target_unit11-SplitByType.TRIAL_IND] PASSED [ 18%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1 -value_target_unit11-SplitByType.SUBJECT] PASSED [ 18%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1 -value_target_unit11-SplitByType.SUBJECT_IND] PASSED [ 18%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1 -value_target_unit11-ValSplitByType.DISABLE] PASSED [ 18%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1 -value_target_unit11-ValSplitByType.SESSION] PASSED [ 18%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1 -value_target_unit11-ValSplitByType.TRIAL] PASSED [ 19%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1 -value_target_unit11-ValSplitByType.SUBJECT] PASSED [ 19%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.0-value_target_unit12-SplitByType.DISABLE] PASSED [ 19%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.0-value_target_unit12-SplitByType.SESSION] PASSED [ 19%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.0-value_target_unit12-SplitByType.SESSION_IND] PASSED [ 19%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.0-value_target_unit12-SplitByType.TRIAL] PASSED [ 19%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.0-value_target_unit12-SplitByType.TRIAL_IND] PASSED [ 19%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.0-value_target_unit12-SplitByType.SUBJECT] PASSED [ 19%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.0-value_target_unit12-SplitByType.SUBJECT_IND] PASSED [ 19%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.0-value_target_unit12-ValSplitByType.DISABLE] PASSED [ 19%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.0-value_target_unit12-ValSplitByType.SESSION] PASSED [ 19%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.0-value_target_unit12-ValSplitByType.TRIAL] PASSED [ 19%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.0-value_target_unit12-ValSplitByType.SUBJECT] PASSED [ 19%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.0 -value_target_unit13-SplitByType.DISABLE] PASSED [ 19%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.0 -value_target_unit13-SplitByType.SESSION] PASSED [ 19%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.0 -value_target_unit13-SplitByType.SESSION_IND] PASSED [ 19%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.0 -value_target_unit13-SplitByType.TRIAL] PASSED [ 19%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.0 -value_target_unit13-SplitByType.TRIAL_IND] PASSED [ 19%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.0 -value_target_unit13-SplitByType.SUBJECT] PASSED [ 19%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.0 -value_target_unit13-SplitByType.SUBJECT_IND] PASSED [ 19%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.0 -value_target_unit13-ValSplitByType.DISABLE] PASSED [ 20%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.0 -value_target_unit13-ValSplitByType.SESSION] PASSED [ 20%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.0 -value_target_unit13-ValSplitByType.TRIAL] PASSED [ 20%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.0 -value_target_unit13-ValSplitByType.SUBJECT] PASSED [ 20%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.5-value_target_unit14-SplitByType.DISABLE] PASSED [ 20%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.5-value_target_unit14-SplitByType.SESSION] PASSED [ 20%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.5-value_target_unit14-SplitByType.SESSION_IND] PASSED [ 20%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.5-value_target_unit14-SplitByType.TRIAL] PASSED [ 20%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.5-value_target_unit14-SplitByType.TRIAL_IND] PASSED [ 20%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.5-value_target_unit14-SplitByType.SUBJECT] PASSED [ 20%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.5-value_target_unit14-SplitByType.SUBJECT_IND] PASSED [ 20%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.5-value_target_unit14-ValSplitByType.DISABLE] PASSED [ 20%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.5-value_target_unit14-ValSplitByType.SESSION] PASSED [ 20%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.5-value_target_unit14-ValSplitByType.TRIAL] PASSED [ 20%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.5-value_target_unit14-ValSplitByType.SUBJECT] PASSED [ 20%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.5 -value_target_unit15-SplitByType.DISABLE] PASSED [ 20%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.5 -value_target_unit15-SplitByType.SESSION] PASSED [ 20%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.5 -value_target_unit15-SplitByType.SESSION_IND] PASSED [ 20%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.5 -value_target_unit15-SplitByType.TRIAL] PASSED [ 20%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.5 -value_target_unit15-SplitByType.TRIAL_IND] PASSED [ 20%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.5 -value_target_unit15-SplitByType.SUBJECT] PASSED [ 20%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.5 -value_target_unit15-SplitByType.SUBJECT_IND] PASSED [ 21%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.5 -value_target_unit15-ValSplitByType.DISABLE] PASSED [ 21%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.5 -value_target_unit15-ValSplitByType.SESSION] PASSED [ 21%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.5 -value_target_unit15-ValSplitByType.TRIAL] PASSED [ 21%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None--1.5 -value_target_unit15-ValSplitByType.SUBJECT] PASSED [ 21%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-parsed_value16-1 2 3-value_target_unit16-SplitByType.DISABLE] PASSED [ 21%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-parsed_value16-1 2 3-value_target_unit16-SplitByType.SESSION] PASSED [ 21%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-parsed_value16-1 2 3-value_target_unit16-SplitByType.SESSION_IND] PASSED [ 21%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-parsed_value16-1 2 3-value_target_unit16-SplitByType.TRIAL] PASSED [ 21%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-parsed_value16-1 2 3-value_target_unit16-SplitByType.TRIAL_IND] PASSED [ 21%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-parsed_value16-1 2 3-value_target_unit16-SplitByType.SUBJECT] PASSED [ 21%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-parsed_value16-1 2 3-value_target_unit16-SplitByType.SUBJECT_IND] PASSED [ 21%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-parsed_value16-1 2 3-value_target_unit16-ValSplitByType.DISABLE] PASSED [ 21%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-parsed_value16-1 2 3-value_target_unit16-ValSplitByType.SESSION] PASSED [ 21%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-parsed_value16-1 2 3-value_target_unit16-ValSplitByType.TRIAL] PASSED [ 21%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-parsed_value16-1 2 3-value_target_unit16-ValSplitByType.SUBJECT] PASSED [ 21%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 2 -3-value_target_unit17-SplitByType.DISABLE] PASSED [ 21%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 2 -3-value_target_unit17-SplitByType.SESSION] PASSED [ 21%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 2 -3-value_target_unit17-SplitByType.SESSION_IND] PASSED [ 21%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 2 -3-value_target_unit17-SplitByType.TRIAL] PASSED [ 21%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 2 -3-value_target_unit17-SplitByType.TRIAL_IND] PASSED [ 22%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 2 -3-value_target_unit17-SplitByType.SUBJECT] PASSED [ 22%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 2 -3-value_target_unit17-SplitByType.SUBJECT_IND] PASSED [ 22%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 2 -3-value_target_unit17-ValSplitByType.DISABLE] PASSED [ 22%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 2 -3-value_target_unit17-ValSplitByType.SESSION] PASSED [ 22%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 2 -3-value_target_unit17-ValSplitByType.TRIAL] PASSED [ 22%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 2 -3-value_target_unit17-ValSplitByType.SUBJECT] PASSED [ 22%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 2 0.3-value_target_unit18-SplitByType.DISABLE] PASSED [ 22%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 2 0.3-value_target_unit18-SplitByType.SESSION] PASSED [ 22%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 2 0.3-value_target_unit18-SplitByType.SESSION_IND] PASSED [ 22%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 2 0.3-value_target_unit18-SplitByType.TRIAL] PASSED [ 22%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 2 0.3-value_target_unit18-SplitByType.TRIAL_IND] PASSED [ 22%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 2 0.3-value_target_unit18-SplitByType.SUBJECT] PASSED [ 22%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 2 0.3-value_target_unit18-SplitByType.SUBJECT_IND] PASSED [ 22%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 2 0.3-value_target_unit18-ValSplitByType.DISABLE] PASSED [ 22%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 2 0.3-value_target_unit18-ValSplitByType.SESSION] PASSED [ 22%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 2 0.3-value_target_unit18-ValSplitByType.TRIAL] PASSED [ 22%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 2 0.3-value_target_unit18-ValSplitByType.SUBJECT] PASSED [ 22%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-e-value_target_unit19-SplitByType.DISABLE] PASSED [ 22%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-e-value_target_unit19-SplitByType.SESSION] PASSED [ 22%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-e-value_target_unit19-SplitByType.SESSION_IND] PASSED [ 23%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-e-value_target_unit19-SplitByType.TRIAL] PASSED [ 23%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-e-value_target_unit19-SplitByType.TRIAL_IND] PASSED [ 23%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-e-value_target_unit19-SplitByType.SUBJECT] PASSED [ 23%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-e-value_target_unit19-SplitByType.SUBJECT_IND] PASSED [ 23%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-e-value_target_unit19-ValSplitByType.DISABLE] PASSED [ 23%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-e-value_target_unit19-ValSplitByType.SESSION] PASSED [ 23%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-e-value_target_unit19-ValSplitByType.TRIAL] PASSED [ 23%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-e-value_target_unit19-ValSplitByType.SUBJECT] PASSED [ 23%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-e -value_target_unit20-SplitByType.DISABLE] PASSED [ 23%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-e -value_target_unit20-SplitByType.SESSION] PASSED [ 23%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-e -value_target_unit20-SplitByType.SESSION_IND] PASSED [ 23%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-e -value_target_unit20-SplitByType.TRIAL] PASSED [ 23%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-e -value_target_unit20-SplitByType.TRIAL_IND] PASSED [ 23%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-e -value_target_unit20-SplitByType.SUBJECT] PASSED [ 23%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-e -value_target_unit20-SplitByType.SUBJECT_IND] PASSED [ 23%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-e -value_target_unit20-ValSplitByType.DISABLE] PASSED [ 23%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-e -value_target_unit20-ValSplitByType.SESSION] PASSED [ 23%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-e -value_target_unit20-ValSplitByType.TRIAL] PASSED [ 23%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-e -value_target_unit20-ValSplitByType.SUBJECT] PASSED [ 23%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 e-value_target_unit21-SplitByType.DISABLE] PASSED [ 24%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 e-value_target_unit21-SplitByType.SESSION] PASSED [ 24%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 e-value_target_unit21-SplitByType.SESSION_IND] PASSED [ 24%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 e-value_target_unit21-SplitByType.TRIAL] PASSED [ 24%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 e-value_target_unit21-SplitByType.TRIAL_IND] PASSED [ 24%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 e-value_target_unit21-SplitByType.SUBJECT] PASSED [ 24%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 e-value_target_unit21-SplitByType.SUBJECT_IND] PASSED [ 24%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 e-value_target_unit21-ValSplitByType.DISABLE] PASSED [ 24%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 e-value_target_unit21-ValSplitByType.SESSION] PASSED [ 24%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 e-value_target_unit21-ValSplitByType.TRIAL] PASSED [ 24%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-1 e-value_target_unit21-ValSplitByType.SUBJECT] PASSED [ 24%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-None-value_target_unit22-SplitByType.DISABLE] PASSED [ 24%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-None-value_target_unit22-SplitByType.SESSION] PASSED [ 24%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-None-value_target_unit22-SplitByType.SESSION_IND] PASSED [ 24%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-None-value_target_unit22-SplitByType.TRIAL] PASSED [ 24%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-None-value_target_unit22-SplitByType.TRIAL_IND] PASSED [ 24%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-None-value_target_unit22-SplitByType.SUBJECT] PASSED [ 24%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-None-value_target_unit22-SplitByType.SUBJECT_IND] PASSED [ 24%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-None-value_target_unit22-ValSplitByType.DISABLE] PASSED [ 24%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-None-value_target_unit22-ValSplitByType.SESSION] PASSED [ 24%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-None-value_target_unit22-ValSplitByType.TRIAL] PASSED [ 25%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.NUMBER-None-None-value_target_unit22-ValSplitByType.SUBJECT] PASSED [ 25%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0-0-value_target_unit0-SplitByType.DISABLE] PASSED [ 25%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0-0-value_target_unit0-SplitByType.SESSION] PASSED [ 25%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0-0-value_target_unit0-SplitByType.SESSION_IND] PASSED [ 25%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0-0-value_target_unit0-SplitByType.TRIAL] PASSED [ 25%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0-0-value_target_unit0-SplitByType.TRIAL_IND] PASSED [ 25%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0-0-value_target_unit0-SplitByType.SUBJECT] PASSED [ 25%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0-0-value_target_unit0-SplitByType.SUBJECT_IND] PASSED [ 25%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0-0-value_target_unit0-ValSplitByType.DISABLE] PASSED [ 25%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0-0-value_target_unit0-ValSplitByType.SESSION] PASSED [ 25%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0-0-value_target_unit0-ValSplitByType.TRIAL] PASSED [ 25%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0-0-value_target_unit0-ValSplitByType.SUBJECT] PASSED [ 25%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0.0-0.0-value_target_unit1-SplitByType.DISABLE] PASSED [ 25%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0.0-0.0-value_target_unit1-SplitByType.SESSION] PASSED [ 25%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0.0-0.0-value_target_unit1-SplitByType.SESSION_IND] PASSED [ 25%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0.0-0.0-value_target_unit1-SplitByType.TRIAL] PASSED [ 25%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0.0-0.0-value_target_unit1-SplitByType.TRIAL_IND] PASSED [ 25%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0.0-0.0-value_target_unit1-SplitByType.SUBJECT] PASSED [ 25%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0.0-0.0-value_target_unit1-SplitByType.SUBJECT_IND] PASSED [ 25%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0.0-0.0-value_target_unit1-ValSplitByType.DISABLE] PASSED [ 25%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0.0-0.0-value_target_unit1-ValSplitByType.SESSION] PASSED [ 26%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0.0-0.0-value_target_unit1-ValSplitByType.TRIAL] PASSED [ 26%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0.0-0.0-value_target_unit1-ValSplitByType.SUBJECT] PASSED [ 26%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0.3-0.3-value_target_unit2-SplitByType.DISABLE] PASSED [ 26%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0.3-0.3-value_target_unit2-SplitByType.SESSION] PASSED [ 26%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0.3-0.3-value_target_unit2-SplitByType.SESSION_IND] PASSED [ 26%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0.3-0.3-value_target_unit2-SplitByType.TRIAL] PASSED [ 26%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0.3-0.3-value_target_unit2-SplitByType.TRIAL_IND] PASSED [ 26%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0.3-0.3-value_target_unit2-SplitByType.SUBJECT] PASSED [ 26%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0.3-0.3-value_target_unit2-SplitByType.SUBJECT_IND] PASSED [ 26%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0.3-0.3-value_target_unit2-ValSplitByType.DISABLE] PASSED [ 26%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0.3-0.3-value_target_unit2-ValSplitByType.SESSION] PASSED [ 26%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0.3-0.3-value_target_unit2-ValSplitByType.TRIAL] PASSED [ 26%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-0.3-0.3-value_target_unit2-ValSplitByType.SUBJECT] PASSED [ 26%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-1-1-value_target_unit3-SplitByType.DISABLE] PASSED [ 26%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-1-1-value_target_unit3-SplitByType.SESSION] PASSED [ 26%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-1-1-value_target_unit3-SplitByType.SESSION_IND] PASSED [ 26%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-1-1-value_target_unit3-SplitByType.TRIAL] PASSED [ 26%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-1-1-value_target_unit3-SplitByType.TRIAL_IND] PASSED [ 26%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-1-1-value_target_unit3-SplitByType.SUBJECT] PASSED [ 26%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-1-1-value_target_unit3-SplitByType.SUBJECT_IND] PASSED [ 27%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-1-1-value_target_unit3-ValSplitByType.DISABLE] PASSED [ 27%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-1-1-value_target_unit3-ValSplitByType.SESSION] PASSED [ 27%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-1-1-value_target_unit3-ValSplitByType.TRIAL] PASSED [ 27%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-1-1-value_target_unit3-ValSplitByType.SUBJECT] PASSED [ 27%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-1.0-1.0-value_target_unit4-SplitByType.DISABLE] PASSED [ 27%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-1.0-1.0-value_target_unit4-SplitByType.SESSION] PASSED [ 27%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-1.0-1.0-value_target_unit4-SplitByType.SESSION_IND] PASSED [ 27%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-1.0-1.0-value_target_unit4-SplitByType.TRIAL] PASSED [ 27%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-1.0-1.0-value_target_unit4-SplitByType.TRIAL_IND] PASSED [ 27%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-1.0-1.0-value_target_unit4-SplitByType.SUBJECT] PASSED [ 27%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-1.0-1.0-value_target_unit4-SplitByType.SUBJECT_IND] PASSED [ 27%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-1.0-1.0-value_target_unit4-ValSplitByType.DISABLE] PASSED [ 27%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-1.0-1.0-value_target_unit4-ValSplitByType.SESSION] PASSED [ 27%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-1.0-1.0-value_target_unit4-ValSplitByType.TRIAL] PASSED [ 27%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-1.0-1.0-value_target_unit4-ValSplitByType.SUBJECT] PASSED [ 27%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1.5-value_target_unit5-SplitByType.DISABLE] PASSED [ 27%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1.5-value_target_unit5-SplitByType.SESSION] PASSED [ 27%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1.5-value_target_unit5-SplitByType.SESSION_IND] PASSED [ 27%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1.5-value_target_unit5-SplitByType.TRIAL] PASSED [ 27%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1.5-value_target_unit5-SplitByType.TRIAL_IND] PASSED [ 28%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1.5-value_target_unit5-SplitByType.SUBJECT] PASSED [ 28%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1.5-value_target_unit5-SplitByType.SUBJECT_IND] PASSED [ 28%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1.5-value_target_unit5-ValSplitByType.DISABLE] PASSED [ 28%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1.5-value_target_unit5-ValSplitByType.SESSION] PASSED [ 28%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1.5-value_target_unit5-ValSplitByType.TRIAL] PASSED [ 28%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1.5-value_target_unit5-ValSplitByType.SUBJECT] PASSED [ 28%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-2-2-value_target_unit6-SplitByType.DISABLE] PASSED [ 28%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-2-2-value_target_unit6-SplitByType.SESSION] PASSED [ 28%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-2-2-value_target_unit6-SplitByType.SESSION_IND] PASSED [ 28%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-2-2-value_target_unit6-SplitByType.TRIAL] PASSED [ 28%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-2-2-value_target_unit6-SplitByType.TRIAL_IND] PASSED [ 28%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-2-2-value_target_unit6-SplitByType.SUBJECT] PASSED [ 28%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-2-2-value_target_unit6-SplitByType.SUBJECT_IND] PASSED [ 28%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-2-2-value_target_unit6-ValSplitByType.DISABLE] PASSED [ 28%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-2-2-value_target_unit6-ValSplitByType.SESSION] PASSED [ 28%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-2-2-value_target_unit6-ValSplitByType.TRIAL] PASSED [ 28%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-2-2-value_target_unit6-ValSplitByType.SUBJECT] PASSED [ 28%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-2.0-value_target_unit7-SplitByType.DISABLE] PASSED [ 28%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-2.0-value_target_unit7-SplitByType.SESSION] PASSED [ 28%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-2.0-value_target_unit7-SplitByType.SESSION_IND] PASSED [ 29%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-2.0-value_target_unit7-SplitByType.TRIAL] PASSED [ 29%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-2.0-value_target_unit7-SplitByType.TRIAL_IND] PASSED [ 29%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-2.0-value_target_unit7-SplitByType.SUBJECT] PASSED [ 29%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-2.0-value_target_unit7-SplitByType.SUBJECT_IND] PASSED [ 29%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-2.0-value_target_unit7-ValSplitByType.DISABLE] PASSED [ 29%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-2.0-value_target_unit7-ValSplitByType.SESSION] PASSED [ 29%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-2.0-value_target_unit7-ValSplitByType.TRIAL] PASSED [ 29%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-2.0-value_target_unit7-ValSplitByType.SUBJECT] PASSED [ 29%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-2.0 -value_target_unit8-SplitByType.DISABLE] PASSED [ 29%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-2.0 -value_target_unit8-SplitByType.SESSION] PASSED [ 29%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-2.0 -value_target_unit8-SplitByType.SESSION_IND] PASSED [ 29%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-2.0 -value_target_unit8-SplitByType.TRIAL] PASSED [ 29%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-2.0 -value_target_unit8-SplitByType.TRIAL_IND] PASSED [ 29%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-2.0 -value_target_unit8-SplitByType.SUBJECT] PASSED [ 29%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-2.0 -value_target_unit8-SplitByType.SUBJECT_IND] PASSED [ 29%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-2.0 -value_target_unit8-ValSplitByType.DISABLE] PASSED [ 29%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-2.0 -value_target_unit8-ValSplitByType.SESSION] PASSED [ 29%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-2.0 -value_target_unit8-ValSplitByType.TRIAL] PASSED [ 29%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-2.0 -value_target_unit8-ValSplitByType.SUBJECT] PASSED [ 29%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-parsed_value9-2 -value_target_unit9-SplitByType.DISABLE] PASSED [ 30%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-parsed_value9-2 -value_target_unit9-SplitByType.SESSION] PASSED [ 30%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-parsed_value9-2 -value_target_unit9-SplitByType.SESSION_IND] PASSED [ 30%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-parsed_value9-2 -value_target_unit9-SplitByType.TRIAL] PASSED [ 30%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-parsed_value9-2 -value_target_unit9-SplitByType.TRIAL_IND] PASSED [ 30%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-parsed_value9-2 -value_target_unit9-SplitByType.SUBJECT] PASSED [ 30%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-parsed_value9-2 -value_target_unit9-SplitByType.SUBJECT_IND] PASSED [ 30%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-parsed_value9-2 -value_target_unit9-ValSplitByType.DISABLE] PASSED [ 30%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-parsed_value9-2 -value_target_unit9-ValSplitByType.SESSION] PASSED [ 30%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-parsed_value9-2 -value_target_unit9-ValSplitByType.TRIAL] PASSED [ 30%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-parsed_value9-2 -value_target_unit9-ValSplitByType.SUBJECT] PASSED [ 30%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1-value_target_unit10-SplitByType.DISABLE] PASSED [ 30%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1-value_target_unit10-SplitByType.SESSION] PASSED [ 30%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1-value_target_unit10-SplitByType.SESSION_IND] PASSED [ 30%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1-value_target_unit10-SplitByType.TRIAL] PASSED [ 30%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1-value_target_unit10-SplitByType.TRIAL_IND] PASSED [ 30%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1-value_target_unit10-SplitByType.SUBJECT] PASSED [ 30%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1-value_target_unit10-SplitByType.SUBJECT_IND] PASSED [ 30%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1-value_target_unit10-ValSplitByType.DISABLE] PASSED [ 30%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1-value_target_unit10-ValSplitByType.SESSION] PASSED [ 30%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1-value_target_unit10-ValSplitByType.TRIAL] PASSED [ 30%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1-value_target_unit10-ValSplitByType.SUBJECT] PASSED [ 31%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1 -value_target_unit11-SplitByType.DISABLE] PASSED [ 31%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1 -value_target_unit11-SplitByType.SESSION] PASSED [ 31%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1 -value_target_unit11-SplitByType.SESSION_IND] PASSED [ 31%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1 -value_target_unit11-SplitByType.TRIAL] PASSED [ 31%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1 -value_target_unit11-SplitByType.TRIAL_IND] PASSED [ 31%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1 -value_target_unit11-SplitByType.SUBJECT] PASSED [ 31%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1 -value_target_unit11-SplitByType.SUBJECT_IND] PASSED [ 31%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1 -value_target_unit11-ValSplitByType.DISABLE] PASSED [ 31%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1 -value_target_unit11-ValSplitByType.SESSION] PASSED [ 31%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1 -value_target_unit11-ValSplitByType.TRIAL] PASSED [ 31%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1 -value_target_unit11-ValSplitByType.SUBJECT] PASSED [ 31%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.0-value_target_unit12-SplitByType.DISABLE] PASSED [ 31%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.0-value_target_unit12-SplitByType.SESSION] PASSED [ 31%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.0-value_target_unit12-SplitByType.SESSION_IND] PASSED [ 31%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.0-value_target_unit12-SplitByType.TRIAL] PASSED [ 31%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.0-value_target_unit12-SplitByType.TRIAL_IND] PASSED [ 31%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.0-value_target_unit12-SplitByType.SUBJECT] PASSED [ 31%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.0-value_target_unit12-SplitByType.SUBJECT_IND] PASSED [ 31%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.0-value_target_unit12-ValSplitByType.DISABLE] PASSED [ 31%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.0-value_target_unit12-ValSplitByType.SESSION] PASSED [ 32%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.0-value_target_unit12-ValSplitByType.TRIAL] PASSED [ 32%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.0-value_target_unit12-ValSplitByType.SUBJECT] PASSED [ 32%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.0 -value_target_unit13-SplitByType.DISABLE] PASSED [ 32%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.0 -value_target_unit13-SplitByType.SESSION] PASSED [ 32%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.0 -value_target_unit13-SplitByType.SESSION_IND] PASSED [ 32%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.0 -value_target_unit13-SplitByType.TRIAL] PASSED [ 32%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.0 -value_target_unit13-SplitByType.TRIAL_IND] PASSED [ 32%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.0 -value_target_unit13-SplitByType.SUBJECT] PASSED [ 32%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.0 -value_target_unit13-SplitByType.SUBJECT_IND] PASSED [ 32%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.0 -value_target_unit13-ValSplitByType.DISABLE] PASSED [ 32%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.0 -value_target_unit13-ValSplitByType.SESSION] PASSED [ 32%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.0 -value_target_unit13-ValSplitByType.TRIAL] PASSED [ 32%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.0 -value_target_unit13-ValSplitByType.SUBJECT] PASSED [ 32%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.5-value_target_unit14-SplitByType.DISABLE] PASSED [ 32%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.5-value_target_unit14-SplitByType.SESSION] PASSED [ 32%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.5-value_target_unit14-SplitByType.SESSION_IND] PASSED [ 32%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.5-value_target_unit14-SplitByType.TRIAL] PASSED [ 32%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.5-value_target_unit14-SplitByType.TRIAL_IND] PASSED [ 32%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.5-value_target_unit14-SplitByType.SUBJECT] PASSED [ 32%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.5-value_target_unit14-SplitByType.SUBJECT_IND] PASSED [ 33%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.5-value_target_unit14-ValSplitByType.DISABLE] PASSED [ 33%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.5-value_target_unit14-ValSplitByType.SESSION] PASSED [ 33%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.5-value_target_unit14-ValSplitByType.TRIAL] PASSED [ 33%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.5-value_target_unit14-ValSplitByType.SUBJECT] PASSED [ 33%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.5 -value_target_unit15-SplitByType.DISABLE] PASSED [ 33%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.5 -value_target_unit15-SplitByType.SESSION] PASSED [ 33%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.5 -value_target_unit15-SplitByType.SESSION_IND] PASSED [ 33%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.5 -value_target_unit15-SplitByType.TRIAL] PASSED [ 33%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.5 -value_target_unit15-SplitByType.TRIAL_IND] PASSED [ 33%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.5 -value_target_unit15-SplitByType.SUBJECT] PASSED [ 33%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.5 -value_target_unit15-SplitByType.SUBJECT_IND] PASSED [ 33%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.5 -value_target_unit15-ValSplitByType.DISABLE] PASSED [ 33%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.5 -value_target_unit15-ValSplitByType.SESSION] PASSED [ 33%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.5 -value_target_unit15-ValSplitByType.TRIAL] PASSED [ 33%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None--1.5 -value_target_unit15-ValSplitByType.SUBJECT] PASSED [ 33%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-parsed_value16-1 2 3-value_target_unit16-SplitByType.DISABLE] PASSED [ 33%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-parsed_value16-1 2 3-value_target_unit16-SplitByType.SESSION] PASSED [ 33%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-parsed_value16-1 2 3-value_target_unit16-SplitByType.SESSION_IND] PASSED [ 33%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-parsed_value16-1 2 3-value_target_unit16-SplitByType.TRIAL] PASSED [ 33%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-parsed_value16-1 2 3-value_target_unit16-SplitByType.TRIAL_IND] PASSED [ 34%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-parsed_value16-1 2 3-value_target_unit16-SplitByType.SUBJECT] PASSED [ 34%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-parsed_value16-1 2 3-value_target_unit16-SplitByType.SUBJECT_IND] PASSED [ 34%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-parsed_value16-1 2 3-value_target_unit16-ValSplitByType.DISABLE] PASSED [ 34%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-parsed_value16-1 2 3-value_target_unit16-ValSplitByType.SESSION] PASSED [ 34%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-parsed_value16-1 2 3-value_target_unit16-ValSplitByType.TRIAL] PASSED [ 34%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-parsed_value16-1 2 3-value_target_unit16-ValSplitByType.SUBJECT] PASSED [ 34%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 2 -3-value_target_unit17-SplitByType.DISABLE] PASSED [ 34%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 2 -3-value_target_unit17-SplitByType.SESSION] PASSED [ 34%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 2 -3-value_target_unit17-SplitByType.SESSION_IND] PASSED [ 34%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 2 -3-value_target_unit17-SplitByType.TRIAL] PASSED [ 34%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 2 -3-value_target_unit17-SplitByType.TRIAL_IND] PASSED [ 34%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 2 -3-value_target_unit17-SplitByType.SUBJECT] PASSED [ 34%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 2 -3-value_target_unit17-SplitByType.SUBJECT_IND] PASSED [ 34%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 2 -3-value_target_unit17-ValSplitByType.DISABLE] PASSED [ 34%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 2 -3-value_target_unit17-ValSplitByType.SESSION] PASSED [ 34%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 2 -3-value_target_unit17-ValSplitByType.TRIAL] PASSED [ 34%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 2 -3-value_target_unit17-ValSplitByType.SUBJECT] PASSED [ 34%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 2 0.3-value_target_unit18-SplitByType.DISABLE] PASSED [ 34%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 2 0.3-value_target_unit18-SplitByType.SESSION] PASSED [ 34%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 2 0.3-value_target_unit18-SplitByType.SESSION_IND] PASSED [ 35%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 2 0.3-value_target_unit18-SplitByType.TRIAL] PASSED [ 35%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 2 0.3-value_target_unit18-SplitByType.TRIAL_IND] PASSED [ 35%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 2 0.3-value_target_unit18-SplitByType.SUBJECT] PASSED [ 35%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 2 0.3-value_target_unit18-SplitByType.SUBJECT_IND] PASSED [ 35%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 2 0.3-value_target_unit18-ValSplitByType.DISABLE] PASSED [ 35%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 2 0.3-value_target_unit18-ValSplitByType.SESSION] PASSED [ 35%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 2 0.3-value_target_unit18-ValSplitByType.TRIAL] PASSED [ 35%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 2 0.3-value_target_unit18-ValSplitByType.SUBJECT] PASSED [ 35%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-e-value_target_unit19-SplitByType.DISABLE] PASSED [ 35%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-e-value_target_unit19-SplitByType.SESSION] PASSED [ 35%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-e-value_target_unit19-SplitByType.SESSION_IND] PASSED [ 35%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-e-value_target_unit19-SplitByType.TRIAL] PASSED [ 35%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-e-value_target_unit19-SplitByType.TRIAL_IND] PASSED [ 35%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-e-value_target_unit19-SplitByType.SUBJECT] PASSED [ 35%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-e-value_target_unit19-SplitByType.SUBJECT_IND] PASSED [ 35%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-e-value_target_unit19-ValSplitByType.DISABLE] PASSED [ 35%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-e-value_target_unit19-ValSplitByType.SESSION] PASSED [ 35%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-e-value_target_unit19-ValSplitByType.TRIAL] PASSED [ 35%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-e-value_target_unit19-ValSplitByType.SUBJECT] PASSED [ 35%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-e -value_target_unit20-SplitByType.DISABLE] PASSED [ 35%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-e -value_target_unit20-SplitByType.SESSION] PASSED [ 36%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-e -value_target_unit20-SplitByType.SESSION_IND] PASSED [ 36%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-e -value_target_unit20-SplitByType.TRIAL] PASSED [ 36%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-e -value_target_unit20-SplitByType.TRIAL_IND] PASSED [ 36%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-e -value_target_unit20-SplitByType.SUBJECT] PASSED [ 36%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-e -value_target_unit20-SplitByType.SUBJECT_IND] PASSED [ 36%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-e -value_target_unit20-ValSplitByType.DISABLE] PASSED [ 36%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-e -value_target_unit20-ValSplitByType.SESSION] PASSED [ 36%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-e -value_target_unit20-ValSplitByType.TRIAL] PASSED [ 36%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-e -value_target_unit20-ValSplitByType.SUBJECT] PASSED [ 36%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 e-value_target_unit21-SplitByType.DISABLE] PASSED [ 36%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 e-value_target_unit21-SplitByType.SESSION] PASSED [ 36%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 e-value_target_unit21-SplitByType.SESSION_IND] PASSED [ 36%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 e-value_target_unit21-SplitByType.TRIAL] PASSED [ 36%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 e-value_target_unit21-SplitByType.TRIAL_IND] PASSED [ 36%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 e-value_target_unit21-SplitByType.SUBJECT] PASSED [ 36%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 e-value_target_unit21-SplitByType.SUBJECT_IND] PASSED [ 36%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 e-value_target_unit21-ValSplitByType.DISABLE] PASSED [ 36%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 e-value_target_unit21-ValSplitByType.SESSION] PASSED [ 36%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 e-value_target_unit21-ValSplitByType.TRIAL] PASSED [ 36%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-1 e-value_target_unit21-ValSplitByType.SUBJECT] PASSED [ 37%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-None-value_target_unit22-SplitByType.DISABLE] PASSED [ 37%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-None-value_target_unit22-SplitByType.SESSION] PASSED [ 37%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-None-value_target_unit22-SplitByType.SESSION_IND] PASSED [ 37%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-None-value_target_unit22-SplitByType.TRIAL] PASSED [ 37%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-None-value_target_unit22-SplitByType.TRIAL_IND] PASSED [ 37%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-None-value_target_unit22-SplitByType.SUBJECT] PASSED [ 37%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-None-value_target_unit22-SplitByType.SUBJECT_IND] PASSED [ 37%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-None-value_target_unit22-ValSplitByType.DISABLE] PASSED [ 37%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-None-value_target_unit22-ValSplitByType.SESSION] PASSED [ 37%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-None-value_target_unit22-ValSplitByType.TRIAL] PASSED [ 37%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.MANUAL-None-None-value_target_unit22-ValSplitByType.SUBJECT] PASSED [ 37%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0-0-value_target_unit0-SplitByType.DISABLE] PASSED [ 37%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0-0-value_target_unit0-SplitByType.SESSION] PASSED [ 37%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0-0-value_target_unit0-SplitByType.SESSION_IND] PASSED [ 37%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0-0-value_target_unit0-SplitByType.TRIAL] PASSED [ 37%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0-0-value_target_unit0-SplitByType.TRIAL_IND] PASSED [ 37%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0-0-value_target_unit0-SplitByType.SUBJECT] PASSED [ 37%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0-0-value_target_unit0-SplitByType.SUBJECT_IND] PASSED [ 37%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0-0-value_target_unit0-ValSplitByType.DISABLE] PASSED [ 37%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0-0-value_target_unit0-ValSplitByType.SESSION] PASSED [ 38%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0-0-value_target_unit0-ValSplitByType.TRIAL] PASSED [ 38%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0-0-value_target_unit0-ValSplitByType.SUBJECT] PASSED [ 38%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0.0-0.0-value_target_unit1-SplitByType.DISABLE] PASSED [ 38%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0.0-0.0-value_target_unit1-SplitByType.SESSION] PASSED [ 38%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0.0-0.0-value_target_unit1-SplitByType.SESSION_IND] PASSED [ 38%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0.0-0.0-value_target_unit1-SplitByType.TRIAL] PASSED [ 38%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0.0-0.0-value_target_unit1-SplitByType.TRIAL_IND] PASSED [ 38%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0.0-0.0-value_target_unit1-SplitByType.SUBJECT] PASSED [ 38%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0.0-0.0-value_target_unit1-SplitByType.SUBJECT_IND] PASSED [ 38%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0.0-0.0-value_target_unit1-ValSplitByType.DISABLE] PASSED [ 38%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0.0-0.0-value_target_unit1-ValSplitByType.SESSION] PASSED [ 38%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0.0-0.0-value_target_unit1-ValSplitByType.TRIAL] PASSED [ 38%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0.0-0.0-value_target_unit1-ValSplitByType.SUBJECT] PASSED [ 38%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0.3-0.3-value_target_unit2-SplitByType.DISABLE] PASSED [ 38%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0.3-0.3-value_target_unit2-SplitByType.SESSION] PASSED [ 38%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0.3-0.3-value_target_unit2-SplitByType.SESSION_IND] PASSED [ 38%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0.3-0.3-value_target_unit2-SplitByType.TRIAL] PASSED [ 38%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0.3-0.3-value_target_unit2-SplitByType.TRIAL_IND] PASSED [ 38%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0.3-0.3-value_target_unit2-SplitByType.SUBJECT] PASSED [ 38%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0.3-0.3-value_target_unit2-SplitByType.SUBJECT_IND] PASSED [ 39%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0.3-0.3-value_target_unit2-ValSplitByType.DISABLE] PASSED [ 39%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0.3-0.3-value_target_unit2-ValSplitByType.SESSION] PASSED [ 39%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0.3-0.3-value_target_unit2-ValSplitByType.TRIAL] PASSED [ 39%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-0.3-0.3-value_target_unit2-ValSplitByType.SUBJECT] PASSED [ 39%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-1-1-value_target_unit3-SplitByType.DISABLE] PASSED [ 39%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-1-1-value_target_unit3-SplitByType.SESSION] PASSED [ 39%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-1-1-value_target_unit3-SplitByType.SESSION_IND] PASSED [ 39%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-1-1-value_target_unit3-SplitByType.TRIAL] PASSED [ 39%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-1-1-value_target_unit3-SplitByType.TRIAL_IND] PASSED [ 39%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-1-1-value_target_unit3-SplitByType.SUBJECT] PASSED [ 39%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-1-1-value_target_unit3-SplitByType.SUBJECT_IND] PASSED [ 39%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-1-1-value_target_unit3-ValSplitByType.DISABLE] PASSED [ 39%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-1-1-value_target_unit3-ValSplitByType.SESSION] PASSED [ 39%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-1-1-value_target_unit3-ValSplitByType.TRIAL] PASSED [ 39%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-1-1-value_target_unit3-ValSplitByType.SUBJECT] PASSED [ 39%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-1.0-1.0-value_target_unit4-SplitByType.DISABLE] PASSED [ 39%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-1.0-1.0-value_target_unit4-SplitByType.SESSION] PASSED [ 39%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-1.0-1.0-value_target_unit4-SplitByType.SESSION_IND] PASSED [ 39%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-1.0-1.0-value_target_unit4-SplitByType.TRIAL] PASSED [ 39%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-1.0-1.0-value_target_unit4-SplitByType.TRIAL_IND] PASSED [ 40%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-1.0-1.0-value_target_unit4-SplitByType.SUBJECT] PASSED [ 40%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-1.0-1.0-value_target_unit4-SplitByType.SUBJECT_IND] PASSED [ 40%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-1.0-1.0-value_target_unit4-ValSplitByType.DISABLE] PASSED [ 40%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-1.0-1.0-value_target_unit4-ValSplitByType.SESSION] PASSED [ 40%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-1.0-1.0-value_target_unit4-ValSplitByType.TRIAL] PASSED [ 40%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-1.0-1.0-value_target_unit4-ValSplitByType.SUBJECT] PASSED [ 40%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1.5-value_target_unit5-SplitByType.DISABLE] PASSED [ 40%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1.5-value_target_unit5-SplitByType.SESSION] PASSED [ 40%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1.5-value_target_unit5-SplitByType.SESSION_IND] PASSED [ 40%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1.5-value_target_unit5-SplitByType.TRIAL] PASSED [ 40%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1.5-value_target_unit5-SplitByType.TRIAL_IND] PASSED [ 40%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1.5-value_target_unit5-SplitByType.SUBJECT] PASSED [ 40%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1.5-value_target_unit5-SplitByType.SUBJECT_IND] PASSED [ 40%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1.5-value_target_unit5-ValSplitByType.DISABLE] PASSED [ 40%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1.5-value_target_unit5-ValSplitByType.SESSION] PASSED [ 40%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1.5-value_target_unit5-ValSplitByType.TRIAL] PASSED [ 40%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1.5-value_target_unit5-ValSplitByType.SUBJECT] PASSED [ 40%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-2-2-value_target_unit6-SplitByType.DISABLE] PASSED [ 40%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-2-2-value_target_unit6-SplitByType.SESSION] PASSED [ 40%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-2-2-value_target_unit6-SplitByType.SESSION_IND] PASSED [ 40%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-2-2-value_target_unit6-SplitByType.TRIAL] PASSED [ 41%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-2-2-value_target_unit6-SplitByType.TRIAL_IND] PASSED [ 41%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-2-2-value_target_unit6-SplitByType.SUBJECT] PASSED [ 41%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-2-2-value_target_unit6-SplitByType.SUBJECT_IND] PASSED [ 41%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-2-2-value_target_unit6-ValSplitByType.DISABLE] PASSED [ 41%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-2-2-value_target_unit6-ValSplitByType.SESSION] PASSED [ 41%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-2-2-value_target_unit6-ValSplitByType.TRIAL] PASSED [ 41%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-2-2-value_target_unit6-ValSplitByType.SUBJECT] PASSED [ 41%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-2.0-value_target_unit7-SplitByType.DISABLE] PASSED [ 41%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-2.0-value_target_unit7-SplitByType.SESSION] PASSED [ 41%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-2.0-value_target_unit7-SplitByType.SESSION_IND] PASSED [ 41%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-2.0-value_target_unit7-SplitByType.TRIAL] PASSED [ 41%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-2.0-value_target_unit7-SplitByType.TRIAL_IND] PASSED [ 41%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-2.0-value_target_unit7-SplitByType.SUBJECT] PASSED [ 41%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-2.0-value_target_unit7-SplitByType.SUBJECT_IND] PASSED [ 41%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-2.0-value_target_unit7-ValSplitByType.DISABLE] PASSED [ 41%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-2.0-value_target_unit7-ValSplitByType.SESSION] PASSED [ 41%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-2.0-value_target_unit7-ValSplitByType.TRIAL] PASSED [ 41%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-2.0-value_target_unit7-ValSplitByType.SUBJECT] PASSED [ 41%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-2.0 -value_target_unit8-SplitByType.DISABLE] PASSED [ 41%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-2.0 -value_target_unit8-SplitByType.SESSION] PASSED [ 42%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-2.0 -value_target_unit8-SplitByType.SESSION_IND] PASSED [ 42%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-2.0 -value_target_unit8-SplitByType.TRIAL] PASSED [ 42%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-2.0 -value_target_unit8-SplitByType.TRIAL_IND] PASSED [ 42%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-2.0 -value_target_unit8-SplitByType.SUBJECT] PASSED [ 42%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-2.0 -value_target_unit8-SplitByType.SUBJECT_IND] PASSED [ 42%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-2.0 -value_target_unit8-ValSplitByType.DISABLE] PASSED [ 42%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-2.0 -value_target_unit8-ValSplitByType.SESSION] PASSED [ 42%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-2.0 -value_target_unit8-ValSplitByType.TRIAL] PASSED [ 42%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-2.0 -value_target_unit8-ValSplitByType.SUBJECT] PASSED [ 42%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-parsed_value9-2 -value_target_unit9-SplitByType.DISABLE] PASSED [ 42%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-parsed_value9-2 -value_target_unit9-SplitByType.SESSION] PASSED [ 42%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-parsed_value9-2 -value_target_unit9-SplitByType.SESSION_IND] PASSED [ 42%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-parsed_value9-2 -value_target_unit9-SplitByType.TRIAL] PASSED [ 42%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-parsed_value9-2 -value_target_unit9-SplitByType.TRIAL_IND] PASSED [ 42%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-parsed_value9-2 -value_target_unit9-SplitByType.SUBJECT] PASSED [ 42%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-parsed_value9-2 -value_target_unit9-SplitByType.SUBJECT_IND] PASSED [ 42%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-parsed_value9-2 -value_target_unit9-ValSplitByType.DISABLE] PASSED [ 42%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-parsed_value9-2 -value_target_unit9-ValSplitByType.SESSION] PASSED [ 42%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-parsed_value9-2 -value_target_unit9-ValSplitByType.TRIAL] PASSED [ 42%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-parsed_value9-2 -value_target_unit9-ValSplitByType.SUBJECT] PASSED [ 43%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1-value_target_unit10-SplitByType.DISABLE] PASSED [ 43%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1-value_target_unit10-SplitByType.SESSION] PASSED [ 43%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1-value_target_unit10-SplitByType.SESSION_IND] PASSED [ 43%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1-value_target_unit10-SplitByType.TRIAL] PASSED [ 43%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1-value_target_unit10-SplitByType.TRIAL_IND] PASSED [ 43%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1-value_target_unit10-SplitByType.SUBJECT] PASSED [ 43%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1-value_target_unit10-SplitByType.SUBJECT_IND] PASSED [ 43%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1-value_target_unit10-ValSplitByType.DISABLE] PASSED [ 43%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1-value_target_unit10-ValSplitByType.SESSION] PASSED [ 43%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1-value_target_unit10-ValSplitByType.TRIAL] PASSED [ 43%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1-value_target_unit10-ValSplitByType.SUBJECT] PASSED [ 43%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1 -value_target_unit11-SplitByType.DISABLE] PASSED [ 43%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1 -value_target_unit11-SplitByType.SESSION] PASSED [ 43%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1 -value_target_unit11-SplitByType.SESSION_IND] PASSED [ 43%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1 -value_target_unit11-SplitByType.TRIAL] PASSED [ 43%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1 -value_target_unit11-SplitByType.TRIAL_IND] PASSED [ 43%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1 -value_target_unit11-SplitByType.SUBJECT] PASSED [ 43%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1 -value_target_unit11-SplitByType.SUBJECT_IND] PASSED [ 43%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1 -value_target_unit11-ValSplitByType.DISABLE] PASSED [ 43%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1 -value_target_unit11-ValSplitByType.SESSION] PASSED [ 44%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1 -value_target_unit11-ValSplitByType.TRIAL] PASSED [ 44%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1 -value_target_unit11-ValSplitByType.SUBJECT] PASSED [ 44%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.0-value_target_unit12-SplitByType.DISABLE] PASSED [ 44%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.0-value_target_unit12-SplitByType.SESSION] PASSED [ 44%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.0-value_target_unit12-SplitByType.SESSION_IND] PASSED [ 44%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.0-value_target_unit12-SplitByType.TRIAL] PASSED [ 44%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.0-value_target_unit12-SplitByType.TRIAL_IND] PASSED [ 44%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.0-value_target_unit12-SplitByType.SUBJECT] PASSED [ 44%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.0-value_target_unit12-SplitByType.SUBJECT_IND] PASSED [ 44%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.0-value_target_unit12-ValSplitByType.DISABLE] PASSED [ 44%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.0-value_target_unit12-ValSplitByType.SESSION] PASSED [ 44%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.0-value_target_unit12-ValSplitByType.TRIAL] PASSED [ 44%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.0-value_target_unit12-ValSplitByType.SUBJECT] PASSED [ 44%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.0 -value_target_unit13-SplitByType.DISABLE] PASSED [ 44%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.0 -value_target_unit13-SplitByType.SESSION] PASSED [ 44%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.0 -value_target_unit13-SplitByType.SESSION_IND] PASSED [ 44%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.0 -value_target_unit13-SplitByType.TRIAL] PASSED [ 44%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.0 -value_target_unit13-SplitByType.TRIAL_IND] PASSED [ 44%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.0 -value_target_unit13-SplitByType.SUBJECT] PASSED [ 44%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.0 -value_target_unit13-SplitByType.SUBJECT_IND] PASSED [ 45%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.0 -value_target_unit13-ValSplitByType.DISABLE] PASSED [ 45%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.0 -value_target_unit13-ValSplitByType.SESSION] PASSED [ 45%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.0 -value_target_unit13-ValSplitByType.TRIAL] PASSED [ 45%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.0 -value_target_unit13-ValSplitByType.SUBJECT] PASSED [ 45%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.5-value_target_unit14-SplitByType.DISABLE] PASSED [ 45%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.5-value_target_unit14-SplitByType.SESSION] PASSED [ 45%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.5-value_target_unit14-SplitByType.SESSION_IND] PASSED [ 45%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.5-value_target_unit14-SplitByType.TRIAL] PASSED [ 45%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.5-value_target_unit14-SplitByType.TRIAL_IND] PASSED [ 45%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.5-value_target_unit14-SplitByType.SUBJECT] PASSED [ 45%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.5-value_target_unit14-SplitByType.SUBJECT_IND] PASSED [ 45%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.5-value_target_unit14-ValSplitByType.DISABLE] PASSED [ 45%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.5-value_target_unit14-ValSplitByType.SESSION] PASSED [ 45%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.5-value_target_unit14-ValSplitByType.TRIAL] PASSED [ 45%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.5-value_target_unit14-ValSplitByType.SUBJECT] PASSED [ 45%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.5 -value_target_unit15-SplitByType.DISABLE] PASSED [ 45%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.5 -value_target_unit15-SplitByType.SESSION] PASSED [ 45%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.5 -value_target_unit15-SplitByType.SESSION_IND] PASSED [ 45%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.5 -value_target_unit15-SplitByType.TRIAL] PASSED [ 45%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.5 -value_target_unit15-SplitByType.TRIAL_IND] PASSED [ 45%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.5 -value_target_unit15-SplitByType.SUBJECT] PASSED [ 46%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.5 -value_target_unit15-SplitByType.SUBJECT_IND] PASSED [ 46%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.5 -value_target_unit15-ValSplitByType.DISABLE] PASSED [ 46%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.5 -value_target_unit15-ValSplitByType.SESSION] PASSED [ 46%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.5 -value_target_unit15-ValSplitByType.TRIAL] PASSED [ 46%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None--1.5 -value_target_unit15-ValSplitByType.SUBJECT] PASSED [ 46%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-parsed_value16-1 2 3-value_target_unit16-SplitByType.DISABLE] PASSED [ 46%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-parsed_value16-1 2 3-value_target_unit16-SplitByType.SESSION] PASSED [ 46%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-parsed_value16-1 2 3-value_target_unit16-SplitByType.SESSION_IND] PASSED [ 46%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-parsed_value16-1 2 3-value_target_unit16-SplitByType.TRIAL] PASSED [ 46%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-parsed_value16-1 2 3-value_target_unit16-SplitByType.TRIAL_IND] PASSED [ 46%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-parsed_value16-1 2 3-value_target_unit16-SplitByType.SUBJECT] PASSED [ 46%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-parsed_value16-1 2 3-value_target_unit16-SplitByType.SUBJECT_IND] PASSED [ 46%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-parsed_value16-1 2 3-value_target_unit16-ValSplitByType.DISABLE] PASSED [ 46%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-parsed_value16-1 2 3-value_target_unit16-ValSplitByType.SESSION] PASSED [ 46%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-parsed_value16-1 2 3-value_target_unit16-ValSplitByType.TRIAL] PASSED [ 46%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-parsed_value16-1 2 3-value_target_unit16-ValSplitByType.SUBJECT] PASSED [ 46%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 2 -3-value_target_unit17-SplitByType.DISABLE] PASSED [ 46%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 2 -3-value_target_unit17-SplitByType.SESSION] PASSED [ 46%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 2 -3-value_target_unit17-SplitByType.SESSION_IND] PASSED [ 46%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 2 -3-value_target_unit17-SplitByType.TRIAL] PASSED [ 47%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 2 -3-value_target_unit17-SplitByType.TRIAL_IND] PASSED [ 47%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 2 -3-value_target_unit17-SplitByType.SUBJECT] PASSED [ 47%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 2 -3-value_target_unit17-SplitByType.SUBJECT_IND] PASSED [ 47%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 2 -3-value_target_unit17-ValSplitByType.DISABLE] PASSED [ 47%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 2 -3-value_target_unit17-ValSplitByType.SESSION] PASSED [ 47%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 2 -3-value_target_unit17-ValSplitByType.TRIAL] PASSED [ 47%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 2 -3-value_target_unit17-ValSplitByType.SUBJECT] PASSED [ 47%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 2 0.3-value_target_unit18-SplitByType.DISABLE] PASSED [ 47%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 2 0.3-value_target_unit18-SplitByType.SESSION] PASSED [ 47%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 2 0.3-value_target_unit18-SplitByType.SESSION_IND] PASSED [ 47%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 2 0.3-value_target_unit18-SplitByType.TRIAL] PASSED [ 47%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 2 0.3-value_target_unit18-SplitByType.TRIAL_IND] PASSED [ 47%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 2 0.3-value_target_unit18-SplitByType.SUBJECT] PASSED [ 47%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 2 0.3-value_target_unit18-SplitByType.SUBJECT_IND] PASSED [ 47%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 2 0.3-value_target_unit18-ValSplitByType.DISABLE] PASSED [ 47%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 2 0.3-value_target_unit18-ValSplitByType.SESSION] PASSED [ 47%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 2 0.3-value_target_unit18-ValSplitByType.TRIAL] PASSED [ 47%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 2 0.3-value_target_unit18-ValSplitByType.SUBJECT] PASSED [ 47%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-e-value_target_unit19-SplitByType.DISABLE] PASSED [ 47%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-e-value_target_unit19-SplitByType.SESSION] PASSED [ 48%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-e-value_target_unit19-SplitByType.SESSION_IND] PASSED [ 48%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-e-value_target_unit19-SplitByType.TRIAL] PASSED [ 48%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-e-value_target_unit19-SplitByType.TRIAL_IND] PASSED [ 48%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-e-value_target_unit19-SplitByType.SUBJECT] PASSED [ 48%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-e-value_target_unit19-SplitByType.SUBJECT_IND] PASSED [ 48%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-e-value_target_unit19-ValSplitByType.DISABLE] PASSED [ 48%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-e-value_target_unit19-ValSplitByType.SESSION] PASSED [ 48%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-e-value_target_unit19-ValSplitByType.TRIAL] PASSED [ 48%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-e-value_target_unit19-ValSplitByType.SUBJECT] PASSED [ 48%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-e -value_target_unit20-SplitByType.DISABLE] PASSED [ 48%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-e -value_target_unit20-SplitByType.SESSION] PASSED [ 48%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-e -value_target_unit20-SplitByType.SESSION_IND] PASSED [ 48%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-e -value_target_unit20-SplitByType.TRIAL] PASSED [ 48%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-e -value_target_unit20-SplitByType.TRIAL_IND] PASSED [ 48%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-e -value_target_unit20-SplitByType.SUBJECT] PASSED [ 48%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-e -value_target_unit20-SplitByType.SUBJECT_IND] PASSED [ 48%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-e -value_target_unit20-ValSplitByType.DISABLE] PASSED [ 48%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-e -value_target_unit20-ValSplitByType.SESSION] PASSED [ 48%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-e -value_target_unit20-ValSplitByType.TRIAL] PASSED [ 48%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-e -value_target_unit20-ValSplitByType.SUBJECT] PASSED [ 49%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 e-value_target_unit21-SplitByType.DISABLE] PASSED [ 49%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 e-value_target_unit21-SplitByType.SESSION] PASSED [ 49%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 e-value_target_unit21-SplitByType.SESSION_IND] PASSED [ 49%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 e-value_target_unit21-SplitByType.TRIAL] PASSED [ 49%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 e-value_target_unit21-SplitByType.TRIAL_IND] PASSED [ 49%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 e-value_target_unit21-SplitByType.SUBJECT] PASSED [ 49%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 e-value_target_unit21-SplitByType.SUBJECT_IND] PASSED [ 49%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 e-value_target_unit21-ValSplitByType.DISABLE] PASSED [ 49%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 e-value_target_unit21-ValSplitByType.SESSION] PASSED [ 49%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 e-value_target_unit21-ValSplitByType.TRIAL] PASSED [ 49%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-1 e-value_target_unit21-ValSplitByType.SUBJECT] PASSED [ 49%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-None-value_target_unit22-SplitByType.DISABLE] PASSED [ 49%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-None-value_target_unit22-SplitByType.SESSION] PASSED [ 49%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-None-value_target_unit22-SplitByType.SESSION_IND] PASSED [ 49%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-None-value_target_unit22-SplitByType.TRIAL] PASSED [ 49%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-None-value_target_unit22-SplitByType.TRIAL_IND] PASSED [ 49%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-None-value_target_unit22-SplitByType.SUBJECT] PASSED [ 49%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-None-value_target_unit22-SplitByType.SUBJECT_IND] PASSED [ 49%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-None-value_target_unit22-ValSplitByType.DISABLE] PASSED [ 49%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-None-value_target_unit22-ValSplitByType.SESSION] PASSED [ 50%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-None-value_target_unit22-ValSplitByType.TRIAL] PASSED [ 50%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[SplitUnit.KFOLD-None-None-value_target_unit22-ValSplitByType.SUBJECT] PASSED [ 50%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0-0-value_target_unit0-SplitByType.DISABLE] PASSED [ 50%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0-0-value_target_unit0-SplitByType.SESSION] PASSED [ 50%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0-0-value_target_unit0-SplitByType.SESSION_IND] PASSED [ 50%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0-0-value_target_unit0-SplitByType.TRIAL] PASSED [ 50%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0-0-value_target_unit0-SplitByType.TRIAL_IND] PASSED [ 50%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0-0-value_target_unit0-SplitByType.SUBJECT] PASSED [ 50%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0-0-value_target_unit0-SplitByType.SUBJECT_IND] PASSED [ 50%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0-0-value_target_unit0-ValSplitByType.DISABLE] PASSED [ 50%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0-0-value_target_unit0-ValSplitByType.SESSION] PASSED [ 50%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0-0-value_target_unit0-ValSplitByType.TRIAL] PASSED [ 50%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0-0-value_target_unit0-ValSplitByType.SUBJECT] PASSED [ 50%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0.0-0.0-value_target_unit1-SplitByType.DISABLE] PASSED [ 50%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0.0-0.0-value_target_unit1-SplitByType.SESSION] PASSED [ 50%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0.0-0.0-value_target_unit1-SplitByType.SESSION_IND] PASSED [ 50%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0.0-0.0-value_target_unit1-SplitByType.TRIAL] PASSED [ 50%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0.0-0.0-value_target_unit1-SplitByType.TRIAL_IND] PASSED [ 50%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0.0-0.0-value_target_unit1-SplitByType.SUBJECT] PASSED [ 50%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0.0-0.0-value_target_unit1-SplitByType.SUBJECT_IND] PASSED [ 50%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0.0-0.0-value_target_unit1-ValSplitByType.DISABLE] PASSED [ 51%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0.0-0.0-value_target_unit1-ValSplitByType.SESSION] PASSED [ 51%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0.0-0.0-value_target_unit1-ValSplitByType.TRIAL] PASSED [ 51%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0.0-0.0-value_target_unit1-ValSplitByType.SUBJECT] PASSED [ 51%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0.3-0.3-value_target_unit2-SplitByType.DISABLE] PASSED [ 51%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0.3-0.3-value_target_unit2-SplitByType.SESSION] PASSED [ 51%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0.3-0.3-value_target_unit2-SplitByType.SESSION_IND] PASSED [ 51%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0.3-0.3-value_target_unit2-SplitByType.TRIAL] PASSED [ 51%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0.3-0.3-value_target_unit2-SplitByType.TRIAL_IND] PASSED [ 51%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0.3-0.3-value_target_unit2-SplitByType.SUBJECT] PASSED [ 51%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0.3-0.3-value_target_unit2-SplitByType.SUBJECT_IND] PASSED [ 51%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0.3-0.3-value_target_unit2-ValSplitByType.DISABLE] PASSED [ 51%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0.3-0.3-value_target_unit2-ValSplitByType.SESSION] PASSED [ 51%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0.3-0.3-value_target_unit2-ValSplitByType.TRIAL] PASSED [ 51%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-0.3-0.3-value_target_unit2-ValSplitByType.SUBJECT] PASSED [ 51%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-1-1-value_target_unit3-SplitByType.DISABLE] PASSED [ 51%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-1-1-value_target_unit3-SplitByType.SESSION] PASSED [ 51%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-1-1-value_target_unit3-SplitByType.SESSION_IND] PASSED [ 51%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-1-1-value_target_unit3-SplitByType.TRIAL] PASSED [ 51%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-1-1-value_target_unit3-SplitByType.TRIAL_IND] PASSED [ 51%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-1-1-value_target_unit3-SplitByType.SUBJECT] PASSED [ 52%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-1-1-value_target_unit3-SplitByType.SUBJECT_IND] PASSED [ 52%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-1-1-value_target_unit3-ValSplitByType.DISABLE] PASSED [ 52%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-1-1-value_target_unit3-ValSplitByType.SESSION] PASSED [ 52%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-1-1-value_target_unit3-ValSplitByType.TRIAL] PASSED [ 52%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-1-1-value_target_unit3-ValSplitByType.SUBJECT] PASSED [ 52%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-1.0-1.0-value_target_unit4-SplitByType.DISABLE] PASSED [ 52%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-1.0-1.0-value_target_unit4-SplitByType.SESSION] PASSED [ 52%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-1.0-1.0-value_target_unit4-SplitByType.SESSION_IND] PASSED [ 52%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-1.0-1.0-value_target_unit4-SplitByType.TRIAL] PASSED [ 52%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-1.0-1.0-value_target_unit4-SplitByType.TRIAL_IND] PASSED [ 52%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-1.0-1.0-value_target_unit4-SplitByType.SUBJECT] PASSED [ 52%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-1.0-1.0-value_target_unit4-SplitByType.SUBJECT_IND] PASSED [ 52%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-1.0-1.0-value_target_unit4-ValSplitByType.DISABLE] PASSED [ 52%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-1.0-1.0-value_target_unit4-ValSplitByType.SESSION] PASSED [ 52%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-1.0-1.0-value_target_unit4-ValSplitByType.TRIAL] PASSED [ 52%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-1.0-1.0-value_target_unit4-ValSplitByType.SUBJECT] PASSED [ 52%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1.5-value_target_unit5-SplitByType.DISABLE] PASSED [ 52%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1.5-value_target_unit5-SplitByType.SESSION] PASSED [ 52%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1.5-value_target_unit5-SplitByType.SESSION_IND] PASSED [ 52%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1.5-value_target_unit5-SplitByType.TRIAL] PASSED [ 53%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1.5-value_target_unit5-SplitByType.TRIAL_IND] PASSED [ 53%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1.5-value_target_unit5-SplitByType.SUBJECT] PASSED [ 53%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1.5-value_target_unit5-SplitByType.SUBJECT_IND] PASSED [ 53%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1.5-value_target_unit5-ValSplitByType.DISABLE] PASSED [ 53%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1.5-value_target_unit5-ValSplitByType.SESSION] PASSED [ 53%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1.5-value_target_unit5-ValSplitByType.TRIAL] PASSED [ 53%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1.5-value_target_unit5-ValSplitByType.SUBJECT] PASSED [ 53%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-2-2-value_target_unit6-SplitByType.DISABLE] PASSED [ 53%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-2-2-value_target_unit6-SplitByType.SESSION] PASSED [ 53%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-2-2-value_target_unit6-SplitByType.SESSION_IND] PASSED [ 53%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-2-2-value_target_unit6-SplitByType.TRIAL] PASSED [ 53%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-2-2-value_target_unit6-SplitByType.TRIAL_IND] PASSED [ 53%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-2-2-value_target_unit6-SplitByType.SUBJECT] PASSED [ 53%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-2-2-value_target_unit6-SplitByType.SUBJECT_IND] PASSED [ 53%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-2-2-value_target_unit6-ValSplitByType.DISABLE] PASSED [ 53%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-2-2-value_target_unit6-ValSplitByType.SESSION] PASSED [ 53%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-2-2-value_target_unit6-ValSplitByType.TRIAL] PASSED [ 53%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-2-2-value_target_unit6-ValSplitByType.SUBJECT] PASSED [ 53%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-2.0-value_target_unit7-SplitByType.DISABLE] PASSED [ 53%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-2.0-value_target_unit7-SplitByType.SESSION] PASSED [ 54%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-2.0-value_target_unit7-SplitByType.SESSION_IND] PASSED [ 54%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-2.0-value_target_unit7-SplitByType.TRIAL] PASSED [ 54%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-2.0-value_target_unit7-SplitByType.TRIAL_IND] PASSED [ 54%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-2.0-value_target_unit7-SplitByType.SUBJECT] PASSED [ 54%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-2.0-value_target_unit7-SplitByType.SUBJECT_IND] PASSED [ 54%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-2.0-value_target_unit7-ValSplitByType.DISABLE] PASSED [ 54%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-2.0-value_target_unit7-ValSplitByType.SESSION] PASSED [ 54%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-2.0-value_target_unit7-ValSplitByType.TRIAL] PASSED [ 54%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-2.0-value_target_unit7-ValSplitByType.SUBJECT] PASSED [ 54%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-2.0 -value_target_unit8-SplitByType.DISABLE] PASSED [ 54%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-2.0 -value_target_unit8-SplitByType.SESSION] PASSED [ 54%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-2.0 -value_target_unit8-SplitByType.SESSION_IND] PASSED [ 54%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-2.0 -value_target_unit8-SplitByType.TRIAL] PASSED [ 54%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-2.0 -value_target_unit8-SplitByType.TRIAL_IND] PASSED [ 54%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-2.0 -value_target_unit8-SplitByType.SUBJECT] PASSED [ 54%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-2.0 -value_target_unit8-SplitByType.SUBJECT_IND] PASSED [ 54%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-2.0 -value_target_unit8-ValSplitByType.DISABLE] PASSED [ 54%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-2.0 -value_target_unit8-ValSplitByType.SESSION] PASSED [ 54%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-2.0 -value_target_unit8-ValSplitByType.TRIAL] PASSED [ 54%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-2.0 -value_target_unit8-ValSplitByType.SUBJECT] PASSED [ 55%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-parsed_value9-2 -value_target_unit9-SplitByType.DISABLE] PASSED [ 55%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-parsed_value9-2 -value_target_unit9-SplitByType.SESSION] PASSED [ 55%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-parsed_value9-2 -value_target_unit9-SplitByType.SESSION_IND] PASSED [ 55%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-parsed_value9-2 -value_target_unit9-SplitByType.TRIAL] PASSED [ 55%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-parsed_value9-2 -value_target_unit9-SplitByType.TRIAL_IND] PASSED [ 55%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-parsed_value9-2 -value_target_unit9-SplitByType.SUBJECT] PASSED [ 55%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-parsed_value9-2 -value_target_unit9-SplitByType.SUBJECT_IND] PASSED [ 55%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-parsed_value9-2 -value_target_unit9-ValSplitByType.DISABLE] PASSED [ 55%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-parsed_value9-2 -value_target_unit9-ValSplitByType.SESSION] PASSED [ 55%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-parsed_value9-2 -value_target_unit9-ValSplitByType.TRIAL] PASSED [ 55%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-parsed_value9-2 -value_target_unit9-ValSplitByType.SUBJECT] PASSED [ 55%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1-value_target_unit10-SplitByType.DISABLE] PASSED [ 55%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1-value_target_unit10-SplitByType.SESSION] PASSED [ 55%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1-value_target_unit10-SplitByType.SESSION_IND] PASSED [ 55%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1-value_target_unit10-SplitByType.TRIAL] PASSED [ 55%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1-value_target_unit10-SplitByType.TRIAL_IND] PASSED [ 55%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1-value_target_unit10-SplitByType.SUBJECT] PASSED [ 55%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1-value_target_unit10-SplitByType.SUBJECT_IND] PASSED [ 55%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1-value_target_unit10-ValSplitByType.DISABLE] PASSED [ 55%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1-value_target_unit10-ValSplitByType.SESSION] PASSED [ 55%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1-value_target_unit10-ValSplitByType.TRIAL] PASSED [ 56%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1-value_target_unit10-ValSplitByType.SUBJECT] PASSED [ 56%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1 -value_target_unit11-SplitByType.DISABLE] PASSED [ 56%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1 -value_target_unit11-SplitByType.SESSION] PASSED [ 56%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1 -value_target_unit11-SplitByType.SESSION_IND] PASSED [ 56%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1 -value_target_unit11-SplitByType.TRIAL] PASSED [ 56%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1 -value_target_unit11-SplitByType.TRIAL_IND] PASSED [ 56%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1 -value_target_unit11-SplitByType.SUBJECT] PASSED [ 56%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1 -value_target_unit11-SplitByType.SUBJECT_IND] PASSED [ 56%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1 -value_target_unit11-ValSplitByType.DISABLE] PASSED [ 56%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1 -value_target_unit11-ValSplitByType.SESSION] PASSED [ 56%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1 -value_target_unit11-ValSplitByType.TRIAL] PASSED [ 56%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1 -value_target_unit11-ValSplitByType.SUBJECT] PASSED [ 56%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.0-value_target_unit12-SplitByType.DISABLE] PASSED [ 56%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.0-value_target_unit12-SplitByType.SESSION] PASSED [ 56%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.0-value_target_unit12-SplitByType.SESSION_IND] PASSED [ 56%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.0-value_target_unit12-SplitByType.TRIAL] PASSED [ 56%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.0-value_target_unit12-SplitByType.TRIAL_IND] PASSED [ 56%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.0-value_target_unit12-SplitByType.SUBJECT] PASSED [ 56%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.0-value_target_unit12-SplitByType.SUBJECT_IND] PASSED [ 56%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.0-value_target_unit12-ValSplitByType.DISABLE] PASSED [ 57%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.0-value_target_unit12-ValSplitByType.SESSION] PASSED [ 57%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.0-value_target_unit12-ValSplitByType.TRIAL] PASSED [ 57%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.0-value_target_unit12-ValSplitByType.SUBJECT] PASSED [ 57%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.0 -value_target_unit13-SplitByType.DISABLE] PASSED [ 57%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.0 -value_target_unit13-SplitByType.SESSION] PASSED [ 57%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.0 -value_target_unit13-SplitByType.SESSION_IND] PASSED [ 57%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.0 -value_target_unit13-SplitByType.TRIAL] PASSED [ 57%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.0 -value_target_unit13-SplitByType.TRIAL_IND] PASSED [ 57%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.0 -value_target_unit13-SplitByType.SUBJECT] PASSED [ 57%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.0 -value_target_unit13-SplitByType.SUBJECT_IND] PASSED [ 57%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.0 -value_target_unit13-ValSplitByType.DISABLE] PASSED [ 57%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.0 -value_target_unit13-ValSplitByType.SESSION] PASSED [ 57%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.0 -value_target_unit13-ValSplitByType.TRIAL] PASSED [ 57%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.0 -value_target_unit13-ValSplitByType.SUBJECT] PASSED [ 57%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.5-value_target_unit14-SplitByType.DISABLE] PASSED [ 57%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.5-value_target_unit14-SplitByType.SESSION] PASSED [ 57%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.5-value_target_unit14-SplitByType.SESSION_IND] PASSED [ 57%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.5-value_target_unit14-SplitByType.TRIAL] PASSED [ 57%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.5-value_target_unit14-SplitByType.TRIAL_IND] PASSED [ 57%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.5-value_target_unit14-SplitByType.SUBJECT] PASSED [ 58%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.5-value_target_unit14-SplitByType.SUBJECT_IND] PASSED [ 58%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.5-value_target_unit14-ValSplitByType.DISABLE] PASSED [ 58%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.5-value_target_unit14-ValSplitByType.SESSION] PASSED [ 58%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.5-value_target_unit14-ValSplitByType.TRIAL] PASSED [ 58%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.5-value_target_unit14-ValSplitByType.SUBJECT] PASSED [ 58%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.5 -value_target_unit15-SplitByType.DISABLE] PASSED [ 58%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.5 -value_target_unit15-SplitByType.SESSION] PASSED [ 58%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.5 -value_target_unit15-SplitByType.SESSION_IND] PASSED [ 58%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.5 -value_target_unit15-SplitByType.TRIAL] PASSED [ 58%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.5 -value_target_unit15-SplitByType.TRIAL_IND] PASSED [ 58%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.5 -value_target_unit15-SplitByType.SUBJECT] PASSED [ 58%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.5 -value_target_unit15-SplitByType.SUBJECT_IND] PASSED [ 58%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.5 -value_target_unit15-ValSplitByType.DISABLE] PASSED [ 58%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.5 -value_target_unit15-ValSplitByType.SESSION] PASSED [ 58%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.5 -value_target_unit15-ValSplitByType.TRIAL] PASSED [ 58%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None--1.5 -value_target_unit15-ValSplitByType.SUBJECT] PASSED [ 58%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-parsed_value16-1 2 3-value_target_unit16-SplitByType.DISABLE] PASSED [ 58%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-parsed_value16-1 2 3-value_target_unit16-SplitByType.SESSION] PASSED [ 58%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-parsed_value16-1 2 3-value_target_unit16-SplitByType.SESSION_IND] PASSED [ 58%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-parsed_value16-1 2 3-value_target_unit16-SplitByType.TRIAL] PASSED [ 59%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-parsed_value16-1 2 3-value_target_unit16-SplitByType.TRIAL_IND] PASSED [ 59%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-parsed_value16-1 2 3-value_target_unit16-SplitByType.SUBJECT] PASSED [ 59%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-parsed_value16-1 2 3-value_target_unit16-SplitByType.SUBJECT_IND] PASSED [ 59%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-parsed_value16-1 2 3-value_target_unit16-ValSplitByType.DISABLE] PASSED [ 59%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-parsed_value16-1 2 3-value_target_unit16-ValSplitByType.SESSION] PASSED [ 59%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-parsed_value16-1 2 3-value_target_unit16-ValSplitByType.TRIAL] PASSED [ 59%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-parsed_value16-1 2 3-value_target_unit16-ValSplitByType.SUBJECT] PASSED [ 59%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 2 -3-value_target_unit17-SplitByType.DISABLE] PASSED [ 59%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 2 -3-value_target_unit17-SplitByType.SESSION] PASSED [ 59%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 2 -3-value_target_unit17-SplitByType.SESSION_IND] PASSED [ 59%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 2 -3-value_target_unit17-SplitByType.TRIAL] PASSED [ 59%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 2 -3-value_target_unit17-SplitByType.TRIAL_IND] PASSED [ 59%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 2 -3-value_target_unit17-SplitByType.SUBJECT] PASSED [ 59%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 2 -3-value_target_unit17-SplitByType.SUBJECT_IND] PASSED [ 59%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 2 -3-value_target_unit17-ValSplitByType.DISABLE] PASSED [ 59%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 2 -3-value_target_unit17-ValSplitByType.SESSION] PASSED [ 59%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 2 -3-value_target_unit17-ValSplitByType.TRIAL] PASSED [ 59%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 2 -3-value_target_unit17-ValSplitByType.SUBJECT] PASSED [ 59%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 2 0.3-value_target_unit18-SplitByType.DISABLE] PASSED [ 59%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 2 0.3-value_target_unit18-SplitByType.SESSION] PASSED [ 60%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 2 0.3-value_target_unit18-SplitByType.SESSION_IND] PASSED [ 60%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 2 0.3-value_target_unit18-SplitByType.TRIAL] PASSED [ 60%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 2 0.3-value_target_unit18-SplitByType.TRIAL_IND] PASSED [ 60%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 2 0.3-value_target_unit18-SplitByType.SUBJECT] PASSED [ 60%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 2 0.3-value_target_unit18-SplitByType.SUBJECT_IND] PASSED [ 60%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 2 0.3-value_target_unit18-ValSplitByType.DISABLE] PASSED [ 60%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 2 0.3-value_target_unit18-ValSplitByType.SESSION] PASSED [ 60%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 2 0.3-value_target_unit18-ValSplitByType.TRIAL] PASSED [ 60%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 2 0.3-value_target_unit18-ValSplitByType.SUBJECT] PASSED [ 60%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-e-value_target_unit19-SplitByType.DISABLE] PASSED [ 60%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-e-value_target_unit19-SplitByType.SESSION] PASSED [ 60%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-e-value_target_unit19-SplitByType.SESSION_IND] PASSED [ 60%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-e-value_target_unit19-SplitByType.TRIAL] PASSED [ 60%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-e-value_target_unit19-SplitByType.TRIAL_IND] PASSED [ 60%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-e-value_target_unit19-SplitByType.SUBJECT] PASSED [ 60%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-e-value_target_unit19-SplitByType.SUBJECT_IND] PASSED [ 60%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-e-value_target_unit19-ValSplitByType.DISABLE] PASSED [ 60%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-e-value_target_unit19-ValSplitByType.SESSION] PASSED [ 60%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-e-value_target_unit19-ValSplitByType.TRIAL] PASSED [ 60%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-e-value_target_unit19-ValSplitByType.SUBJECT] PASSED [ 60%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-e -value_target_unit20-SplitByType.DISABLE] PASSED [ 61%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-e -value_target_unit20-SplitByType.SESSION] PASSED [ 61%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-e -value_target_unit20-SplitByType.SESSION_IND] PASSED [ 61%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-e -value_target_unit20-SplitByType.TRIAL] PASSED [ 61%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-e -value_target_unit20-SplitByType.TRIAL_IND] PASSED [ 61%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-e -value_target_unit20-SplitByType.SUBJECT] PASSED [ 61%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-e -value_target_unit20-SplitByType.SUBJECT_IND] PASSED [ 61%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-e -value_target_unit20-ValSplitByType.DISABLE] PASSED [ 61%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-e -value_target_unit20-ValSplitByType.SESSION] PASSED [ 61%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-e -value_target_unit20-ValSplitByType.TRIAL] PASSED [ 61%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-e -value_target_unit20-ValSplitByType.SUBJECT] PASSED [ 61%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 e-value_target_unit21-SplitByType.DISABLE] PASSED [ 61%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 e-value_target_unit21-SplitByType.SESSION] PASSED [ 61%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 e-value_target_unit21-SplitByType.SESSION_IND] PASSED [ 61%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 e-value_target_unit21-SplitByType.TRIAL] PASSED [ 61%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 e-value_target_unit21-SplitByType.TRIAL_IND] PASSED [ 61%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 e-value_target_unit21-SplitByType.SUBJECT] PASSED [ 61%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 e-value_target_unit21-SplitByType.SUBJECT_IND] PASSED [ 61%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 e-value_target_unit21-ValSplitByType.DISABLE] PASSED [ 61%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 e-value_target_unit21-ValSplitByType.SESSION] PASSED [ 61%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 e-value_target_unit21-ValSplitByType.TRIAL] PASSED [ 62%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-1 e-value_target_unit21-ValSplitByType.SUBJECT] PASSED [ 62%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-None-value_target_unit22-SplitByType.DISABLE] PASSED [ 62%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-None-value_target_unit22-SplitByType.SESSION] PASSED [ 62%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-None-value_target_unit22-SplitByType.SESSION_IND] PASSED [ 62%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-None-value_target_unit22-SplitByType.TRIAL] PASSED [ 62%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-None-value_target_unit22-SplitByType.TRIAL_IND] PASSED [ 62%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-None-value_target_unit22-SplitByType.SUBJECT] PASSED [ 62%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-None-value_target_unit22-SplitByType.SUBJECT_IND] PASSED [ 62%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-None-value_target_unit22-ValSplitByType.DISABLE] PASSED [ 62%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-None-value_target_unit22-ValSplitByType.SESSION] PASSED [ 62%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-None-value_target_unit22-ValSplitByType.TRIAL] PASSED [ 62%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter[None-None-None-value_target_unit22-ValSplitByType.SUBJECT] PASSED [ 62%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter_not_implemented[SplitUnit.RATIO] PASSED [ 62%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter_not_implemented[SplitUnit.NUMBER] PASSED [ 62%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter_not_implemented[SplitUnit.MANUAL] PASSED [ 62%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter_not_implemented[SplitUnit.KFOLD] PASSED [ 62%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter_not_implemented[test] PASSED [ 62%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_splitter_getter PASSED [ 62%]
XBrainLab/tests/backend/dataset/test_data_splitter.py::test_config PASSED [ 62%]
XBrainLab/tests/backend/dataset/test_dataset.py::test_dataset PASSED     [ 63%]
XBrainLab/tests/backend/dataset/test_dataset.py::test_dataset_set_test_mask FAILED [ 63%]
XBrainLab/tests/backend/dataset/test_dataset.py::test_dataset_discard PASSED [ 63%]
XBrainLab/tests/backend/dataset/test_dataset.py::test_dataset_set_remaining_by_subject_idx FAILED [ 63%]
XBrainLab/tests/backend/dataset/test_dataset.py::test_dataset_intersection_with_subject_by_idx[12-24_0] PASSED [ 63%]
XBrainLab/tests/backend/dataset/test_dataset.py::test_dataset_intersection_with_subject_by_idx[6-12] PASSED [ 63%]
XBrainLab/tests/backend/dataset/test_dataset.py::test_dataset_intersection_with_subject_by_idx[0-24] FAILED [ 63%]
XBrainLab/tests/backend/dataset/test_dataset.py::test_dataset_intersection_with_subject_by_idx[12-24_1] PASSED [ 63%]
XBrainLab/tests/backend/dataset/test_dataset.py::test_dataset_get_data FAILED [ 63%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator PASSED [ 63%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_test[SplitByType.SESSION-pick_session] FAILED [ 63%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_test[SplitByType.SESSION_IND-pick_session] FAILED [ 63%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_test[SplitByType.SUBJECT-pick_subject] FAILED [ 63%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_test[SplitByType.SUBJECT_IND-pick_subject] FAILED [ 63%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_test[SplitByType.TRIAL-pick_trial] FAILED [ 63%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_test[SplitByType.TRIAL_IND-pick_trial] FAILED [ 63%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_test_list[SplitByType.SESSION-pick_session] PASSED [ 63%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_test_list[SplitByType.SESSION_IND-pick_session] PASSED [ 63%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_test_list[SplitByType.SUBJECT-pick_subject] PASSED [ 63%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_test_list[SplitByType.SUBJECT_IND-pick_subject] PASSED [ 63%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_test_list[SplitByType.TRIAL-pick_trial] PASSED [ 64%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_test_list[SplitByType.TRIAL_IND-pick_trial] PASSED [ 64%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_test_empty PASSED [ 64%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_test_failed PASSED [ 64%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_test_interrupted PASSED [ 64%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_test_independent[get_subject_list-2-test_splitter_list0] PASSED [ 64%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_test_independent[get_session_list-1-test_splitter_list1] PASSED [ 64%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_test_not_implemented[error] PASSED [ 64%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_test_not_implemented[None] PASSED [ 64%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_validation[ValSplitByType.SESSION-pick_session] FAILED [ 64%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_validation[ValSplitByType.SUBJECT-pick_subject] FAILED [ 64%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_validation[ValSplitByType.TRIAL-pick_trial] FAILED [ 64%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_validation_failed PASSED [ 64%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_validation_not_implemented[error] PASSED [ 64%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_validation_not_implemented[None] PASSED [ 64%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_validation_interrupt PASSED [ 64%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_failed PASSED [ 64%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_name_prefix[handle_IND-Subject-] PASSED [ 64%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_name_prefix[handle_FULL-Group] PASSED [ 64%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_handle_individual FAILED [ 64%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_handle_individual_cross_validation FAILED [ 65%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_handle_full FAILED [ 65%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_handle_full_cross_validation FAILED [ 65%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_generate[datasets0-True-TrainingType.IND-handle_IND] PASSED [ 65%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_generate[datasets0-True-TrainingType.FULL-handle_FULL] PASSED [ 65%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_generate[datasets1-False-TrainingType.IND-handle_IND] PASSED [ 65%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_generate[datasets1-False-TrainingType.FULL-handle_FULL] PASSED [ 65%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_generate[datasets2-False-TrainingType.IND-handle_IND] PASSED [ 65%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_generate[datasets2-False-TrainingType.FULL-handle_FULL] PASSED [ 65%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_generate_not_implemented[error] PASSED [ 65%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_generate_not_implemented[None] PASSED [ 65%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_generate_exists[TrainingType.IND] PASSED [ 65%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_generate_exists[TrainingType.FULL] PASSED [ 65%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_prepare_reuslt[TrainingType.IND-datasets0-True] PASSED [ 65%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_prepare_reuslt[TrainingType.IND-datasets1-True] PASSED [ 65%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_prepare_reuslt[TrainingType.IND-datasets2-False] PASSED [ 65%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_prepare_reuslt[TrainingType.IND-datasets3-False] PASSED [ 65%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_prepare_reuslt[TrainingType.IND-datasets4-True] PASSED [ 65%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_prepare_reuslt[TrainingType.FULL-datasets0-True] PASSED [ 65%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_prepare_reuslt[TrainingType.FULL-datasets1-True] PASSED [ 65%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_prepare_reuslt[TrainingType.FULL-datasets2-False] PASSED [ 65%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_prepare_reuslt[TrainingType.FULL-datasets3-False] PASSED [ 66%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_prepare_reuslt[TrainingType.FULL-datasets4-True] PASSED [ 66%]
XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_apply PASSED [ 66%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_args_error PASSED [ 66%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_subject_attributes FAILED [ 66%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_session_attributes FAILED [ 66%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_label_attributes FAILED [ 66%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_copy PASSED  [ 66%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_by_mask FAILED [ 66%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_by_index FAILED [ 66%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_info FAILED  [ 66%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_set_channel PASSED [ 66%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_generate_mask_target ERROR [ 66%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_generate_mask_target_partial FAILED [ 66%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_filtered_mask_pair ERROR [ 66%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_update_mask_target ERROR [ 66%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num[mask0-None-1-SplitUnit.NUMBER-1] PASSED [ 66%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num[mask0-None-4-SplitUnit.NUMBER-4] PASSED [ 66%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num[mask0-None-200-SplitUnit.NUMBER-4] PASSED [ 66%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num[mask0-None-0.0-SplitUnit.RATIO-0] PASSED [ 66%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num[mask0-None-0.1-SplitUnit.RATIO-0] PASSED [ 67%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num[mask0-None-0.2-SplitUnit.RATIO-0] PASSED [ 67%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num[mask0-None-0.30000000000000004-SplitUnit.RATIO-1] PASSED [ 67%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num[mask0-None-0.4-SplitUnit.RATIO-1] PASSED [ 67%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num[mask0-None-0.5-SplitUnit.RATIO-2] PASSED [ 67%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num[mask0-None-0.6000000000000001-SplitUnit.RATIO-2] PASSED [ 67%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num[mask0-None-0.7000000000000001-SplitUnit.RATIO-2] PASSED [ 67%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num[mask0-None-0.8-SplitUnit.RATIO-3] PASSED [ 67%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num[mask0-None-0.9-SplitUnit.RATIO-3] PASSED [ 67%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num[mask1-clean_mask1-1-SplitUnit.NUMBER-1] PASSED [ 67%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num[mask1-clean_mask1-4-SplitUnit.NUMBER-4] PASSED [ 67%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num[mask1-clean_mask1-200-SplitUnit.NUMBER-4] PASSED [ 67%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num[mask1-clean_mask1-0.0-SplitUnit.RATIO-0] PASSED [ 67%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num[mask1-clean_mask1-0.1-SplitUnit.RATIO-0] PASSED [ 67%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num[mask1-clean_mask1-0.2-SplitUnit.RATIO-0] PASSED [ 67%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num[mask1-clean_mask1-0.30000000000000004-SplitUnit.RATIO-1] PASSED [ 67%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num[mask1-clean_mask1-0.4-SplitUnit.RATIO-1] PASSED [ 67%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num[mask1-clean_mask1-0.5-SplitUnit.RATIO-2] PASSED [ 67%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num[mask1-clean_mask1-0.6000000000000001-SplitUnit.RATIO-2] PASSED [ 67%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num[mask1-clean_mask1-0.7000000000000001-SplitUnit.RATIO-2] PASSED [ 67%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num[mask1-clean_mask1-0.8-SplitUnit.RATIO-3] PASSED [ 68%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num[mask1-clean_mask1-0.9-SplitUnit.RATIO-3] PASSED [ 68%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num_partial[1-SplitUnit.NUMBER-1] PASSED [ 68%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num_partial[4-SplitUnit.NUMBER-3] PASSED [ 68%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num_partial[200-SplitUnit.NUMBER-3] PASSED [ 68%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num_partial[0.0-SplitUnit.RATIO-0] PASSED [ 68%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num_partial[0.1-SplitUnit.RATIO-0] PASSED [ 68%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num_partial[0.2-SplitUnit.RATIO-0] PASSED [ 68%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num_partial[0.30000000000000004-SplitUnit.RATIO-0] PASSED [ 68%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num_partial[0.4-SplitUnit.RATIO-1] PASSED [ 68%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num_partial[0.5-SplitUnit.RATIO-1] PASSED [ 68%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num_partial[0.6000000000000001-SplitUnit.RATIO-1] PASSED [ 68%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num_partial[0.7000000000000001-SplitUnit.RATIO-2] PASSED [ 68%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num_partial[0.8-SplitUnit.RATIO-2] PASSED [ 68%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num_partial[0.9-SplitUnit.RATIO-2] PASSED [ 68%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num_k_fold[1-0-4-0] PASSED [ 68%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num_k_fold[2-0-2-0] PASSED [ 68%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num_k_fold[2-1-2-0] PASSED [ 68%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num_k_fold[3-0-2-0] PASSED [ 68%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num_k_fold[3-1-1-0] PASSED [ 68%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num_k_fold[3-2-1-0] PASSED [ 69%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num_k_fold[1-0-3-1] PASSED [ 69%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num_k_fold[2-0-2-1] PASSED [ 69%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num_k_fold[2-1-1-1] PASSED [ 69%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num_k_fold[3-0-1-1] PASSED [ 69%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num_k_fold[3-1-1-1] PASSED [ 69%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num_k_fold[3-2-1-1] PASSED [ 69%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_real_num_not_implemented PASSED [ 69%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[False-selected_num0] FAILED [ 69%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[False-selected_num1] FAILED [ 69%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[False-selected_num2] FAILED [ 69%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[False-selected_num3] FAILED [ 69%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[False-selected_num4] FAILED [ 69%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[False-selected_num5] FAILED [ 69%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[False-selected_num6] FAILED [ 69%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[False-selected_num7] FAILED [ 69%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[True-selected_num0] FAILED [ 69%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[True-selected_num1] FAILED [ 69%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[True-selected_num2] FAILED [ 69%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[True-selected_num3] FAILED [ 69%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[True-selected_num4] FAILED [ 70%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[True-selected_num5] FAILED [ 70%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[True-selected_num6] FAILED [ 70%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[True-selected_num7] FAILED [ 70%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_manual PASSED [ 70%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_wrapper[SplitUnit.MANUAL-True-pick_subject-get_subject_list] PASSED [ 70%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_wrapper[SplitUnit.MANUAL-True-pick_session-get_session_list] PASSED [ 70%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_wrapper[SplitUnit.NUMBER-False-pick_subject-get_subject_list] PASSED [ 70%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_wrapper[SplitUnit.NUMBER-False-pick_session-get_session_list] PASSED [ 70%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_wrapper[SplitUnit.KFOLD-False-pick_subject-get_subject_list] PASSED [ 70%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_wrapper[SplitUnit.KFOLD-False-pick_session-get_session_list] PASSED [ 70%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_wrapper[SplitUnit.RATIO-False-pick_subject-get_subject_list] PASSED [ 70%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_wrapper[SplitUnit.RATIO-False-pick_session-get_session_list] PASSED [ 70%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_manual_trial PASSED [ 70%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-0-expected0-0-False] FAILED [ 70%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-1-expected1-0-False] FAILED [ 70%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-2-expected2-0-False] FAILED [ 70%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-3-expected3-0-False] FAILED [ 70%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-4-expected4-0-False] FAILED [ 70%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-5-expected5-0-False] FAILED [ 70%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-6-expected6-0-False] FAILED [ 70%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-7-expected7-0-False] FAILED [ 71%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-8-expected8-0-False] FAILED [ 71%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-9-expected9-0-False] FAILED [ 71%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-10-expected10-0-False] FAILED [ 71%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-11-expected11-0-False] FAILED [ 71%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-12-expected12-0-False] FAILED [ 71%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-13-expected13-0-False] FAILED [ 71%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-14-expected14-0-False] FAILED [ 71%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-15-expected15-0-False] FAILED [ 71%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-16-expected16-0-False] FAILED [ 71%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-17-expected17-0-False] FAILED [ 71%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-18-expected18-0-False] FAILED [ 71%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-19-expected19-0-False] FAILED [ 71%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-20-expected20-0-False] FAILED [ 71%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-21-expected21-0-False] FAILED [ 71%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-22-expected22-0-False] FAILED [ 71%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-23-expected23-0-False] FAILED [ 71%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-24-expected24-0-False] FAILED [ 71%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-25-expected25-0-False] FAILED [ 71%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-26-expected26-0-False] FAILED [ 71%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-27-expected27-0-False] FAILED [ 72%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-28-expected28-0-False] FAILED [ 72%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-29-expected29-0-False] FAILED [ 72%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-30-expected30-0-False] FAILED [ 72%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-31-expected31-0-False] FAILED [ 72%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-32-expected32-0-False] FAILED [ 72%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-33-expected33-0-False] FAILED [ 72%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-34-expected34-0-False] FAILED [ 72%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-35-expected35-0-False] FAILED [ 72%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-36-expected36-0-False] FAILED [ 72%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-37-expected37-0-False] FAILED [ 72%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.KFOLD-1-expected38-0-False] FAILED [ 72%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected39-0-False] FAILED [ 72%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected40-1-False] FAILED [ 72%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected41-2-False] FAILED [ 72%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected42-6-False] FAILED [ 72%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.0-expected43-0-False] FAILED [ 72%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.1-expected44-0-False] FAILED [ 72%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.2-expected45-0-False] FAILED [ 72%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.30000000000000004-expected46-0-False] FAILED [ 72%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.4-expected47-0-False] FAILED [ 73%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.5-expected48-0-False] FAILED [ 73%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.6000000000000001-expected49-0-False] FAILED [ 73%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.7000000000000001-expected50-0-False] FAILED [ 73%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.8-expected51-0-False] FAILED [ 73%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.9-expected52-0-False] FAILED [ 73%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-0-expected53-0-True] FAILED [ 73%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-1-expected54-0-True] FAILED [ 73%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-2-expected55-0-True] FAILED [ 73%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-3-expected56-0-True] FAILED [ 73%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-4-expected57-0-True] FAILED [ 73%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-5-expected58-0-True] FAILED [ 73%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-6-expected59-0-True] FAILED [ 73%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-7-expected60-0-True] FAILED [ 73%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-8-expected61-0-True] FAILED [ 73%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-9-expected62-0-True] FAILED [ 73%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-10-expected63-0-True] FAILED [ 73%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-11-expected64-0-True] FAILED [ 73%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-12-expected65-0-True] FAILED [ 73%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-13-expected66-0-True] FAILED [ 73%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-14-expected67-0-True] FAILED [ 74%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-15-expected68-0-True] FAILED [ 74%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-16-expected69-0-True] FAILED [ 74%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-17-expected70-0-True] FAILED [ 74%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-18-expected71-0-True] FAILED [ 74%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-19-expected72-0-True] FAILED [ 74%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-20-expected73-0-True] FAILED [ 74%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-21-expected74-0-True] FAILED [ 74%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-22-expected75-0-True] FAILED [ 74%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-23-expected76-0-True] FAILED [ 74%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-24-expected77-0-True] FAILED [ 74%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-25-expected78-0-True] FAILED [ 74%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-26-expected79-0-True] FAILED [ 74%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-27-expected80-0-True] FAILED [ 74%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-28-expected81-0-True] FAILED [ 74%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-29-expected82-0-True] FAILED [ 74%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-30-expected83-0-True] FAILED [ 74%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-31-expected84-0-True] FAILED [ 74%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-32-expected85-0-True] FAILED [ 74%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-33-expected86-0-True] FAILED [ 74%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-34-expected87-0-True] FAILED [ 75%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-35-expected88-0-True] FAILED [ 75%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-36-expected89-0-True] FAILED [ 75%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-37-expected90-0-True] FAILED [ 75%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.KFOLD-1-expected91-0-True] FAILED [ 75%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected92-0-True] FAILED [ 75%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected93-1-True] FAILED [ 75%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected94-2-True] FAILED [ 75%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected95-3-True] FAILED [ 75%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected96-4-True] FAILED [ 75%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected97-5-True] FAILED [ 75%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.0-expected98-0-True] FAILED [ 75%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.1-expected99-0-True] FAILED [ 75%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.2-expected100-0-True] FAILED [ 75%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.30000000000000004-expected101-0-True] FAILED [ 75%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.4-expected102-0-True] FAILED [ 75%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.5-expected103-0-True] FAILED [ 75%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.6000000000000001-expected104-0-True] FAILED [ 75%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.7000000000000001-expected105-0-True] FAILED [ 75%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.8-expected106-0-True] FAILED [ 75%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.9-expected107-0-True] FAILED [ 75%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-0-expected0-0-False] FAILED [ 76%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-1-expected1-0-False] FAILED [ 76%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-2-expected2-0-False] FAILED [ 76%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-3-expected3-0-False] FAILED [ 76%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-4-expected4-0-False] FAILED [ 76%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-5-expected5-0-False] FAILED [ 76%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-6-expected6-0-False] FAILED [ 76%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-7-expected7-0-False] FAILED [ 76%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-8-expected8-0-False] FAILED [ 76%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-9-expected9-0-False] FAILED [ 76%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-10-expected10-0-False] FAILED [ 76%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-11-expected11-0-False] FAILED [ 76%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-12-expected12-0-False] FAILED [ 76%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-13-expected13-0-False] FAILED [ 76%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-14-expected14-0-False] FAILED [ 76%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-15-expected15-0-False] FAILED [ 76%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-16-expected16-0-False] FAILED [ 76%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-17-expected17-0-False] FAILED [ 76%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-18-expected18-0-False] FAILED [ 76%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-19-expected19-0-False] FAILED [ 76%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-20-expected20-0-False] FAILED [ 77%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-21-expected21-0-False] FAILED [ 77%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-22-expected22-0-False] FAILED [ 77%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-23-expected23-0-False] FAILED [ 77%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-24-expected24-0-False] FAILED [ 77%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-25-expected25-0-False] FAILED [ 77%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-26-expected26-0-False] FAILED [ 77%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-27-expected27-0-False] FAILED [ 77%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-28-expected28-0-False] FAILED [ 77%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-29-expected29-0-False] FAILED [ 77%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-30-expected30-0-False] FAILED [ 77%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-31-expected31-0-False] FAILED [ 77%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-32-expected32-0-False] FAILED [ 77%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-33-expected33-0-False] FAILED [ 77%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-34-expected34-0-False] FAILED [ 77%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-35-expected35-0-False] FAILED [ 77%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-36-expected36-0-False] FAILED [ 77%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-37-expected37-0-False] FAILED [ 77%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-1-expected38-0-False] FAILED [ 77%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected39-0-False] FAILED [ 77%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected40-1-False] FAILED [ 78%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected41-2-False] FAILED [ 78%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected42-6-False] FAILED [ 78%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.0-expected43-0-False] FAILED [ 78%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.1-expected44-0-False] FAILED [ 78%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.2-expected45-0-False] FAILED [ 78%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.30000000000000004-expected46-0-False] FAILED [ 78%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.4-expected47-0-False] FAILED [ 78%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.5-expected48-0-False] FAILED [ 78%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.6000000000000001-expected49-0-False] FAILED [ 78%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.7000000000000001-expected50-0-False] FAILED [ 78%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.8-expected51-0-False] FAILED [ 78%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.9-expected52-0-False] FAILED [ 78%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-0-expected53-0-True] FAILED [ 78%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-1-expected54-0-True] FAILED [ 78%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-2-expected55-0-True] FAILED [ 78%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-3-expected56-0-True] FAILED [ 78%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-4-expected57-0-True] FAILED [ 78%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-5-expected58-0-True] FAILED [ 78%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-6-expected59-0-True] FAILED [ 78%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-7-expected60-0-True] FAILED [ 79%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-8-expected61-0-True] FAILED [ 79%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-9-expected62-0-True] FAILED [ 79%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-10-expected63-0-True] FAILED [ 79%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-11-expected64-0-True] FAILED [ 79%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-12-expected65-0-True] FAILED [ 79%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-13-expected66-0-True] FAILED [ 79%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-14-expected67-0-True] FAILED [ 79%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-15-expected68-0-True] FAILED [ 79%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-16-expected69-0-True] FAILED [ 79%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-17-expected70-0-True] FAILED [ 79%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-18-expected71-0-True] FAILED [ 79%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-19-expected72-0-True] FAILED [ 79%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-20-expected73-0-True] FAILED [ 79%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-21-expected74-0-True] FAILED [ 79%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-22-expected75-0-True] FAILED [ 79%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-23-expected76-0-True] FAILED [ 79%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-24-expected77-0-True] FAILED [ 79%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-25-expected78-0-True] FAILED [ 79%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-26-expected79-0-True] FAILED [ 79%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-27-expected80-0-True] FAILED [ 80%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-28-expected81-0-True] FAILED [ 80%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-29-expected82-0-True] FAILED [ 80%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-30-expected83-0-True] FAILED [ 80%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-31-expected84-0-True] FAILED [ 80%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-32-expected85-0-True] FAILED [ 80%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-33-expected86-0-True] FAILED [ 80%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-34-expected87-0-True] FAILED [ 80%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-35-expected88-0-True] FAILED [ 80%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-36-expected89-0-True] FAILED [ 80%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-37-expected90-0-True] FAILED [ 80%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-1-expected91-0-True] FAILED [ 80%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected92-0-True] FAILED [ 80%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected93-1-True] FAILED [ 80%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected94-2-True] FAILED [ 80%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected95-3-True] FAILED [ 80%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected96-4-True] FAILED [ 80%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected97-5-True] FAILED [ 80%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.0-expected98-0-True] FAILED [ 80%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.1-expected99-0-True] FAILED [ 80%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.2-expected100-0-True] FAILED [ 80%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.30000000000000004-expected101-0-True] FAILED [ 81%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.4-expected102-0-True] FAILED [ 81%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.5-expected103-0-True] FAILED [ 81%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.6000000000000001-expected104-0-True] FAILED [ 81%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.7000000000000001-expected105-0-True] FAILED [ 81%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.8-expected106-0-True] FAILED [ 81%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.9-expected107-0-True] FAILED [ 81%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial_not_implemented PASSED [ 81%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_subject FAILED [ 81%]
XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_session FAILED [ 81%]
XBrainLab/tests/backend/dataset/test_option.py::test_split_unit PASSED   [ 81%]
XBrainLab/tests/backend/dataset/test_option.py::test_training_type PASSED [ 81%]
XBrainLab/tests/backend/dataset/test_option.py::test_split_by_type PASSED [ 81%]
XBrainLab/tests/backend/dataset/test_option.py::test_val_split_by_type PASSED [ 81%]
XBrainLab/tests/backend/load_data/test_data_loader.py::test_raw_data_loader PASSED [ 81%]
XBrainLab/tests/backend/load_data/test_data_loader.py::test_raw_data_loader_validate PASSED [ 81%]
XBrainLab/tests/backend/load_data/test_data_loader.py::test_raw_data_loader_append FAILED [ 81%]
XBrainLab/tests/backend/load_data/test_data_loader.py::test_raw_data_loader_append_error FAILED [ 81%]
XBrainLab/tests/backend/load_data/test_data_loader.py::test_apply PASSED [ 81%]
XBrainLab/tests/backend/load_data/test_event_loader.py::test_event_loader_init PASSED [ 81%]
XBrainLab/tests/backend/load_data/test_event_loader.py::test_create_event_from_1d_list FAILED [ 82%]
XBrainLab/tests/backend/load_data/test_event_loader.py::test_create_event_from_nx3_array PASSED [ 82%]
XBrainLab/tests/backend/load_data/test_event_loader.py::test_create_event_inconsistent ERROR [ 82%]
XBrainLab/tests/backend/load_data/test_event_loader_strict.py::test_event_loader_raw_no_events_raises_error FAILED [ 82%]
XBrainLab/tests/backend/load_data/test_event_loader_strict.py::test_event_loader_raw_mismatch_raises_error PASSED [ 82%]
XBrainLab/tests/backend/load_data/test_event_loader_strict.py::test_event_loader_epochs_fallback_ok FAILED [ 82%]
XBrainLab/tests/backend/load_data/test_label_loader.py::TestLabelLoader::test_load_txt_success PASSED [ 82%]
XBrainLab/tests/backend/load_data/test_label_loader.py::TestLabelLoader::test_load_txt_with_garbage PASSED [ 82%]
XBrainLab/tests/backend/load_data/test_label_loader.py::TestLabelLoader::test_load_mat_success PASSED [ 82%]
XBrainLab/tests/backend/load_data/test_label_loader.py::TestLabelLoader::test_load_non_existent_file PASSED [ 82%]
XBrainLab/tests/backend/load_data/test_label_loader.py::TestLabelLoader::test_load_unsupported_format PASSED [ 82%]
XBrainLab/tests/backend/load_data/test_loaders.py::TestLoaders::test_load_bdf_file FAILED [ 82%]
XBrainLab/tests/backend/load_data/test_loaders.py::TestLoaders::test_load_brainvision_file FAILED [ 82%]
XBrainLab/tests/backend/load_data/test_loaders.py::TestLoaders::test_load_cnt_file FAILED [ 82%]
XBrainLab/tests/backend/load_data/test_loaders.py::TestLoaders::test_load_edf_file FAILED [ 82%]
XBrainLab/tests/backend/load_data/test_loaders.py::TestLoaders::test_load_fif_failure FAILED [ 82%]
XBrainLab/tests/backend/load_data/test_loaders.py::TestLoaders::test_load_fif_file FAILED [ 82%]
XBrainLab/tests/backend/load_data/test_raw.py::test_add_preprocess PASSED [ 82%]
XBrainLab/tests/backend/load_data/test_raw.py::test_parse_filename PASSED [ 82%]
XBrainLab/tests/backend/load_data/test_raw.py::test_file_info PASSED     [ 82%]
XBrainLab/tests/backend/load_data/test_raw.py::test_labels_imported_status PASSED [ 83%]
XBrainLab/tests/backend/load_data/test_raw.py::test_set_event PASSED     [ 83%]
XBrainLab/tests/backend/load_data/test_raw.py::test_set_event_error PASSED [ 83%]
XBrainLab/tests/backend/load_data/test_raw.py::test_set_event_consistency ERROR [ 83%]
XBrainLab/tests/backend/load_data/test_raw.py::test_mne_raw_info FAILED  [ 83%]
XBrainLab/tests/backend/load_data/test_raw.py::test_mne_raw_2_info FAILED [ 83%]
XBrainLab/tests/backend/load_data/test_raw.py::test_raw_empty_event FAILED [ 83%]
XBrainLab/tests/backend/load_data/test_raw.py::test_raw_set_event_on_empty_event FAILED [ 83%]
XBrainLab/tests/backend/load_data/test_raw.py::test_raw_stim_event FAILED [ 83%]
XBrainLab/tests/backend/load_data/test_raw.py::test_raw_set_event_on_stim_event FAILED [ 83%]
XBrainLab/tests/backend/load_data/test_raw.py::test_raw_annotation_event ERROR [ 83%]
XBrainLab/tests/backend/load_data/test_raw.py::test_raw_set_event_on_annotation_event ERROR [ 83%]
XBrainLab/tests/backend/load_data/test_raw.py::test_mne_epoch_info ERROR [ 83%]
XBrainLab/tests/backend/load_data/test_raw.py::test_epoch ERROR          [ 83%]
XBrainLab/tests/backend/load_data/test_raw.py::test_epoch_set_event ERROR [ 83%]
XBrainLab/tests/backend/load_data/test_raw.py::test_set_mne_1[raw] FAILED [ 83%]
XBrainLab/tests/backend/load_data/test_raw.py::test_set_mne_1[epoch] FAILED [ 83%]
XBrainLab/tests/backend/load_data/test_raw.py::test_set_mne_2[raw] FAILED [ 83%]
XBrainLab/tests/backend/load_data/test_raw.py::test_set_mne_2[epoch] FAILED [ 83%]
XBrainLab/tests/backend/load_data/test_raw.py::test_set_mne_after_set_event_1[raw] FAILED [ 83%]
XBrainLab/tests/backend/load_data/test_raw.py::test_set_mne_after_set_event_1[epoch] FAILED [ 84%]
XBrainLab/tests/backend/load_data/test_raw.py::test_set_mne_after_set_event_2[raw] FAILED [ 84%]
XBrainLab/tests/backend/load_data/test_raw.py::test_set_mne_after_set_event_2[epoch] FAILED [ 84%]
XBrainLab/tests/backend/load_data/test_raw.py::test_set_mne_consistency PASSED [ 84%]
XBrainLab/tests/backend/load_data/test_raw.py::test_set_mne_and_wipe_events_1[raw] FAILED [ 84%]
XBrainLab/tests/backend/load_data/test_raw.py::test_set_mne_and_wipe_events_1[epoch] FAILED [ 84%]
XBrainLab/tests/backend/load_data/test_raw.py::test_set_mne_and_wipe_events_2[raw] FAILED [ 84%]
XBrainLab/tests/backend/load_data/test_raw.py::test_set_mne_and_wipe_events_2[epoch] FAILED [ 84%]
XBrainLab/tests/backend/load_data/test_raw_data_loader.py::TestRawDataLoaderUnit::test_load_gdf_success PASSED [ 84%]
XBrainLab/tests/backend/load_data/test_raw_data_loader.py::TestRawDataLoaderUnit::test_load_gdf_failure PASSED [ 84%]
XBrainLab/tests/backend/load_data/test_raw_data_loader.py::TestRawDataLoaderUnit::test_load_set_raw_success PASSED [ 84%]
XBrainLab/tests/backend/load_data/test_raw_data_loader.py::TestRawDataLoaderUnit::test_load_set_fallback_to_epochs PASSED [ 84%]
XBrainLab/tests/backend/preprocessor/test_base.py::test_base PASSED      [ 84%]
XBrainLab/tests/backend/preprocessor/test_base.py::test_inherit PASSED   [ 84%]
XBrainLab/tests/backend/preprocessor/test_filtering.py::test_filtering_bandpass FAILED [ 84%]
XBrainLab/tests/backend/preprocessor/test_filtering.py::test_filtering_notch FAILED [ 84%]
XBrainLab/tests/backend/preprocessor/test_filtering.py::test_filtering_combined FAILED [ 84%]
XBrainLab/tests/backend/preprocessor/test_ica.py::test_ica_picard_missing_dependency FAILED [ 84%]
XBrainLab/tests/backend/preprocessor/test_ica.py::test_ica_fit_apply FAILED [ 84%]
XBrainLab/tests/backend/preprocessor/test_ica.py::test_ica_params PASSED [ 84%]
XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_channel_selection[raw] FAILED [ 85%]
XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_channel_selection[epoch] FAILED [ 85%]
XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_edit_event_name_raw PASSED [ 85%]
XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_edit_event_name_epoch ERROR [ 85%]
XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_edit_event_id_raw PASSED [ 85%]
XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_edit_event_id_epoch ERROR [ 85%]
XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_export[raw] FAILED [ 85%]
XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_export[epoch] FAILED [ 85%]
XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_filtering[raw] FAILED [ 85%]
XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_filtering[epoch] FAILED [ 85%]
XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_resample[raw] FAILED [ 85%]
XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_resample[epoch] FAILED [ 85%]
XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_epoch_wrong_type[TimeEpoch] ERROR [ 85%]
XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_epoch_wrong_type[WindowEpoch] ERROR [ 85%]
XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_epoch_wrong_events[TimeEpoch] FAILED [ 85%]
XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_epoch_wrong_events[WindowEpoch] FAILED [ 85%]
XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_sliding_epoch_error PASSED [ 85%]
XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_time_epoch_no_epochs PASSED [ 85%]
XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_time_epoch_without_baseline FAILED [ 85%]
XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_time_epoch_with_baseline FAILED [ 85%]
XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_window_epoch FAILED [ 85%]
XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_normalization_z_score[raw] FAILED [ 86%]
XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_normalization_z_score[epoch] FAILED [ 86%]
XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_normalization_minmax[raw] FAILED [ 86%]
XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_normalization_minmax[epoch] FAILED [ 86%]
XBrainLab/tests/backend/preprocessor/test_rereference.py::test_rereference_average FAILED [ 86%]
XBrainLab/tests/backend/preprocessor/test_rereference.py::test_rereference_specific_channel FAILED [ 86%]
XBrainLab/tests/backend/preprocessor/test_resample.py::TestResample::test_resample_downsample FAILED [ 86%]
XBrainLab/tests/backend/preprocessor/test_resample.py::TestResample::test_resample_upsample FAILED [ 86%]
XBrainLab/tests/backend/preprocessor/test_resample.py::TestResample::test_resample_no_events FAILED [ 86%]
XBrainLab/tests/backend/preprocessor/test_time_epoch.py::TestTimeEpoch::test_time_epoch_success FAILED [ 86%]
XBrainLab/tests/backend/preprocessor/test_time_epoch.py::TestTimeEpoch::test_time_epoch_no_matching_events PASSED [ 86%]
XBrainLab/tests/backend/preprocessor/test_time_epoch.py::TestTimeEpoch::test_time_epoch_duplicate_events FAILED [ 86%]
XBrainLab/tests/backend/preprocessor/test_time_epoch.py::TestTimeEpoch::test_time_epoch_already_epoched PASSED [ 86%]
XBrainLab/tests/backend/training/record/test_eval.py::test_calculate_confusion[output0-label0-expected0] PASSED [ 86%]
XBrainLab/tests/backend/training/record/test_eval.py::test_calculate_confusion[output1-label1-expected1] PASSED [ 86%]
XBrainLab/tests/backend/training/record/test_eval.py::test_calculate_confusion[output2-label2-expected2] PASSED [ 86%]
XBrainLab/tests/backend/training/record/test_eval.py::test_calculate_confusion[output3-label3-expected3] PASSED [ 86%]
XBrainLab/tests/backend/training/record/test_eval.py::test_acc[label0-output0-0.3333333333333333] PASSED [ 86%]
XBrainLab/tests/backend/training/record/test_eval.py::test_acc[label1-output1-0.6666666666666666] PASSED [ 86%]
XBrainLab/tests/backend/training/record/test_eval.py::test_acc[label2-output2-1.0] PASSED [ 86%]
XBrainLab/tests/backend/training/record/test_eval.py::test_kappa[value0-0.5652173913043478] PASSED [ 87%]
XBrainLab/tests/backend/training/record/test_eval.py::test_kappa[value1-0.13043478260869554] PASSED [ 87%]
XBrainLab/tests/backend/training/record/test_eval.py::test_auc[None-None-None] XFAIL [ 87%]
XBrainLab/tests/backend/training/record/test_eval.py::test_export PASSED [ 87%]
XBrainLab/tests/backend/training/record/test_eval.py::test_export_csv PASSED [ 87%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record PASSED [ 87%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_getter FAILED [ 87%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_create_dir FAILED [ 87%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_backup_dir FAILED [ 87%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_append_record ERROR [ 87%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_append_record_with_step ERROR [ 87%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_append_record_with_large_array ERROR [ 87%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_append_record_with_small_array ERROR [ 87%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_update_smaller[val-loss-best_val_loss] ERROR [ 87%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_update_smaller[test-loss-best_test_loss] ERROR [ 87%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_update_larger[val-accuracy-best_val_accuracy] ERROR [ 87%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_update_larger[val-auc-best_val_auc] ERROR [ 87%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_update_larger[test-accuracy-best_test_accuracy] ERROR [ 87%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_update_larger[test-auc-best_test_auc] ERROR [ 87%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_update_eval ERROR [ 87%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_update_test ERROR [ 88%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_update_train ERROR [ 88%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_update_statistic ERROR [ 88%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_step ERROR [ 88%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_loss_figure-loss-True-True-True] ERROR [ 88%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_loss_figure-loss-True-True-False] ERROR [ 88%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_loss_figure-loss-True-False-True] ERROR [ 88%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_loss_figure-loss-True-False-False] ERROR [ 88%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_loss_figure-loss-False-True-True] ERROR [ 88%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_loss_figure-loss-False-True-False] ERROR [ 88%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_loss_figure-loss-False-False-True] ERROR [ 88%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_loss_figure-loss-False-False-False] ERROR [ 88%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_acc_figure-accuracy-True-True-True] ERROR [ 88%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_acc_figure-accuracy-True-True-False] ERROR [ 88%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_acc_figure-accuracy-True-False-True] ERROR [ 88%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_acc_figure-accuracy-True-False-False] ERROR [ 88%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_acc_figure-accuracy-False-True-True] ERROR [ 88%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_acc_figure-accuracy-False-True-False] ERROR [ 88%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_acc_figure-accuracy-False-False-True] ERROR [ 88%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_acc_figure-accuracy-False-False-False] ERROR [ 88%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_auc_figure-auc-True-True-True] ERROR [ 89%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_auc_figure-auc-True-True-False] ERROR [ 89%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_auc_figure-auc-True-False-True] ERROR [ 89%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_auc_figure-auc-True-False-False] ERROR [ 89%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_auc_figure-auc-False-True-True] ERROR [ 89%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_auc_figure-auc-False-True-False] ERROR [ 89%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_auc_figure-auc-False-False-True] ERROR [ 89%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_auc_figure-auc-False-False-False] ERROR [ 89%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_lr_figure ERROR [ 89%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_confusion_figure ERROR [ 89%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_eval_record_getter[get_acc] ERROR [ 89%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_eval_record_getter[get_auc] ERROR [ 89%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_eval_record_getter[get_kappa] ERROR [ 89%]
XBrainLab/tests/backend/training/record/test_train.py::test_train_record_eval_record_getter[get_eval_record] ERROR [ 89%]
XBrainLab/tests/backend/training/record/test_train.py::test_export[accuracy-val] ERROR [ 89%]
XBrainLab/tests/backend/training/record/test_train.py::test_export[accuracy-test] ERROR [ 89%]
XBrainLab/tests/backend/training/record/test_train.py::test_export[auc-val] ERROR [ 89%]
XBrainLab/tests/backend/training/record/test_train.py::test_export[auc-test] ERROR [ 89%]
XBrainLab/tests/backend/training/record/test_train.py::test_export[loss-val] ERROR [ 89%]
XBrainLab/tests/backend/training/record/test_train.py::test_export[loss-test] ERROR [ 89%]
XBrainLab/tests/backend/training/test_model_holder.py::test_model_holder PASSED [ 90%]
XBrainLab/tests/backend/training/test_option.py::test_parse_device_name[True-None-cpu] PASSED [ 90%]
XBrainLab/tests/backend/training/test_option.py::test_parse_device_name[True-0-cpu] PASSED [ 90%]
XBrainLab/tests/backend/training/test_option.py::test_parse_device_name[False-0-0 - test] PASSED [ 90%]
XBrainLab/tests/backend/training/test_option.py::test_parse_device_name[False-1-1 - test] PASSED [ 90%]
XBrainLab/tests/backend/training/test_option.py::test_parse_device_name[False-None-None] PASSED [ 90%]
XBrainLab/tests/backend/training/test_option.py::test_parse_optim_name PASSED [ 90%]
XBrainLab/tests/backend/training/test_option.py::test_option[kwargs0-True] PASSED [ 90%]
XBrainLab/tests/backend/training/test_option.py::test_option[kwargs1-True] PASSED [ 90%]
XBrainLab/tests/backend/training/test_option.py::test_option[kwargs2-True] PASSED [ 90%]
XBrainLab/tests/backend/training/test_option.py::test_option[kwargs3-True] PASSED [ 90%]
XBrainLab/tests/backend/training/test_option.py::test_option[kwargs4-True] PASSED [ 90%]
XBrainLab/tests/backend/training/test_option.py::test_option[kwargs5-True] PASSED [ 90%]
XBrainLab/tests/backend/training/test_option.py::test_option[kwargs6-False] PASSED [ 90%]
XBrainLab/tests/backend/training/test_option.py::test_option[kwargs7-True] PASSED [ 90%]
XBrainLab/tests/backend/training/test_option.py::test_option[kwargs8-False] FAILED [ 90%]
XBrainLab/tests/backend/training/test_option.py::test_option[kwargs9-False] FAILED [ 90%]
XBrainLab/tests/backend/training/test_option.py::test_option[kwargs10-False] FAILED [ 90%]
XBrainLab/tests/backend/training/test_option.py::test_option[kwargs11-False] FAILED [ 90%]
XBrainLab/tests/backend/training/test_option.py::test_option[kwargs12-False] FAILED [ 90%]
XBrainLab/tests/backend/training/test_option.py::test_option[kwargs13-True] PASSED [ 90%]
XBrainLab/tests/backend/training/test_option.py::test_option[kwargs14-True] PASSED [ 91%]
XBrainLab/tests/backend/training/test_option.py::test_option[kwargs15-True] PASSED [ 91%]
XBrainLab/tests/backend/training/test_option.py::test_option[kwargs16-True] PASSED [ 91%]
XBrainLab/tests/backend/training/test_option.py::test_option[kwargs17-True] PASSED [ 91%]
XBrainLab/tests/backend/training/test_option.py::test_option[kwargs18-True] PASSED [ 91%]
XBrainLab/tests/backend/training/test_option.py::test_option[kwargs19-True] PASSED [ 91%]
XBrainLab/tests/backend/training/test_option.py::test_option[kwargs20-False] FAILED [ 91%]
XBrainLab/tests/backend/training/test_option.py::test_option[kwargs21-True] PASSED [ 91%]
XBrainLab/tests/backend/training/test_option.py::test_option[kwargs22-True] PASSED [ 91%]
XBrainLab/tests/backend/training/test_option.py::test_option[kwargs23-True] PASSED [ 91%]
XBrainLab/tests/backend/training/test_option.py::test_option[kwargs24-True] PASSED [ 91%]
XBrainLab/tests/backend/training/test_option.py::test_test_only_option[kwargs0-True] PASSED [ 91%]
XBrainLab/tests/backend/training/test_option.py::test_test_only_option[kwargs1-True] PASSED [ 91%]
XBrainLab/tests/backend/training/test_option.py::test_test_only_option[kwargs2-True] PASSED [ 91%]
XBrainLab/tests/backend/training/test_option.py::test_test_only_option[kwargs3-True] PASSED [ 91%]
XBrainLab/tests/backend/training/test_option.py::test_test_only_option[kwargs4-False] PASSED [ 91%]
XBrainLab/tests/backend/training/test_option.py::test_test_only_option[kwargs5-True] PASSED [ 91%]
XBrainLab/tests/backend/training/test_option.py::test_test_only_option[kwargs6-False] PASSED [ 91%]
XBrainLab/tests/backend/training/test_option.py::test_test_only_option[kwargs7-False] PASSED [ 91%]
XBrainLab/tests/backend/training/test_option.py::test_test_only_option[kwargs8-True] PASSED [ 91%]
XBrainLab/tests/backend/training/test_option.py::test_test_only_option[kwargs9-True] PASSED [ 92%]
XBrainLab/tests/backend/training/test_trainer.py::test_trainer FAILED    [ 92%]
XBrainLab/tests/backend/training/test_trainer.py::test_trainer_custom_progress_text PASSED [ 92%]
XBrainLab/tests/backend/training/test_trainer.py::test_trainer_run[True] PASSED [ 92%]
XBrainLab/tests/backend/training/test_trainer.py::test_trainer_run[False] PASSED [ 92%]
XBrainLab/tests/backend/training/test_trainer.py::test_trainer_job PASSED [ 92%]
XBrainLab/tests/backend/training/test_trainer.py::test_trainer_interrupt PASSED [ 92%]
XBrainLab/tests/backend/training/test_trainer.py::test_trainer_get_plan[Fake-test-1] FAILED [ 92%]
XBrainLab/tests/backend/training/test_trainer.py::test_trainer_get_plan[Fake0-test-0] FAILED [ 92%]
XBrainLab/tests/backend/training/test_trainer.py::test_trainer_get_plan[Fake1-test-0] FAILED [ 92%]
XBrainLab/tests/backend/training/test_trainer.py::test_trainer_get_plan[Fake1-tests-2] FAILED [ 92%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_check_data[model_holder] PASSED [ 92%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_check_data[dataset] PASSED [ 92%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_check_data[option] PASSED [ 92%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_check_data[saliency_params] PASSED [ 92%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_check_data[None] FAILED [ 92%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_loader ERROR [ 92%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_loader[val-test-test] ERROR [ 92%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_loader[None-test-test] ERROR [ 92%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_loader[val-None-val] ERROR [ 92%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_loader[None-None-None] ERROR [ 93%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_model[test-TRAINING_EVALUATION.VAL_LOSS-best_val_loss_model0] ERROR [ 93%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_model[test-TRAINING_EVALUATION.VAL_LOSS-best_val_loss_model1] ERROR [ 93%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_model[test-TRAINING_EVALUATION.TEST_AUC-best_test_auc_model0] ERROR [ 93%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_model[test-TRAINING_EVALUATION.TEST_AUC-best_test_auc_model1] ERROR [ 93%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_model[test-TRAINING_EVALUATION.TEST_ACC-best_test_accuracy_model0] ERROR [ 93%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_model[test-TRAINING_EVALUATION.TEST_ACC-best_test_accuracy_model1] ERROR [ 93%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_model[None-TRAINING_EVALUATION.VAL_LOSS-best_val_loss_model0] ERROR [ 93%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_model[None-TRAINING_EVALUATION.VAL_LOSS-best_val_loss_model1] ERROR [ 93%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_model[None-TRAINING_EVALUATION.TEST_AUC-best_test_auc_model0] ERROR [ 93%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_model[None-TRAINING_EVALUATION.TEST_AUC-best_test_auc_model1] ERROR [ 93%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_model[None-TRAINING_EVALUATION.TEST_ACC-best_test_accuracy_model0] ERROR [ 93%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_model[None-TRAINING_EVALUATION.TEST_ACC-best_test_accuracy_model1] ERROR [ 93%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.VAL_LOSS-val-test-test] ERROR [ 93%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.VAL_LOSS-None-test-test] ERROR [ 93%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.VAL_LOSS-val-None-val] ERROR [ 93%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.VAL_LOSS-None-None-None] ERROR [ 93%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.TEST_AUC-val-test-test] ERROR [ 93%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.TEST_AUC-None-test-test] ERROR [ 93%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.TEST_AUC-val-None-val] ERROR [ 93%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.TEST_AUC-None-None-None] ERROR [ 94%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.TEST_ACC-val-test-test] ERROR [ 94%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.TEST_ACC-None-test-test] ERROR [ 94%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.TEST_ACC-val-None-val] ERROR [ 94%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.TEST_ACC-None-None-None] ERROR [ 94%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.LAST_EPOCH-val-test-test] ERROR [ 94%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.LAST_EPOCH-None-test-test] ERROR [ 94%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.LAST_EPOCH-val-None-val] ERROR [ 94%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.LAST_EPOCH-None-None-None] ERROR [ 94%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[None-val-test-test] ERROR [ 94%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[None-None-test-test] ERROR [ 94%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[None-val-None-val] ERROR [ 94%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[None-None-None-None] ERROR [ 94%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_model_by_lastest_model ERROR [ 94%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_set_interrupt ERROR [ 94%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_trivial_getter ERROR [ 94%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_one_epoch[True] ERROR [ 94%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_one_epoch[False] ERROR [ 94%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_train_one_repeat ERROR [ 94%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_train_one_repeat_status ERROR [ 94%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_train_one_repeat_empty_training_data ERROR [ 95%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_train_one_repeat_eval ERROR [ 95%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_train_one_repeat_already_finished ERROR [ 95%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_train ERROR [ 95%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_train_status ERROR [ 95%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_train_error ERROR [ 95%]
XBrainLab/tests/backend/training/test_training_plan.py::test_test_model_metrics FAILED [ 95%]
XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_init_error ERROR [ 95%]
XBrainLab/tests/backend/training/test_training_plan_test_model.py::test_to_holder[True] FAILED [ 95%]
XBrainLab/tests/backend/training/test_training_plan_test_model.py::test_to_holder[False] FAILED [ 95%]
XBrainLab/tests/backend/training/test_training_plan_test_model.py::test_to_holder_empty PASSED [ 95%]
XBrainLab/tests/backend/training/test_training_plan_test_model.py::test_test_model ERROR [ 95%]
XBrainLab/tests/backend/training/test_training_plan_test_model.py::test_eval_model FAILED [ 95%]
XBrainLab/tests/backend/utils/test_check.py::test__get_type_name PASSED  [ 95%]
XBrainLab/tests/backend/utils/test_check.py::test_validate_type PASSED   [ 95%]
XBrainLab/tests/backend/utils/test_check.py::test_validate_list_type PASSED [ 95%]
XBrainLab/tests/backend/utils/test_check.py::test_validate_issubclass PASSED [ 95%]
XBrainLab/tests/backend/utils/test_filename_parser.py::TestFilenameParser::test_parse_by_split PASSED [ 95%]
XBrainLab/tests/backend/utils/test_filename_parser.py::TestFilenameParser::test_parse_by_regex PASSED [ 95%]
XBrainLab/tests/backend/utils/test_filename_parser.py::TestFilenameParser::test_parse_by_folder PASSED [ 95%]
XBrainLab/tests/backend/utils/test_filename_parser.py::TestFilenameParser::test_parse_by_fixed_position PASSED [ 95%]
XBrainLab/tests/backend/utils/test_logger.py::test_setup_logger PASSED   [ 96%]
XBrainLab/tests/backend/utils/test_logger.py::test_logger_file_creation PASSED [ 96%]
XBrainLab/tests/backend/utils/test_logger.py::test_logger_singleton_behavior PASSED [ 96%]
XBrainLab/tests/backend/utils/test_seed.py::test_set_seed FAILED         [ 96%]
XBrainLab/tests/backend/utils/test_seed.py::test_get_random_state FAILED [ 96%]
XBrainLab/tests/backend/utils/test_seed.py::test_set_random_state PASSED [ 96%]
XBrainLab/tests/backend/visualization/test_base.py::test_visualizer PASSED [ 96%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[True-VisualizerType.SaliencyMap-epochs0-2-True] FAILED [ 96%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[True-VisualizerType.SaliencyMap-epochs0-2-False] FAILED [ 96%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[True-VisualizerType.SaliencyMap-epochs1-3-True] FAILED [ 96%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[True-VisualizerType.SaliencyMap-epochs1-3-False] FAILED [ 96%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[True-VisualizerType.SaliencyMap-epochs2-4-True] FAILED [ 96%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[True-VisualizerType.SaliencyMap-epochs2-4-False] FAILED [ 96%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[True-VisualizerType.SaliencyTopoMap-epochs0-2-True] FAILED [ 96%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[True-VisualizerType.SaliencyTopoMap-epochs0-2-False] FAILED [ 96%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[True-VisualizerType.SaliencyTopoMap-epochs1-3-True] FAILED [ 96%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[True-VisualizerType.SaliencyTopoMap-epochs1-3-False] FAILED [ 96%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[True-VisualizerType.SaliencyTopoMap-epochs2-4-True] FAILED [ 96%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[True-VisualizerType.SaliencyTopoMap-epochs2-4-False] FAILED [ 96%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[False-VisualizerType.SaliencyMap-epochs0-2-True] FAILED [ 96%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[False-VisualizerType.SaliencyMap-epochs0-2-False] FAILED [ 97%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[False-VisualizerType.SaliencyMap-epochs1-3-True] FAILED [ 97%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[False-VisualizerType.SaliencyMap-epochs1-3-False] FAILED [ 97%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[False-VisualizerType.SaliencyMap-epochs2-4-True] FAILED [ 97%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[False-VisualizerType.SaliencyMap-epochs2-4-False] FAILED [ 97%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[False-VisualizerType.SaliencyTopoMap-epochs0-2-True] FAILED [ 97%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[False-VisualizerType.SaliencyTopoMap-epochs0-2-False] FAILED [ 97%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[False-VisualizerType.SaliencyTopoMap-epochs1-3-True] FAILED [ 97%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[False-VisualizerType.SaliencyTopoMap-epochs1-3-False] FAILED [ 97%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[False-VisualizerType.SaliencyTopoMap-epochs2-4-True] FAILED [ 97%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[False-VisualizerType.SaliencyTopoMap-epochs2-4-False] FAILED [ 97%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_eval_plot[VisualizerType.SaliencySpectrogramMap-True-epochs0-2] FAILED [ 97%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_eval_plot[VisualizerType.SaliencySpectrogramMap-True-epochs1-3] FAILED [ 97%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_eval_plot[VisualizerType.SaliencySpectrogramMap-True-epochs2-4] FAILED [ 97%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_eval_plot[VisualizerType.SaliencySpectrogramMap-False-epochs0-2] FAILED [ 97%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_eval_plot[VisualizerType.SaliencySpectrogramMap-False-epochs1-3] FAILED [ 97%]
XBrainLab/tests/backend/visualization/test_visualizer.py::test_eval_plot[VisualizerType.SaliencySpectrogramMap-False-epochs2-4] FAILED [ 97%]
XBrainLab/tests/integration/test_ui_integration.py::test_full_import_flow FAILED [ 97%]
XBrainLab/tests/integration/test_ui_integration.py::test_resample_and_epoch FAILED [ 97%]
XBrainLab/tests/integration/test_ui_integration.py::test_resample_epoch_no_labels FAILED [ 97%]
XBrainLab/tests/integration/test_ui_refresh.py::test_ui_refresh_on_tab_switch FAILED [ 98%]
XBrainLab/tests/test_study.py::test_study_load_data PASSED               [ 98%]
XBrainLab/tests/test_study.py::test_study_set_loaded_data_list[True] PASSED [ 98%]
XBrainLab/tests/test_study.py::test_study_set_loaded_data_list[False] PASSED [ 98%]
XBrainLab/tests/test_study.py::test_study_set_preprocessed_data_list[_test_study_set_loaded_data_list_raise-loaded_data_list-True-True] PASSED [ 98%]
XBrainLab/tests/test_study.py::test_study_set_preprocessed_data_list[_test_study_set_loaded_data_list_raise-loaded_data_list-True-False] PASSED [ 98%]
XBrainLab/tests/test_study.py::test_study_set_preprocessed_data_list[_test_study_set_loaded_data_list_raise-loaded_epoch_data_list-False-True] PASSED [ 98%]
XBrainLab/tests/test_study.py::test_study_set_preprocessed_data_list[_test_study_set_loaded_data_list_raise-loaded_epoch_data_list-False-False] PASSED [ 98%]
XBrainLab/tests/test_study.py::test_study_get_datasets_generator PASSED  [ 98%]
XBrainLab/tests/test_study.py::test_study_set_datasets[_test_study_set_loaded_data_list_raise-loaded_data_list-True] PASSED [ 98%]
XBrainLab/tests/test_study.py::test_study_set_datasets[_test_study_set_loaded_data_list_raise-loaded_data_list-False] PASSED [ 98%]
XBrainLab/tests/test_study.py::test_study_set_datasets[_test_study_set_loaded_data_list_raise-loaded_epoch_data_list-True] PASSED [ 98%]
XBrainLab/tests/test_study.py::test_study_set_datasets[_test_study_set_loaded_data_list_raise-loaded_epoch_data_list-False] PASSED [ 98%]
XBrainLab/tests/test_study.py::test_study_set_datasets[_test_study_set_preprocessed_data_list_raise-loaded_data_list-True] PASSED [ 98%]
XBrainLab/tests/test_study.py::test_study_set_datasets[_test_study_set_preprocessed_data_list_raise-loaded_data_list-False] PASSED [ 98%]
XBrainLab/tests/test_study.py::test_study_set_datasets[_test_study_set_preprocessed_data_list_raise-loaded_epoch_data_list-True] PASSED [ 98%]
XBrainLab/tests/test_study.py::test_study_set_datasets[_test_study_set_preprocessed_data_list_raise-loaded_epoch_data_list-False] PASSED [ 98%]
XBrainLab/tests/test_study.py::test_study_set_training_option[True] PASSED [ 98%]
XBrainLab/tests/test_study.py::test_study_set_training_option[False] PASSED [ 98%]
XBrainLab/tests/test_study.py::test_study_set_model_holder[True] PASSED  [ 98%]
XBrainLab/tests/test_study.py::test_study_set_model_holder[False] PASSED [ 99%]
XBrainLab/tests/test_study.py::test_study_generate_plan[True] PASSED     [ 99%]
XBrainLab/tests/test_study.py::test_study_generate_plan[False] PASSED    [ 99%]
XBrainLab/tests/test_study.py::test_study_generate_plan_missing_options[datasets-dataset] PASSED [ 99%]
XBrainLab/tests/test_study.py::test_study_generate_plan_missing_options[training_option-training option] PASSED [ 99%]
XBrainLab/tests/test_study.py::test_study_generate_plan_missing_options[model_holder-model holder] PASSED [ 99%]
XBrainLab/tests/test_study.py::test_study_training PASSED                [ 99%]
XBrainLab/tests/test_study.py::test_study_training_not_set PASSED        [ 99%]
XBrainLab/tests/test_study.py::test_study_export_output_csv[True-True] PASSED [ 99%]
XBrainLab/tests/test_study.py::test_study_export_output_csv[True-False] PASSED [ 99%]
XBrainLab/tests/test_study.py::test_study_export_output_csv[False-True] PASSED [ 99%]
XBrainLab/tests/test_study.py::test_study_export_output_csv[False-False] PASSED [ 99%]
XBrainLab/tests/test_study.py::test_study_export_output_csv_not_set PASSED [ 99%]
XBrainLab/tests/test_study.py::test_study_set_channels PASSED            [ 99%]
XBrainLab/tests/test_study.py::test_study_set_channels_not_set PASSED    [ 99%]
XBrainLab/tests/test_study.py::test_study_saliency_params PASSED         [ 99%]
XBrainLab/tests/ui/test_main_window.py::test_mainwindow_launch PASSED    [ 99%]
XBrainLab/tests/ui/test_main_window.py::test_navigation PASSED           [ 99%]
XBrainLab/tests/ui/test_training_panel_redesign.py::test_training_panel_layout PASSED [ 99%]
XBrainLab/tests/ui/test_training_panel_redesign.py::test_update_summary_with_split_info PASSED [ 99%]
XBrainLab/tests/ui/test_workflow.py::test_full_workflow PASSED           [100%]

==================================== ERRORS ====================================
______________ ERROR at setup of test_epochs_generate_mask_target ______________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7f37c0>

    @pytest.fixture
    def full_filter_preview_mask(epochs):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
>       filter_preview_mask = epochs._generate_mask_target(mask)

XBrainLab/tests/backend/dataset/test_epochs.py:52: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7f37c0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____________ ERROR at setup of test_epochs_get_filtered_mask_pair _____________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec8e4040>

    @pytest.fixture
    def full_filter_preview_mask(epochs):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
>       filter_preview_mask = epochs._generate_mask_target(mask)

XBrainLab/tests/backend/dataset/test_epochs.py:52: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec8e4040>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_______________ ERROR at setup of test_epochs_update_mask_target _______________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ecbb2a90>

    @pytest.fixture
    def full_filter_preview_mask(epochs):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
>       filter_preview_mask = epochs._generate_mask_target(mask)

XBrainLab/tests/backend/dataset/test_epochs.py:52: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ecbb2a90>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_______________ ERROR at setup of test_create_event_inconsistent _______________

item = <Function test_create_event_inconsistent>

    @pytest.hookimpl(wrapper=True, tryfirst=True)
    def pytest_runtest_setup(item):
        """
        Hook called after before test setup starts, to start capturing exceptions
        as early as possible.
        """
        capture_enabled = _is_exception_capture_enabled(item)
        if capture_enabled:
            item.qt_exception_capture_manager = _QtExceptionCaptureManager()
            item.qt_exception_capture_manager.start()
>       result = yield

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/pytestqt/plugin.py:178: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/tests/backend/load_data/test_raw.py:238: in epoch
    return Raw(path, mne_epoch)
XBrainLab/backend/load_data/raw.py:43: in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = <MagicMock name='mock.Epochs()' id='134904589852928'>
type_class = (<class 'conftest.MockBaseRaw'>, <class 'conftest.MockBaseEpochs'>)
message_name = 'mne_data'

    def validate_type(instance: object,
                      type_class: type | tuple[type],
                      message_name: str) -> None:
        """Validate the type of an instance.
    
        Args:
            instance: The instance to be validated.
            type_class: Acceptable type(s) of the instance.
                        Can be a single type or a tuple of types.
            message_name: The name of the instance to be displayed in the error message.
    
        Raises:
            TypeError: If the instance is not an instance of the acceptable type(s).
        """
        if not isinstance(type_class, (list, tuple)):
            type_class = (type_class, )
        if not isinstance(instance, type_class):
            if len(type_class) == 1:
                type_class = type_class[0]
                type_name = _get_type_name(type_class)
            else:
                type_name_list = [_get_type_name(c) for c in type_class]
                type_name = ' or '.join(type_name_list)
>           raise TypeError(
                f"{message_name} must be an instance of {type_name}, "
                f"got {type(instance)} instead.")
E           TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.

XBrainLab/backend/utils/check.py:31: TypeError
_________________ ERROR at setup of test_set_event_consistency _________________

mne_epoch = <MagicMock name='mock.Epochs()' id='134904589852928'>

    @pytest.fixture
    def epoch(mne_epoch):
        path = 'tests/test_data/sub-01_ses-01_task-rest_eeg.fif'
>       return Raw(path, mne_epoch)

XBrainLab/tests/backend/load_data/test_raw.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/load_data/raw.py:43: in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = <MagicMock name='mock.Epochs()' id='134904589852928'>
type_class = (<class 'conftest.MockBaseRaw'>, <class 'conftest.MockBaseEpochs'>)
message_name = 'mne_data'

    def validate_type(instance: object,
                      type_class: type | tuple[type],
                      message_name: str) -> None:
        """Validate the type of an instance.
    
        Args:
            instance: The instance to be validated.
            type_class: Acceptable type(s) of the instance.
                        Can be a single type or a tuple of types.
            message_name: The name of the instance to be displayed in the error message.
    
        Raises:
            TypeError: If the instance is not an instance of the acceptable type(s).
        """
        if not isinstance(type_class, (list, tuple)):
            type_class = (type_class, )
        if not isinstance(instance, type_class):
            if len(type_class) == 1:
                type_class = type_class[0]
                type_name = _get_type_name(type_class)
            else:
                type_name_list = [_get_type_name(c) for c in type_class]
                type_name = ' or '.join(type_name_list)
>           raise TypeError(
                f"{message_name} must be an instance of {type_name}, "
                f"got {type(instance)} instead.")
E           TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.

XBrainLab/backend/utils/check.py:31: TypeError
_________________ ERROR at setup of test_raw_annotation_event __________________

    @pytest.fixture
    def mne_raw_annot():
        fs = 10
        info = mne.create_info(ch_names=['O1', 'O2'],
                               sfreq=fs,
                               ch_types='eeg')
        data = np.random.RandomState(0).randn(2, fs)
        mne_raw = mne.io.RawArray(data, info)
>       mne_raw.set_annotations(mne.Annotations(onset=[0.1, 0.3, 0.5],
                                                duration=[0.2, 0.2, 0.2],
                                                description=['a', 'b', 'c']))
E       AttributeError: 'MockBaseRaw' object has no attribute 'set_annotations'

XBrainLab/tests/backend/load_data/test_raw.py:197: AttributeError
___________ ERROR at setup of test_raw_set_event_on_annotation_event ___________

    @pytest.fixture
    def mne_raw_annot():
        fs = 10
        info = mne.create_info(ch_names=['O1', 'O2'],
                               sfreq=fs,
                               ch_types='eeg')
        data = np.random.RandomState(0).randn(2, fs)
        mne_raw = mne.io.RawArray(data, info)
>       mne_raw.set_annotations(mne.Annotations(onset=[0.1, 0.3, 0.5],
                                                duration=[0.2, 0.2, 0.2],
                                                description=['a', 'b', 'c']))
E       AttributeError: 'MockBaseRaw' object has no attribute 'set_annotations'

XBrainLab/tests/backend/load_data/test_raw.py:197: AttributeError
____________________ ERROR at setup of test_mne_epoch_info _____________________

mne_epoch = <MagicMock name='mock.Epochs()' id='134904589852928'>

    @pytest.fixture
    def epoch(mne_epoch):
        path = 'tests/test_data/sub-01_ses-01_task-rest_eeg.fif'
>       return Raw(path, mne_epoch)

XBrainLab/tests/backend/load_data/test_raw.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/load_data/raw.py:43: in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = <MagicMock name='mock.Epochs()' id='134904589852928'>
type_class = (<class 'conftest.MockBaseRaw'>, <class 'conftest.MockBaseEpochs'>)
message_name = 'mne_data'

    def validate_type(instance: object,
                      type_class: type | tuple[type],
                      message_name: str) -> None:
        """Validate the type of an instance.
    
        Args:
            instance: The instance to be validated.
            type_class: Acceptable type(s) of the instance.
                        Can be a single type or a tuple of types.
            message_name: The name of the instance to be displayed in the error message.
    
        Raises:
            TypeError: If the instance is not an instance of the acceptable type(s).
        """
        if not isinstance(type_class, (list, tuple)):
            type_class = (type_class, )
        if not isinstance(instance, type_class):
            if len(type_class) == 1:
                type_class = type_class[0]
                type_name = _get_type_name(type_class)
            else:
                type_name_list = [_get_type_name(c) for c in type_class]
                type_name = ' or '.join(type_name_list)
>           raise TypeError(
                f"{message_name} must be an instance of {type_name}, "
                f"got {type(instance)} instead.")
E           TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.

XBrainLab/backend/utils/check.py:31: TypeError
_________________________ ERROR at setup of test_epoch _________________________

mne_epoch = <MagicMock name='mock.Epochs()' id='134904589852928'>

    @pytest.fixture
    def epoch(mne_epoch):
        path = 'tests/test_data/sub-01_ses-01_task-rest_eeg.fif'
>       return Raw(path, mne_epoch)

XBrainLab/tests/backend/load_data/test_raw.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/load_data/raw.py:43: in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = <MagicMock name='mock.Epochs()' id='134904589852928'>
type_class = (<class 'conftest.MockBaseRaw'>, <class 'conftest.MockBaseEpochs'>)
message_name = 'mne_data'

    def validate_type(instance: object,
                      type_class: type | tuple[type],
                      message_name: str) -> None:
        """Validate the type of an instance.
    
        Args:
            instance: The instance to be validated.
            type_class: Acceptable type(s) of the instance.
                        Can be a single type or a tuple of types.
            message_name: The name of the instance to be displayed in the error message.
    
        Raises:
            TypeError: If the instance is not an instance of the acceptable type(s).
        """
        if not isinstance(type_class, (list, tuple)):
            type_class = (type_class, )
        if not isinstance(instance, type_class):
            if len(type_class) == 1:
                type_class = type_class[0]
                type_name = _get_type_name(type_class)
            else:
                type_name_list = [_get_type_name(c) for c in type_class]
                type_name = ' or '.join(type_name_list)
>           raise TypeError(
                f"{message_name} must be an instance of {type_name}, "
                f"got {type(instance)} instead.")
E           TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.

XBrainLab/backend/utils/check.py:31: TypeError
____________________ ERROR at setup of test_epoch_set_event ____________________

mne_epoch = <MagicMock name='mock.Epochs()' id='134904589852928'>

    @pytest.fixture
    def epoch(mne_epoch):
        path = 'tests/test_data/sub-01_ses-01_task-rest_eeg.fif'
>       return Raw(path, mne_epoch)

XBrainLab/tests/backend/load_data/test_raw.py:238: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/load_data/raw.py:43: in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = <MagicMock name='mock.Epochs()' id='134904589852928'>
type_class = (<class 'conftest.MockBaseRaw'>, <class 'conftest.MockBaseEpochs'>)
message_name = 'mne_data'

    def validate_type(instance: object,
                      type_class: type | tuple[type],
                      message_name: str) -> None:
        """Validate the type of an instance.
    
        Args:
            instance: The instance to be validated.
            type_class: Acceptable type(s) of the instance.
                        Can be a single type or a tuple of types.
            message_name: The name of the instance to be displayed in the error message.
    
        Raises:
            TypeError: If the instance is not an instance of the acceptable type(s).
        """
        if not isinstance(type_class, (list, tuple)):
            type_class = (type_class, )
        if not isinstance(instance, type_class):
            if len(type_class) == 1:
                type_class = type_class[0]
                type_name = _get_type_name(type_class)
            else:
                type_name_list = [_get_type_name(c) for c in type_class]
                type_name = ' or '.join(type_name_list)
>           raise TypeError(
                f"{message_name} must be an instance of {type_name}, "
                f"got {type(instance)} instead.")
E           TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.

XBrainLab/backend/utils/check.py:31: TypeError
_________________ ERROR at setup of test_edit_event_name_epoch _________________

mne_epoch = <MagicMock name='mock.Epochs()' id='134904589852928'>

    @pytest.fixture
    def epoch(mne_epoch):
        path = 'tests/test_data/sub-01_ses-01_task-rest_eeg.fif'
>       return Raw(path, mne_epoch)

XBrainLab/tests/backend/preprocessor/test_preprocess.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/load_data/raw.py:43: in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = <MagicMock name='mock.Epochs()' id='134904589852928'>
type_class = (<class 'conftest.MockBaseRaw'>, <class 'conftest.MockBaseEpochs'>)
message_name = 'mne_data'

    def validate_type(instance: object,
                      type_class: type | tuple[type],
                      message_name: str) -> None:
        """Validate the type of an instance.
    
        Args:
            instance: The instance to be validated.
            type_class: Acceptable type(s) of the instance.
                        Can be a single type or a tuple of types.
            message_name: The name of the instance to be displayed in the error message.
    
        Raises:
            TypeError: If the instance is not an instance of the acceptable type(s).
        """
        if not isinstance(type_class, (list, tuple)):
            type_class = (type_class, )
        if not isinstance(instance, type_class):
            if len(type_class) == 1:
                type_class = type_class[0]
                type_name = _get_type_name(type_class)
            else:
                type_name_list = [_get_type_name(c) for c in type_class]
                type_name = ' or '.join(type_name_list)
>           raise TypeError(
                f"{message_name} must be an instance of {type_name}, "
                f"got {type(instance)} instead.")
E           TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.

XBrainLab/backend/utils/check.py:31: TypeError
__________________ ERROR at setup of test_edit_event_id_epoch __________________

mne_epoch = <MagicMock name='mock.Epochs()' id='134904589852928'>

    @pytest.fixture
    def epoch(mne_epoch):
        path = 'tests/test_data/sub-01_ses-01_task-rest_eeg.fif'
>       return Raw(path, mne_epoch)

XBrainLab/tests/backend/preprocessor/test_preprocess.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/load_data/raw.py:43: in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = <MagicMock name='mock.Epochs()' id='134904589852928'>
type_class = (<class 'conftest.MockBaseRaw'>, <class 'conftest.MockBaseEpochs'>)
message_name = 'mne_data'

    def validate_type(instance: object,
                      type_class: type | tuple[type],
                      message_name: str) -> None:
        """Validate the type of an instance.
    
        Args:
            instance: The instance to be validated.
            type_class: Acceptable type(s) of the instance.
                        Can be a single type or a tuple of types.
            message_name: The name of the instance to be displayed in the error message.
    
        Raises:
            TypeError: If the instance is not an instance of the acceptable type(s).
        """
        if not isinstance(type_class, (list, tuple)):
            type_class = (type_class, )
        if not isinstance(instance, type_class):
            if len(type_class) == 1:
                type_class = type_class[0]
                type_name = _get_type_name(type_class)
            else:
                type_name_list = [_get_type_name(c) for c in type_class]
                type_name = ' or '.join(type_name_list)
>           raise TypeError(
                f"{message_name} must be an instance of {type_name}, "
                f"got {type(instance)} instead.")
E           TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.

XBrainLab/backend/utils/check.py:31: TypeError
______________ ERROR at setup of test_epoch_wrong_type[TimeEpoch] ______________

mne_epoch = <MagicMock name='mock.Epochs()' id='134904589852928'>

    @pytest.fixture
    def epoch(mne_epoch):
        path = 'tests/test_data/sub-01_ses-01_task-rest_eeg.fif'
>       return Raw(path, mne_epoch)

XBrainLab/tests/backend/preprocessor/test_preprocess.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/load_data/raw.py:43: in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = <MagicMock name='mock.Epochs()' id='134904589852928'>
type_class = (<class 'conftest.MockBaseRaw'>, <class 'conftest.MockBaseEpochs'>)
message_name = 'mne_data'

    def validate_type(instance: object,
                      type_class: type | tuple[type],
                      message_name: str) -> None:
        """Validate the type of an instance.
    
        Args:
            instance: The instance to be validated.
            type_class: Acceptable type(s) of the instance.
                        Can be a single type or a tuple of types.
            message_name: The name of the instance to be displayed in the error message.
    
        Raises:
            TypeError: If the instance is not an instance of the acceptable type(s).
        """
        if not isinstance(type_class, (list, tuple)):
            type_class = (type_class, )
        if not isinstance(instance, type_class):
            if len(type_class) == 1:
                type_class = type_class[0]
                type_name = _get_type_name(type_class)
            else:
                type_name_list = [_get_type_name(c) for c in type_class]
                type_name = ' or '.join(type_name_list)
>           raise TypeError(
                f"{message_name} must be an instance of {type_name}, "
                f"got {type(instance)} instead.")
E           TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.

XBrainLab/backend/utils/check.py:31: TypeError
_____________ ERROR at setup of test_epoch_wrong_type[WindowEpoch] _____________

mne_epoch = <MagicMock name='mock.Epochs()' id='134904589852928'>

    @pytest.fixture
    def epoch(mne_epoch):
        path = 'tests/test_data/sub-01_ses-01_task-rest_eeg.fif'
>       return Raw(path, mne_epoch)

XBrainLab/tests/backend/preprocessor/test_preprocess.py:30: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/load_data/raw.py:43: in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = <MagicMock name='mock.Epochs()' id='134904589852928'>
type_class = (<class 'conftest.MockBaseRaw'>, <class 'conftest.MockBaseEpochs'>)
message_name = 'mne_data'

    def validate_type(instance: object,
                      type_class: type | tuple[type],
                      message_name: str) -> None:
        """Validate the type of an instance.
    
        Args:
            instance: The instance to be validated.
            type_class: Acceptable type(s) of the instance.
                        Can be a single type or a tuple of types.
            message_name: The name of the instance to be displayed in the error message.
    
        Raises:
            TypeError: If the instance is not an instance of the acceptable type(s).
        """
        if not isinstance(type_class, (list, tuple)):
            type_class = (type_class, )
        if not isinstance(instance, type_class):
            if len(type_class) == 1:
                type_class = type_class[0]
                type_name = _get_type_name(type_class)
            else:
                type_name_list = [_get_type_name(c) for c in type_class]
                type_name = ' or '.join(type_name_list)
>           raise TypeError(
                f"{message_name} must be an instance of {type_name}, "
                f"got {type(instance)} instead.")
E           TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.

XBrainLab/backend/utils/check.py:31: TypeError
______________ ERROR at setup of test_train_record_append_record _______________

export_mocker = (<MagicMock name='save' id='134904585769696'>, <MagicMock name='makedirs' id='134904585799040'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebea7610>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebea7640>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebea77c0>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_________ ERROR at setup of test_train_record_append_record_with_step __________

export_mocker = (<MagicMock name='save' id='134904588110000'>, <MagicMock name='makedirs' id='134904586468464'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebfd30a0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebfd3b50>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebfd3d90>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
______ ERROR at setup of test_train_record_append_record_with_large_array ______

export_mocker = (<MagicMock name='save' id='134904584401296'>, <MagicMock name='makedirs' id='134904586839952'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ec0cedc0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ec0ced60>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ec0ce370>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
______ ERROR at setup of test_train_record_append_record_with_small_array ______

export_mocker = (<MagicMock name='save' id='134904585424464'>, <MagicMock name='makedirs' id='134904585832288'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebe330a0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebe335e0>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebeaa130>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
__ ERROR at setup of test_train_record_update_smaller[val-loss-best_val_loss] __

export_mocker = (<MagicMock name='save' id='134904585336624'>, <MagicMock name='makedirs' id='134904585803376'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ec010700>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ec0104f0>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ec010b80>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_ ERROR at setup of test_train_record_update_smaller[test-loss-best_test_loss] _

export_mocker = (<MagicMock name='save' id='134904804081040'>, <MagicMock name='makedirs' id='134904586365872'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebdc5790>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebdc52e0>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebdc50d0>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_ ERROR at setup of test_train_record_update_larger[val-accuracy-best_val_accuracy] _

export_mocker = (<MagicMock name='save' id='134904585206944'>, <MagicMock name='makedirs' id='134904585079632'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ec0f9790>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ec0f9130>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebdc0790>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
___ ERROR at setup of test_train_record_update_larger[val-auc-best_val_auc] ____

export_mocker = (<MagicMock name='save' id='134904588081232'>, <MagicMock name='makedirs' id='134904586257696'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebf13610>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebf13250>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1f8ea0c10>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_ ERROR at setup of test_train_record_update_larger[test-accuracy-best_test_accuracy] _

export_mocker = (<MagicMock name='save' id='134904585349008'>, <MagicMock name='makedirs' id='134904585421872'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebdc2a90>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebdc2e20>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebdc2fd0>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
__ ERROR at setup of test_train_record_update_larger[test-auc-best_test_auc] ___

export_mocker = (<MagicMock name='save' id='134904584867264'>, <MagicMock name='makedirs' id='134904585758704'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebd94100>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebd94370>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebd94eb0>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_______________ ERROR at setup of test_train_record_update_eval ________________

export_mocker = (<MagicMock name='save' id='134904585885440'>, <MagicMock name='makedirs' id='134904588429536'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebec90a0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebec9100>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebec9e20>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_______________ ERROR at setup of test_train_record_update_test ________________

export_mocker = (<MagicMock name='save' id='134904584685696'>, <MagicMock name='makedirs' id='134904585799952'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ec03f9d0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ec03f4f0>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ec03f220>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_______________ ERROR at setup of test_train_record_update_train _______________

export_mocker = (<MagicMock name='save' id='134904584403264'>, <MagicMock name='makedirs' id='134904585726560'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebdc0e50>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebdc07c0>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebdc0b80>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_____________ ERROR at setup of test_train_record_update_statistic _____________

export_mocker = (<MagicMock name='save' id='134904585833632'>, <MagicMock name='makedirs' id='134904584330256'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebe48220>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebe48e80>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebe48700>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
___________________ ERROR at setup of test_train_record_step ___________________

export_mocker = (<MagicMock name='save' id='134904587472656'>, <MagicMock name='makedirs' id='134904588082288'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebe32a60>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebe32fa0>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebe32730>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_ ERROR at setup of test_train_record_test_line_figure[get_loss_figure-loss-True-True-True] _

export_mocker = (<MagicMock name='save' id='134904584859168'>, <MagicMock name='makedirs' id='134904585248976'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebea5f70>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebea55e0>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebea5610>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_ ERROR at setup of test_train_record_test_line_figure[get_loss_figure-loss-True-True-False] _

export_mocker = (<MagicMock name='save' id='134904585285536'>, <MagicMock name='makedirs' id='134904584856384'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebd3dc40>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebd3d490>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebd3d070>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_ ERROR at setup of test_train_record_test_line_figure[get_loss_figure-loss-True-False-True] _

export_mocker = (<MagicMock name='save' id='134904587889440'>, <MagicMock name='makedirs' id='134904803914224'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebe12460>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebe12250>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebe122e0>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_ ERROR at setup of test_train_record_test_line_figure[get_loss_figure-loss-True-False-False] _

export_mocker = (<MagicMock name='save' id='134904585759664'>, <MagicMock name='makedirs' id='134904585201024'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebeae100>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebeae130>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebeae310>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_ ERROR at setup of test_train_record_test_line_figure[get_loss_figure-loss-False-True-True] _

export_mocker = (<MagicMock name='save' id='134904585842352'>, <MagicMock name='makedirs' id='134904584697936'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ec031c10>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ec031af0>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ec031e20>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_ ERROR at setup of test_train_record_test_line_figure[get_loss_figure-loss-False-True-False] _

export_mocker = (<MagicMock name='save' id='134904587337056'>, <MagicMock name='makedirs' id='134904585724448'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebd1ad90>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebd1a970>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebd1afd0>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_ ERROR at setup of test_train_record_test_line_figure[get_loss_figure-loss-False-False-True] _

export_mocker = (<MagicMock name='save' id='134904585883808'>, <MagicMock name='makedirs' id='134904585826016'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebe9feb0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebe9f2e0>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebe9f7c0>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_ ERROR at setup of test_train_record_test_line_figure[get_loss_figure-loss-False-False-False] _

export_mocker = (<MagicMock name='save' id='134904585778224'>, <MagicMock name='makedirs' id='134904587168976'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebfa2820>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebfa2190>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebda56a0>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_ ERROR at setup of test_train_record_test_line_figure[get_acc_figure-accuracy-True-True-True] _

export_mocker = (<MagicMock name='save' id='134904585331904'>, <MagicMock name='makedirs' id='134904586366112'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ec028340>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ec0287f0>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ec028e20>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_ ERROR at setup of test_train_record_test_line_figure[get_acc_figure-accuracy-True-True-False] _

export_mocker = (<MagicMock name='save' id='134904589407232'>, <MagicMock name='makedirs' id='134904587276000'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebf74be0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebf74520>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebe12490>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_ ERROR at setup of test_train_record_test_line_figure[get_acc_figure-accuracy-True-False-True] _

export_mocker = (<MagicMock name='save' id='134904586650384'>, <MagicMock name='makedirs' id='134904804078832'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebe33bb0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebe33040>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebe33dc0>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_ ERROR at setup of test_train_record_test_line_figure[get_acc_figure-accuracy-True-False-False] _

export_mocker = (<MagicMock name='save' id='134904584496032'>, <MagicMock name='makedirs' id='134904584977424'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ec04a430>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ec04a9d0>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ec04abe0>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_ ERROR at setup of test_train_record_test_line_figure[get_acc_figure-accuracy-False-True-True] _

export_mocker = (<MagicMock name='save' id='134904587890160'>, <MagicMock name='makedirs' id='134904589201904'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebe474c0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebe47670>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebe47220>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_ ERROR at setup of test_train_record_test_line_figure[get_acc_figure-accuracy-False-True-False] _

export_mocker = (<MagicMock name='save' id='134904588234272'>, <MagicMock name='makedirs' id='134904586366160'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebe34f10>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebe344f0>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebe34e50>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_ ERROR at setup of test_train_record_test_line_figure[get_acc_figure-accuracy-False-False-True] _

export_mocker = (<MagicMock name='save' id='134904585884672'>, <MagicMock name='makedirs' id='134904584144256'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ec033910>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ec033f70>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ec033ca0>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_ ERROR at setup of test_train_record_test_line_figure[get_acc_figure-accuracy-False-False-False] _

export_mocker = (<MagicMock name='save' id='134904587335040'>, <MagicMock name='makedirs' id='134904585883712'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebdad8b0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebdad7c0>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebdad340>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_ ERROR at setup of test_train_record_test_line_figure[get_auc_figure-auc-True-True-True] _

export_mocker = (<MagicMock name='save' id='134904585331856'>, <MagicMock name='makedirs' id='134904584330640'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebe13c10>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebe13dc0>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebe13820>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_ ERROR at setup of test_train_record_test_line_figure[get_auc_figure-auc-True-True-False] _

export_mocker = (<MagicMock name='save' id='134904803453680'>, <MagicMock name='makedirs' id='134904587292624'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebf2e490>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebf2e3a0>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebf2e100>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_ ERROR at setup of test_train_record_test_line_figure[get_auc_figure-auc-True-False-True] _

export_mocker = (<MagicMock name='save' id='134904590177136'>, <MagicMock name='makedirs' id='134904585772288'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebd46ca0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebd46cd0>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebd46910>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_ ERROR at setup of test_train_record_test_line_figure[get_auc_figure-auc-True-False-False] _

export_mocker = (<MagicMock name='save' id='134904587483312'>, <MagicMock name='makedirs' id='134904585839328'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebff2070>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebff24c0>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebff27c0>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_ ERROR at setup of test_train_record_test_line_figure[get_auc_figure-auc-False-True-True] _

export_mocker = (<MagicMock name='save' id='134904587354656'>, <MagicMock name='makedirs' id='134904584205648'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebe924c0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebe92b80>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebe922b0>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_ ERROR at setup of test_train_record_test_line_figure[get_auc_figure-auc-False-True-False] _

export_mocker = (<MagicMock name='save' id='134904587290320'>, <MagicMock name='makedirs' id='134904584976800'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ec033a90>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ec0330a0>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ec033c10>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_ ERROR at setup of test_train_record_test_line_figure[get_auc_figure-auc-False-False-True] _

export_mocker = (<MagicMock name='save' id='134904588232928'>, <MagicMock name='makedirs' id='134904585724016'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebf8bdc0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebf8be20>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebf8b340>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_ ERROR at setup of test_train_record_test_line_figure[get_auc_figure-auc-False-False-False] _

export_mocker = (<MagicMock name='save' id='134904584875792'>, <MagicMock name='makedirs' id='134904588914496'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ec075340>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ec075e80>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ec0753d0>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
______________ ERROR at setup of test_train_record_test_lr_figure ______________

export_mocker = (<MagicMock name='save' id='134904590057680'>, <MagicMock name='makedirs' id='134904589582640'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ec08f430>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ec08f550>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ec23a6a0>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
__________ ERROR at setup of test_train_record_test_confusion_figure ___________

export_mocker = (<MagicMock name='save' id='134904585330752'>, <MagicMock name='makedirs' id='134904585349344'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebe9dd00>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebe9d550>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebe9df70>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_______ ERROR at setup of test_train_record_eval_record_getter[get_acc] ________

export_mocker = (<MagicMock name='save' id='134904587169456'>, <MagicMock name='makedirs' id='134904585078624'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebf79040>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebf79190>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebf791f0>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_______ ERROR at setup of test_train_record_eval_record_getter[get_auc] ________

export_mocker = (<MagicMock name='save' id='134904586654576'>, <MagicMock name='makedirs' id='134904585759424'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ec017ee0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ec017700>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ec017460>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
______ ERROR at setup of test_train_record_eval_record_getter[get_kappa] _______

export_mocker = (<MagicMock name='save' id='134904585840864'>, <MagicMock name='makedirs' id='134904587357056'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebf664c0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebf662e0>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebf662b0>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
___ ERROR at setup of test_train_record_eval_record_getter[get_eval_record] ____

export_mocker = (<MagicMock name='save' id='134904586594384'>, <MagicMock name='makedirs' id='134904585196928'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebdf4580>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebdf4370>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebeb0250>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_________________ ERROR at setup of test_export[accuracy-val] __________________

export_mocker = (<MagicMock name='save' id='134904584330640'>, <MagicMock name='makedirs' id='134904803453344'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebd6bdc0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebd6bd90>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebd6bbb0>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_________________ ERROR at setup of test_export[accuracy-test] _________________

export_mocker = (<MagicMock name='save' id='134904803500240'>, <MagicMock name='makedirs' id='134904584698944'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ec0866d0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ec086700>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ec0869d0>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
____________________ ERROR at setup of test_export[auc-val] ____________________

export_mocker = (<MagicMock name='save' id='134904585798176'>, <MagicMock name='makedirs' id='134904587272400'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ec04f760>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ec04fa60>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ec04f8e0>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
___________________ ERROR at setup of test_export[auc-test] ____________________

export_mocker = (<MagicMock name='save' id='134904804410656'>, <MagicMock name='makedirs' id='134904584370016'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1f8e36e20>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1f8e36910>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1f8e36d30>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
___________________ ERROR at setup of test_export[loss-val] ____________________

export_mocker = (<MagicMock name='save' id='134904584411792'>, <MagicMock name='makedirs' id='134904584857728'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ec06beb0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ec06bf10>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ec06b130>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
___________________ ERROR at setup of test_export[loss-test] ___________________

export_mocker = (<MagicMock name='save' id='134904584294944'>, <MagicMock name='makedirs' id='134904586838416'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ec0697c0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ec069760>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ec0a2c40>

    @pytest.fixture()
    def train_record(export_mocker, dataset, training_option, model_holder): # noqa: F811
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:159: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
____________ ERROR at setup of test_training_plan_holder_get_loader ____________

export_mocker = (<MagicMock name='save' id='134904587140496'>, <MagicMock name='makedirs' id='134904587656640'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ec04ae80>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ec03bf70>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ec03ba90>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
__ ERROR at setup of test_training_plan_holder_get_eval_loader[val-test-test] __

export_mocker = (<MagicMock name='save' id='134904587529712'>, <MagicMock name='makedirs' id='134904587244352'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ec0806a0>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ec0800a0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ec080310>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_loader[None-test-test] __

export_mocker = (<MagicMock name='save' id='134904584971648'>, <MagicMock name='makedirs' id='134904584422016'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebd5caf0>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ec0f6d90>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ec0f6f70>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
__ ERROR at setup of test_training_plan_holder_get_eval_loader[val-None-val] ___

export_mocker = (<MagicMock name='save' id='134904584457040'>, <MagicMock name='makedirs' id='134904583643584'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebfcf5e0>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebfbf190>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebfbf1c0>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_loader[None-None-None] __

export_mocker = (<MagicMock name='save' id='134904586954544'>, <MagicMock name='makedirs' id='134904586781984'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebc77490>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebc77d90>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebc77dc0>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_model[test-TRAINING_EVALUATION.VAL_LOSS-best_val_loss_model0] _

export_mocker = (<MagicMock name='save' id='134904586785888'>, <MagicMock name='makedirs' id='134904587026240'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebd54ca0>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebc55d90>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebc55dc0>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_model[test-TRAINING_EVALUATION.VAL_LOSS-best_val_loss_model1] _

export_mocker = (<MagicMock name='save' id='134904585655536'>, <MagicMock name='makedirs' id='134904586636016'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebd79fa0>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1f8e54f10>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebff4f10>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_model[test-TRAINING_EVALUATION.TEST_AUC-best_test_auc_model0] _

export_mocker = (<MagicMock name='save' id='134904583745984'>, <MagicMock name='makedirs' id='134904584457520'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebc686a0>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebc73310>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebc73070>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_model[test-TRAINING_EVALUATION.TEST_AUC-best_test_auc_model1] _

export_mocker = (<MagicMock name='save' id='134904584613168'>, <MagicMock name='makedirs' id='134904585755328'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebf8bcd0>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebe9f1c0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebe9fee0>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_model[test-TRAINING_EVALUATION.TEST_ACC-best_test_accuracy_model0] _

export_mocker = (<MagicMock name='save' id='134904586747472'>, <MagicMock name='makedirs' id='134904585203920'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebd47970>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ec005130>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ec0050a0>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_model[test-TRAINING_EVALUATION.TEST_ACC-best_test_accuracy_model1] _

export_mocker = (<MagicMock name='save' id='134904583667472'>, <MagicMock name='makedirs' id='134904586583200'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ec0d1460>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebcc7730>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebcc7760>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_model[None-TRAINING_EVALUATION.VAL_LOSS-best_val_loss_model0] _

export_mocker = (<MagicMock name='save' id='134904583611008'>, <MagicMock name='makedirs' id='134904587772256'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebdbe430>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebc5e580>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebc5e5b0>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_model[None-TRAINING_EVALUATION.VAL_LOSS-best_val_loss_model1] _

export_mocker = (<MagicMock name='save' id='134904583498144'>, <MagicMock name='makedirs' id='134904585558288'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebe5f940>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebe77f40>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebe77ee0>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_model[None-TRAINING_EVALUATION.TEST_AUC-best_test_auc_model0] _

export_mocker = (<MagicMock name='save' id='134904585475936'>, <MagicMock name='makedirs' id='134904585504080'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebe67eb0>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebe678b0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebe67880>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_model[None-TRAINING_EVALUATION.TEST_AUC-best_test_auc_model1] _

export_mocker = (<MagicMock name='save' id='134904585648352'>, <MagicMock name='makedirs' id='134904585539984'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebe5a100>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebe5aa00>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebe5aa30>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_model[None-TRAINING_EVALUATION.TEST_ACC-best_test_accuracy_model0] _

export_mocker = (<MagicMock name='save' id='134904582770064'>, <MagicMock name='makedirs' id='134904583225008'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebdeb640>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebdeb190>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebdeb9d0>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_model[None-TRAINING_EVALUATION.TEST_ACC-best_test_accuracy_model1] _

export_mocker = (<MagicMock name='save' id='134904585558912'>, <MagicMock name='makedirs' id='134904585516944'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebe59100>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebe59610>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebe59eb0>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.VAL_LOSS-val-test-test] _

export_mocker = (<MagicMock name='save' id='134904585491072'>, <MagicMock name='makedirs' id='134904582689984'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebf74d90>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebcafa90>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebcafd00>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.VAL_LOSS-None-test-test] _

export_mocker = (<MagicMock name='save' id='134904586785792'>, <MagicMock name='makedirs' id='134904585418352'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebf94b50>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebc68e50>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebc68fd0>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.VAL_LOSS-val-None-val] _

export_mocker = (<MagicMock name='save' id='134904585147632'>, <MagicMock name='makedirs' id='134904587694528'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebcc7880>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebc6c6a0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebc6cca0>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.VAL_LOSS-None-None-None] _

export_mocker = (<MagicMock name='save' id='134904585207136'>, <MagicMock name='makedirs' id='134904586953008'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebfcddf0>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebfcdd60>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebfcd160>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.TEST_AUC-val-test-test] _

export_mocker = (<MagicMock name='save' id='134904584613840'>, <MagicMock name='makedirs' id='134904587722272'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ec00a820>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ec00a2e0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ec00a220>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.TEST_AUC-None-test-test] _

export_mocker = (<MagicMock name='save' id='134904587266800'>, <MagicMock name='makedirs' id='134904584414016'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ec069b80>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebc77a60>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebc77340>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.TEST_AUC-val-None-val] _

export_mocker = (<MagicMock name='save' id='134904583519488'>, <MagicMock name='makedirs' id='134904582772384'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebe03b50>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebc4ee50>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebc4eca0>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.TEST_AUC-None-None-None] _

export_mocker = (<MagicMock name='save' id='134904585140928'>, <MagicMock name='makedirs' id='134904582942240'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebde54c0>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebdf2610>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebdf2670>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.TEST_ACC-val-test-test] _

export_mocker = (<MagicMock name='save' id='134904585119008'>, <MagicMock name='makedirs' id='134904585063728'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebdee5e0>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebdeeee0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebdeef10>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.TEST_ACC-None-test-test] _

export_mocker = (<MagicMock name='save' id='134904585033040'>, <MagicMock name='makedirs' id='134904585019152'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebbc1e20>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebbeaee0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebbeadf0>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.TEST_ACC-val-None-val] _

export_mocker = (<MagicMock name='save' id='134904587749120'>, <MagicMock name='makedirs' id='134904585138816'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebd102b0>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebdd8af0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebdd8e80>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.TEST_ACC-None-None-None] _

export_mocker = (<MagicMock name='save' id='134904584330448'>, <MagicMock name='makedirs' id='134904582792384'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebc2bdf0>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebc8e1c0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebc8eb20>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.LAST_EPOCH-val-test-test] _

export_mocker = (<MagicMock name='save' id='134904585551296'>, <MagicMock name='makedirs' id='134904583265728'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebbad970>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebcbf3d0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebcbff40>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.LAST_EPOCH-None-test-test] _

export_mocker = (<MagicMock name='save' id='134904584856336'>, <MagicMock name='makedirs' id='134904584552352'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebe05c70>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebc6cdc0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebc6c850>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.LAST_EPOCH-val-None-val] _

export_mocker = (<MagicMock name='save' id='134904585146960'>, <MagicMock name='makedirs' id='134904587335328'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebe5f850>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebdebee0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebdeb610>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.LAST_EPOCH-None-None-None] _

export_mocker = (<MagicMock name='save' id='134904585503024'>, <MagicMock name='makedirs' id='134904583223856'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ec0050d0>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ec0655b0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ec065d90>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_pair_not_implemented[None-val-test-test] _

export_mocker = (<MagicMock name='save' id='134904583378448'>, <MagicMock name='makedirs' id='134904585647488'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebc68ac0>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebcb23d0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebcb2790>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_pair_not_implemented[None-None-test-test] _

export_mocker = (<MagicMock name='save' id='134904583456272'>, <MagicMock name='makedirs' id='134904583724288'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebbf2070>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebbf2e20>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebbf2dc0>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_pair_not_implemented[None-val-None-val] _

export_mocker = (<MagicMock name='save' id='134904583282448'>, <MagicMock name='makedirs' id='134904582831216'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebbe1a90>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebbe1100>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebbe1f40>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_pair_not_implemented[None-None-None-None] _

export_mocker = (<MagicMock name='save' id='134904583924512'>, <MagicMock name='makedirs' id='134904582769104'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ec020a00>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebe77130>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebe77220>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_get_eval_model_by_lastest_model __

export_mocker = (<MagicMock name='save' id='134904586781312'>, <MagicMock name='makedirs' id='134904582933568'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebcf4040>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebcf4790>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebcf47f0>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
__________ ERROR at setup of test_training_plan_holder_set_interrupt ___________

export_mocker = (<MagicMock name='save' id='134904584029664'>, <MagicMock name='makedirs' id='134904585502880'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebc5b670>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebc8edc0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebc8eb20>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
__________ ERROR at setup of test_training_plan_holder_trivial_getter __________

export_mocker = (<MagicMock name='save' id='134904583318784'>, <MagicMock name='makedirs' id='134904585121312'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebba3f40>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebf2e100>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebf2e7f0>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_________ ERROR at setup of test_training_plan_holder_one_epoch[True] __________

export_mocker = (<MagicMock name='save' id='134904583665936'>, <MagicMock name='makedirs' id='134904587751328'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebfebdf0>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebc72f70>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebc72fa0>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_________ ERROR at setup of test_training_plan_holder_one_epoch[False] _________

export_mocker = (<MagicMock name='save' id='134904583214704'>, <MagicMock name='makedirs' id='134904582689504'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebcdc880>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebcdc5b0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebcdc310>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_________ ERROR at setup of test_training_plan_holder_train_one_repeat _________

export_mocker = (<MagicMock name='save' id='134904583415696'>, <MagicMock name='makedirs' id='134904584964848'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebb663d0>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebb66a60>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebb66a90>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_____ ERROR at setup of test_training_plan_holder_train_one_repeat_status ______

export_mocker = (<MagicMock name='save' id='134904584973376'>, <MagicMock name='makedirs' id='134904585062384'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ec079280>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebdd49d0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebdd4af0>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_train_one_repeat_empty_training_data _

export_mocker = (<MagicMock name='save' id='134904587722320'>, <MagicMock name='makedirs' id='134904586957152'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebe47490>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebc4ed30>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebc4e550>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
______ ERROR at setup of test_training_plan_holder_train_one_repeat_eval _______

export_mocker = (<MagicMock name='save' id='134904586952960'>, <MagicMock name='makedirs' id='134904583265248'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebd07880>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebe05a30>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebe05250>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
_ ERROR at setup of test_training_plan_holder_train_one_repeat_already_finished _

export_mocker = (<MagicMock name='save' id='134904583003056'>, <MagicMock name='makedirs' id='134904583009568'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebbcd9d0>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebc03790>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebc03760>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
______________ ERROR at setup of test_training_plan_holder_train _______________

export_mocker = (<MagicMock name='save' id='134904585052416'>, <MagicMock name='makedirs' id='134904586744496'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebd07790>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebbc1700>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebbc17f0>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
___________ ERROR at setup of test_training_plan_holder_train_status ___________

export_mocker = (<MagicMock name='save' id='134904584107104'>, <MagicMock name='makedirs' id='134904587176592'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebdf0580>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ec073880>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ec073af0>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
___________ ERROR at setup of test_training_plan_holder_train_error ____________

export_mocker = (<MagicMock name='save' id='134904584457664'>, <MagicMock name='makedirs' id='134904582689792'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebc2fac0>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebfcfd30>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebfcf370>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
____________ ERROR at setup of test_training_plan_holder_init_error ____________

export_mocker = (<MagicMock name='save' id='134904582226176'>, <MagicMock name='makedirs' id='134904584060400'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebced430>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebcd58b0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebcd5910>

    @pytest.fixture
    def base_holder(export_mocker, model_holder, dataset, training_option):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
>       return TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:149: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
---------------------------- Captured stdout setup -----------------------------
No saliency parameter is set, using default parameters.
______________________ ERROR at setup of test_test_model _______________________

    @pytest.fixture
    def loss_avg():
        criterion = torch.nn.CrossEntropyLoss()
        error_loss = criterion(
            torch.Tensor([[0, 0, 0, 1]]), torch.Tensor([0]).long()
        ).item()
        correct_loss = criterion(
            torch.Tensor([[1, 0, 0, 0]]), torch.Tensor([0]).long()
        ).item()
>       loss = np.ones(TOTAL_NUM) * correct_loss
E       ValueError: operands could not be broadcast together with shapes (20,) (0,)

XBrainLab/tests/backend/training/test_training_plan_test_model.py:104: ValueError
=================================== FAILURES ===================================
__________________________ test_dataset_set_test_mask __________________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ecb4be20>

    def test_dataset_set_test_mask(
        epochs, # noqa: F811
    ):
        config = DataSplittingConfig(TrainingType.IND, False, [], [])
        dataset = Dataset(epochs, config)
        mask = np.zeros(epochs.get_data_length(), dtype=bool)
    
        total = epochs.get_data_length()
        # set test
        mask[:3] = True
        dataset.set_test(mask)
        assert dataset.has_set_empty()
        assert sum(dataset.get_remaining_mask()) == (total - 3)
    
        # set val
        mask[3:9] = True
        dataset.set_val(mask)
        assert dataset.has_set_empty()
>       assert sum(dataset.get_remaining_mask()) == (total - 9)
E       assert 0 == (6 - 9)
E        +  where 0 = sum(array([False, False, False, False, False, False]))
E        +    where array([False, False, False, False, False, False]) = get_remaining_mask()
E        +      where get_remaining_mask = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ecadf490>.get_remaining_mask

XBrainLab/tests/backend/dataset/test_dataset.py:70: AssertionError
__________________ test_dataset_set_remaining_by_subject_idx ___________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ecab50a0>

    def test_dataset_set_remaining_by_subject_idx(
        epochs, # noqa: F811
    ):
        config = DataSplittingConfig(TrainingType.IND, False, [], [])
        dataset = Dataset(epochs, config)
        dataset.set_remaining_by_subject_idx(0)
>       assert dataset.get_remaining_mask()[:block_size * len(session_list)].all()
E       assert False
E        +  where False = <built-in method all of numpy.ndarray object at 0x7ab1ecaa2f90>()
E        +    where <built-in method all of numpy.ndarray object at 0x7ab1ecaa2f90> = array([ True,  True, False, False, False, False]).all

XBrainLab/tests/backend/dataset/test_dataset.py:100: AssertionError
_____________ test_dataset_intersection_with_subject_by_idx[0-24] ______________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ecac0a60>
start = 0, end = 24

    @pytest.mark.parametrize('start, end', [
        (subject_count, subject_count * 2),
        (half_subject_count, subject_count),
        (0, subject_count * 2),
        (subject_count, subject_count * 2)
    ])
    def test_dataset_intersection_with_subject_by_idx(
        epochs, # noqa: F811
        start, end
    ):
        config = DataSplittingConfig(TrainingType.IND, False, [], [])
        dataset = Dataset(epochs, config)
        mask = np.zeros(epochs.get_data_length(), dtype=bool)
    
        mask[start:end] = True
        result = dataset.intersection_with_subject_by_idx(mask, 0)
>       assert (result[:subject_count] == mask[:subject_count]).all()
E       assert False
E        +  where False = <built-in method all of numpy.ndarray object at 0x7ab1ecacb0f0>()
E        +    where <built-in method all of numpy.ndarray object at 0x7ab1ecacb0f0> = array([ True,...False, False]) == array([ True,... True,  True])
E             
E             Full diff:
E             - array([ True,  True,  True,  True,  True,  True])
E             + array([ True,  True, False, False, False, False]).all

XBrainLab/tests/backend/dataset/test_dataset.py:122: AssertionError
____________________________ test_dataset_get_data _____________________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1eca4cc10>

    def test_dataset_get_data(
        epochs, # noqa: F811
    ):
        config = DataSplittingConfig(TrainingType.IND, False, [], [])
        dataset = Dataset(epochs, config)
        mask = np.zeros(epochs.get_data_length(), dtype=bool)
        mask[:subject_count] = True
        dataset.set_test(mask)
    
        mask &= False
        mask[subject_count:subject_count * 2] = True
        dataset.set_val(mask)
    
        mask &= False
        mask[subject_count * 3:] = True
        dataset.discard_remaining_mask(mask)
        dataset.set_remaining_to_train()
    
        X, y = dataset.get_training_data()
        assert (X // 100000 == 3).all()
>       assert np.array_equal(
            y,
            np.tile(np.arange(n_class).repeat(n_trial), len(session_list))
        )
E       AssertionError: assert False
E        +  where False = <function array_equal at 0x7ab2549cdb80>(array([], dtype=float64), array([0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1]))
E        +    where <function array_equal at 0x7ab2549cdb80> = np.array_equal
E        +    and   array([0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1]) = <function tile at 0x7ab2527923a0>(array([0, 0, 0, 1, 1, 1]), 2)
E        +      where <function tile at 0x7ab2527923a0> = np.tile
E        +      and   array([0, 0, 0, 1, 1, 1]) = <built-in method repeat of numpy.ndarray object at 0x7ab1ecacbf30>(3)
E        +        where <built-in method repeat of numpy.ndarray object at 0x7ab1ecacbf30> = array([0, 1]).repeat
E        +          where array([0, 1]) = <built-in function arange>(2)
E        +            where <built-in function arange> = np.arange
E        +      and   2 = len(['1', '2'])

XBrainLab/tests/backend/dataset/test_dataset.py:146: AssertionError
_____ test_dataset_generator_split_test[SplitByType.SESSION-pick_session] ______

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ecab6340>
split_type = <SplitByType.SESSION: 'By Session'>, mock_target = 'pick_session'

    @pytest.mark.parametrize('split_type, mock_target', [
        (SplitByType.SESSION, 'pick_session'),
        (SplitByType.SESSION_IND, 'pick_session'),
        (SplitByType.SUBJECT, 'pick_subject'),
        (SplitByType.SUBJECT_IND, 'pick_subject'),
        (SplitByType.TRIAL, 'pick_trial'),
        (SplitByType.TRIAL_IND, 'pick_trial')
    ])
    def test_dataset_generator_split_test(
        epochs, # noqa: F811
        split_type, mock_target
    ):
        # prepare generator
        train_type = TrainingType.IND
        is_cross_validation = False
        split_value = 0.2
        split_unit = SplitUnit.RATIO
        test_splitter_list = [
            DataSplitter(split_type, split_value, split_unit)
        ]
        val_splitter_list = []
        config = DataSplittingConfig(
            train_type, is_cross_validation, val_splitter_list, test_splitter_list
        )
        generator = DatasetGenerator(epochs, config)
    
        test_mask = np.zeros(epochs.get_data_length(), dtype=bool)
        test_mask[:3] = True
        expected_next_mask = np.array([False, True, False, True, False])
    
        with patch.object(epochs, mock_target, return_value=(test_mask, expected_next_mask)) as split_func_mock:
            dataset = Dataset(epochs, config)
            group_idx = 0
            mask = np.zeros(epochs.get_data_length(), dtype=bool)
            clean_mask = np.zeros(epochs.get_data_length(), dtype=bool)
            next_mask = generator.split_test(dataset, group_idx, mask, clean_mask)
            call_args = split_func_mock.call_args[1]
            assert np.array_equal(call_args['mask'], mask)
            assert np.array_equal(call_args['clean_mask'], clean_mask)
            assert call_args['value'] == split_value
            assert call_args['split_unit'] == split_unit
            assert call_args['group_idx'] == group_idx
    
        assert dataset.get_test_len() == 3
        X, y = dataset.get_test_data()
        for i in range(3):
            expected = np.zeros(X[i].shape)
            expected[:, :] = 1 * 100000 + 1 * 1000 + i
>           assert np.array_equal(X[i], expected)
E           assert False
E            +  where False = <function array_equal at 0x7ab2549cdb80>(array([[0]]), array([[101000.]]))
E            +    where <function array_equal at 0x7ab2549cdb80> = np.array_equal

XBrainLab/tests/backend/dataset/test_dataset_generator.py:90: AssertionError
___ test_dataset_generator_split_test[SplitByType.SESSION_IND-pick_session] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ecd31460>
split_type = <SplitByType.SESSION_IND: 'By Session (Independent)'>
mock_target = 'pick_session'

    @pytest.mark.parametrize('split_type, mock_target', [
        (SplitByType.SESSION, 'pick_session'),
        (SplitByType.SESSION_IND, 'pick_session'),
        (SplitByType.SUBJECT, 'pick_subject'),
        (SplitByType.SUBJECT_IND, 'pick_subject'),
        (SplitByType.TRIAL, 'pick_trial'),
        (SplitByType.TRIAL_IND, 'pick_trial')
    ])
    def test_dataset_generator_split_test(
        epochs, # noqa: F811
        split_type, mock_target
    ):
        # prepare generator
        train_type = TrainingType.IND
        is_cross_validation = False
        split_value = 0.2
        split_unit = SplitUnit.RATIO
        test_splitter_list = [
            DataSplitter(split_type, split_value, split_unit)
        ]
        val_splitter_list = []
        config = DataSplittingConfig(
            train_type, is_cross_validation, val_splitter_list, test_splitter_list
        )
        generator = DatasetGenerator(epochs, config)
    
        test_mask = np.zeros(epochs.get_data_length(), dtype=bool)
        test_mask[:3] = True
        expected_next_mask = np.array([False, True, False, True, False])
    
        with patch.object(epochs, mock_target, return_value=(test_mask, expected_next_mask)) as split_func_mock:
            dataset = Dataset(epochs, config)
            group_idx = 0
            mask = np.zeros(epochs.get_data_length(), dtype=bool)
            clean_mask = np.zeros(epochs.get_data_length(), dtype=bool)
            next_mask = generator.split_test(dataset, group_idx, mask, clean_mask)
            call_args = split_func_mock.call_args[1]
            assert np.array_equal(call_args['mask'], mask)
            assert np.array_equal(call_args['clean_mask'], clean_mask)
            assert call_args['value'] == split_value
            assert call_args['split_unit'] == split_unit
            assert call_args['group_idx'] == group_idx
    
        assert dataset.get_test_len() == 3
        X, y = dataset.get_test_data()
        for i in range(3):
            expected = np.zeros(X[i].shape)
            expected[:, :] = 1 * 100000 + 1 * 1000 + i
>           assert np.array_equal(X[i], expected)
E           assert False
E            +  where False = <function array_equal at 0x7ab2549cdb80>(array([[0]]), array([[101000.]]))
E            +    where <function array_equal at 0x7ab2549cdb80> = np.array_equal

XBrainLab/tests/backend/dataset/test_dataset_generator.py:90: AssertionError
_____ test_dataset_generator_split_test[SplitByType.SUBJECT-pick_subject] ______

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1eca692b0>
split_type = <SplitByType.SUBJECT: 'By Subject'>, mock_target = 'pick_subject'

    @pytest.mark.parametrize('split_type, mock_target', [
        (SplitByType.SESSION, 'pick_session'),
        (SplitByType.SESSION_IND, 'pick_session'),
        (SplitByType.SUBJECT, 'pick_subject'),
        (SplitByType.SUBJECT_IND, 'pick_subject'),
        (SplitByType.TRIAL, 'pick_trial'),
        (SplitByType.TRIAL_IND, 'pick_trial')
    ])
    def test_dataset_generator_split_test(
        epochs, # noqa: F811
        split_type, mock_target
    ):
        # prepare generator
        train_type = TrainingType.IND
        is_cross_validation = False
        split_value = 0.2
        split_unit = SplitUnit.RATIO
        test_splitter_list = [
            DataSplitter(split_type, split_value, split_unit)
        ]
        val_splitter_list = []
        config = DataSplittingConfig(
            train_type, is_cross_validation, val_splitter_list, test_splitter_list
        )
        generator = DatasetGenerator(epochs, config)
    
        test_mask = np.zeros(epochs.get_data_length(), dtype=bool)
        test_mask[:3] = True
        expected_next_mask = np.array([False, True, False, True, False])
    
        with patch.object(epochs, mock_target, return_value=(test_mask, expected_next_mask)) as split_func_mock:
            dataset = Dataset(epochs, config)
            group_idx = 0
            mask = np.zeros(epochs.get_data_length(), dtype=bool)
            clean_mask = np.zeros(epochs.get_data_length(), dtype=bool)
            next_mask = generator.split_test(dataset, group_idx, mask, clean_mask)
            call_args = split_func_mock.call_args[1]
            assert np.array_equal(call_args['mask'], mask)
            assert np.array_equal(call_args['clean_mask'], clean_mask)
            assert call_args['value'] == split_value
            assert call_args['split_unit'] == split_unit
            assert call_args['group_idx'] == group_idx
    
        assert dataset.get_test_len() == 3
        X, y = dataset.get_test_data()
        for i in range(3):
            expected = np.zeros(X[i].shape)
            expected[:, :] = 1 * 100000 + 1 * 1000 + i
>           assert np.array_equal(X[i], expected)
E           assert False
E            +  where False = <function array_equal at 0x7ab2549cdb80>(array([[0]]), array([[101000.]]))
E            +    where <function array_equal at 0x7ab2549cdb80> = np.array_equal

XBrainLab/tests/backend/dataset/test_dataset_generator.py:90: AssertionError
___ test_dataset_generator_split_test[SplitByType.SUBJECT_IND-pick_subject] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ecc98be0>
split_type = <SplitByType.SUBJECT_IND: 'By Subject (Independent)'>
mock_target = 'pick_subject'

    @pytest.mark.parametrize('split_type, mock_target', [
        (SplitByType.SESSION, 'pick_session'),
        (SplitByType.SESSION_IND, 'pick_session'),
        (SplitByType.SUBJECT, 'pick_subject'),
        (SplitByType.SUBJECT_IND, 'pick_subject'),
        (SplitByType.TRIAL, 'pick_trial'),
        (SplitByType.TRIAL_IND, 'pick_trial')
    ])
    def test_dataset_generator_split_test(
        epochs, # noqa: F811
        split_type, mock_target
    ):
        # prepare generator
        train_type = TrainingType.IND
        is_cross_validation = False
        split_value = 0.2
        split_unit = SplitUnit.RATIO
        test_splitter_list = [
            DataSplitter(split_type, split_value, split_unit)
        ]
        val_splitter_list = []
        config = DataSplittingConfig(
            train_type, is_cross_validation, val_splitter_list, test_splitter_list
        )
        generator = DatasetGenerator(epochs, config)
    
        test_mask = np.zeros(epochs.get_data_length(), dtype=bool)
        test_mask[:3] = True
        expected_next_mask = np.array([False, True, False, True, False])
    
        with patch.object(epochs, mock_target, return_value=(test_mask, expected_next_mask)) as split_func_mock:
            dataset = Dataset(epochs, config)
            group_idx = 0
            mask = np.zeros(epochs.get_data_length(), dtype=bool)
            clean_mask = np.zeros(epochs.get_data_length(), dtype=bool)
            next_mask = generator.split_test(dataset, group_idx, mask, clean_mask)
            call_args = split_func_mock.call_args[1]
            assert np.array_equal(call_args['mask'], mask)
            assert np.array_equal(call_args['clean_mask'], clean_mask)
            assert call_args['value'] == split_value
            assert call_args['split_unit'] == split_unit
            assert call_args['group_idx'] == group_idx
    
        assert dataset.get_test_len() == 3
        X, y = dataset.get_test_data()
        for i in range(3):
            expected = np.zeros(X[i].shape)
            expected[:, :] = 1 * 100000 + 1 * 1000 + i
>           assert np.array_equal(X[i], expected)
E           assert False
E            +  where False = <function array_equal at 0x7ab2549cdb80>(array([[0]]), array([[101000.]]))
E            +    where <function array_equal at 0x7ab2549cdb80> = np.array_equal

XBrainLab/tests/backend/dataset/test_dataset_generator.py:90: AssertionError
_______ test_dataset_generator_split_test[SplitByType.TRIAL-pick_trial] ________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab236bd9d30>
split_type = <SplitByType.TRIAL: 'By Trial'>, mock_target = 'pick_trial'

    @pytest.mark.parametrize('split_type, mock_target', [
        (SplitByType.SESSION, 'pick_session'),
        (SplitByType.SESSION_IND, 'pick_session'),
        (SplitByType.SUBJECT, 'pick_subject'),
        (SplitByType.SUBJECT_IND, 'pick_subject'),
        (SplitByType.TRIAL, 'pick_trial'),
        (SplitByType.TRIAL_IND, 'pick_trial')
    ])
    def test_dataset_generator_split_test(
        epochs, # noqa: F811
        split_type, mock_target
    ):
        # prepare generator
        train_type = TrainingType.IND
        is_cross_validation = False
        split_value = 0.2
        split_unit = SplitUnit.RATIO
        test_splitter_list = [
            DataSplitter(split_type, split_value, split_unit)
        ]
        val_splitter_list = []
        config = DataSplittingConfig(
            train_type, is_cross_validation, val_splitter_list, test_splitter_list
        )
        generator = DatasetGenerator(epochs, config)
    
        test_mask = np.zeros(epochs.get_data_length(), dtype=bool)
        test_mask[:3] = True
        expected_next_mask = np.array([False, True, False, True, False])
    
        with patch.object(epochs, mock_target, return_value=(test_mask, expected_next_mask)) as split_func_mock:
            dataset = Dataset(epochs, config)
            group_idx = 0
            mask = np.zeros(epochs.get_data_length(), dtype=bool)
            clean_mask = np.zeros(epochs.get_data_length(), dtype=bool)
            next_mask = generator.split_test(dataset, group_idx, mask, clean_mask)
            call_args = split_func_mock.call_args[1]
            assert np.array_equal(call_args['mask'], mask)
            assert np.array_equal(call_args['clean_mask'], clean_mask)
            assert call_args['value'] == split_value
            assert call_args['split_unit'] == split_unit
            assert call_args['group_idx'] == group_idx
    
        assert dataset.get_test_len() == 3
        X, y = dataset.get_test_data()
        for i in range(3):
            expected = np.zeros(X[i].shape)
            expected[:, :] = 1 * 100000 + 1 * 1000 + i
>           assert np.array_equal(X[i], expected)
E           assert False
E            +  where False = <function array_equal at 0x7ab2549cdb80>(array([[0]]), array([[101000.]]))
E            +    where <function array_equal at 0x7ab2549cdb80> = np.array_equal

XBrainLab/tests/backend/dataset/test_dataset_generator.py:90: AssertionError
_____ test_dataset_generator_split_test[SplitByType.TRIAL_IND-pick_trial] ______

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ecbe4b80>
split_type = <SplitByType.TRIAL_IND: 'By Trial (Independent)'>
mock_target = 'pick_trial'

    @pytest.mark.parametrize('split_type, mock_target', [
        (SplitByType.SESSION, 'pick_session'),
        (SplitByType.SESSION_IND, 'pick_session'),
        (SplitByType.SUBJECT, 'pick_subject'),
        (SplitByType.SUBJECT_IND, 'pick_subject'),
        (SplitByType.TRIAL, 'pick_trial'),
        (SplitByType.TRIAL_IND, 'pick_trial')
    ])
    def test_dataset_generator_split_test(
        epochs, # noqa: F811
        split_type, mock_target
    ):
        # prepare generator
        train_type = TrainingType.IND
        is_cross_validation = False
        split_value = 0.2
        split_unit = SplitUnit.RATIO
        test_splitter_list = [
            DataSplitter(split_type, split_value, split_unit)
        ]
        val_splitter_list = []
        config = DataSplittingConfig(
            train_type, is_cross_validation, val_splitter_list, test_splitter_list
        )
        generator = DatasetGenerator(epochs, config)
    
        test_mask = np.zeros(epochs.get_data_length(), dtype=bool)
        test_mask[:3] = True
        expected_next_mask = np.array([False, True, False, True, False])
    
        with patch.object(epochs, mock_target, return_value=(test_mask, expected_next_mask)) as split_func_mock:
            dataset = Dataset(epochs, config)
            group_idx = 0
            mask = np.zeros(epochs.get_data_length(), dtype=bool)
            clean_mask = np.zeros(epochs.get_data_length(), dtype=bool)
            next_mask = generator.split_test(dataset, group_idx, mask, clean_mask)
            call_args = split_func_mock.call_args[1]
            assert np.array_equal(call_args['mask'], mask)
            assert np.array_equal(call_args['clean_mask'], clean_mask)
            assert call_args['value'] == split_value
            assert call_args['split_unit'] == split_unit
            assert call_args['group_idx'] == group_idx
    
        assert dataset.get_test_len() == 3
        X, y = dataset.get_test_data()
        for i in range(3):
            expected = np.zeros(X[i].shape)
            expected[:, :] = 1 * 100000 + 1 * 1000 + i
>           assert np.array_equal(X[i], expected)
E           assert False
E            +  where False = <function array_equal at 0x7ab2549cdb80>(array([[0]]), array([[101000.]]))
E            +    where <function array_equal at 0x7ab2549cdb80> = np.array_equal

XBrainLab/tests/backend/dataset/test_dataset_generator.py:90: AssertionError
_ test_dataset_generator_split_validation[ValSplitByType.SESSION-pick_session] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ecbfae50>
split_type = <ValSplitByType.SESSION: 'By Session'>
mock_target = 'pick_session'

    @pytest.mark.parametrize('split_type, mock_target', [
        (ValSplitByType.SESSION, 'pick_session'),
        (ValSplitByType.SUBJECT, 'pick_subject'),
        (ValSplitByType.TRIAL, 'pick_trial'),
    ])
    def test_dataset_generator_split_validation(
        epochs, # noqa: F811
        split_type, mock_target
    ):
        train_type = TrainingType.FULL
        is_cross_validation = False
        split_value = 0.2
        split_unit = SplitUnit.RATIO
        val_splitter_list = [
            DataSplitter(split_type, split_value, split_unit)
        ]
        test_splitter_list = []
        config = DataSplittingConfig(
            train_type, is_cross_validation, val_splitter_list, test_splitter_list
        )
        generator = DatasetGenerator(epochs, config)
        dataset = Dataset(epochs, config)
    
        mask = np.ones(epochs.get_data_length(), dtype=bool)
    
        test_mask = np.zeros(epochs.get_data_length(), dtype=bool)
        test_mask[:3] = True
        expected_next_mask = np.array([False, True, False, True, False])
    
        with patch.object(epochs, mock_target, return_value=(test_mask, expected_next_mask)) as split_func_mock:
            group_idx = 0
            generator.split_validate(dataset, group_idx)
    
            call_args = split_func_mock.call_args[1]
    
            assert np.array_equal(call_args['mask'], mask)
            assert np.array_equal(call_args['clean_mask'], None)
            assert call_args['value'] == split_value
            assert call_args['split_unit'] == split_unit
            assert call_args['group_idx'] == group_idx
    
        assert dataset.get_val_len() == 3
        X, y = dataset.get_val_data()
        for i in range(3):
            expected = np.zeros(X[i].shape)
            expected[:, :] = 1 * 100000 + 1 * 1000 + i
>           assert np.array_equal(X[i], expected)
E           assert False
E            +  where False = <function array_equal at 0x7ab2549cdb80>(array([[0]]), array([[101000.]]))
E            +    where <function array_equal at 0x7ab2549cdb80> = np.array_equal

XBrainLab/tests/backend/dataset/test_dataset_generator.py:357: AssertionError
_ test_dataset_generator_split_validation[ValSplitByType.SUBJECT-pick_subject] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ecc6f5b0>
split_type = <ValSplitByType.SUBJECT: 'By Subject'>
mock_target = 'pick_subject'

    @pytest.mark.parametrize('split_type, mock_target', [
        (ValSplitByType.SESSION, 'pick_session'),
        (ValSplitByType.SUBJECT, 'pick_subject'),
        (ValSplitByType.TRIAL, 'pick_trial'),
    ])
    def test_dataset_generator_split_validation(
        epochs, # noqa: F811
        split_type, mock_target
    ):
        train_type = TrainingType.FULL
        is_cross_validation = False
        split_value = 0.2
        split_unit = SplitUnit.RATIO
        val_splitter_list = [
            DataSplitter(split_type, split_value, split_unit)
        ]
        test_splitter_list = []
        config = DataSplittingConfig(
            train_type, is_cross_validation, val_splitter_list, test_splitter_list
        )
        generator = DatasetGenerator(epochs, config)
        dataset = Dataset(epochs, config)
    
        mask = np.ones(epochs.get_data_length(), dtype=bool)
    
        test_mask = np.zeros(epochs.get_data_length(), dtype=bool)
        test_mask[:3] = True
        expected_next_mask = np.array([False, True, False, True, False])
    
        with patch.object(epochs, mock_target, return_value=(test_mask, expected_next_mask)) as split_func_mock:
            group_idx = 0
            generator.split_validate(dataset, group_idx)
    
            call_args = split_func_mock.call_args[1]
    
            assert np.array_equal(call_args['mask'], mask)
            assert np.array_equal(call_args['clean_mask'], None)
            assert call_args['value'] == split_value
            assert call_args['split_unit'] == split_unit
            assert call_args['group_idx'] == group_idx
    
        assert dataset.get_val_len() == 3
        X, y = dataset.get_val_data()
        for i in range(3):
            expected = np.zeros(X[i].shape)
            expected[:, :] = 1 * 100000 + 1 * 1000 + i
>           assert np.array_equal(X[i], expected)
E           assert False
E            +  where False = <function array_equal at 0x7ab2549cdb80>(array([[0]]), array([[101000.]]))
E            +    where <function array_equal at 0x7ab2549cdb80> = np.array_equal

XBrainLab/tests/backend/dataset/test_dataset_generator.py:357: AssertionError
___ test_dataset_generator_split_validation[ValSplitByType.TRIAL-pick_trial] ___

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec990160>
split_type = <ValSplitByType.TRIAL: 'By Trial'>, mock_target = 'pick_trial'

    @pytest.mark.parametrize('split_type, mock_target', [
        (ValSplitByType.SESSION, 'pick_session'),
        (ValSplitByType.SUBJECT, 'pick_subject'),
        (ValSplitByType.TRIAL, 'pick_trial'),
    ])
    def test_dataset_generator_split_validation(
        epochs, # noqa: F811
        split_type, mock_target
    ):
        train_type = TrainingType.FULL
        is_cross_validation = False
        split_value = 0.2
        split_unit = SplitUnit.RATIO
        val_splitter_list = [
            DataSplitter(split_type, split_value, split_unit)
        ]
        test_splitter_list = []
        config = DataSplittingConfig(
            train_type, is_cross_validation, val_splitter_list, test_splitter_list
        )
        generator = DatasetGenerator(epochs, config)
        dataset = Dataset(epochs, config)
    
        mask = np.ones(epochs.get_data_length(), dtype=bool)
    
        test_mask = np.zeros(epochs.get_data_length(), dtype=bool)
        test_mask[:3] = True
        expected_next_mask = np.array([False, True, False, True, False])
    
        with patch.object(epochs, mock_target, return_value=(test_mask, expected_next_mask)) as split_func_mock:
            group_idx = 0
            generator.split_validate(dataset, group_idx)
    
            call_args = split_func_mock.call_args[1]
    
            assert np.array_equal(call_args['mask'], mask)
            assert np.array_equal(call_args['clean_mask'], None)
            assert call_args['value'] == split_value
            assert call_args['split_unit'] == split_unit
            assert call_args['group_idx'] == group_idx
    
        assert dataset.get_val_len() == 3
        X, y = dataset.get_val_data()
        for i in range(3):
            expected = np.zeros(X[i].shape)
            expected[:, :] = 1 * 100000 + 1 * 1000 + i
>           assert np.array_equal(X[i], expected)
E           assert False
E            +  where False = <function array_equal at 0x7ab2549cdb80>(array([[0]]), array([[101000.]]))
E            +    where <function array_equal at 0x7ab2549cdb80> = np.array_equal

XBrainLab/tests/backend/dataset/test_dataset_generator.py:357: AssertionError
___________________ test_dataset_generator_handle_individual ___________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f90a0fa0>

    def test_dataset_generator_handle_individual(
        epochs, # noqa: F811
    ):
        train_type = TrainingType.IND
        is_cross_validation = False
        split_value = 1
        split_unit = SplitUnit.NUMBER
        test_splitter_list = [
            DataSplitter(SplitByType.SESSION, split_value, split_unit)
        ]
        split_value = 0.25
        split_unit = SplitUnit.RATIO
        val_splitter_list = [
            DataSplitter(ValSplitByType.TRIAL, split_value, split_unit)
        ]
        config = DataSplittingConfig(
            train_type, is_cross_validation, val_splitter_list, test_splitter_list
        )
        generator = DatasetGenerator(epochs, config)
        result = generator.generate()
        assert len(result) == len(subject_list)
        for i in range(len(result)):
            assert result[i].get_name() == str(i) + '-Subject-' + str(i + 1) + '_0'
            X, _ = result[i].get_training_data()
>           assert ((X // 1000 * 1000) == ((i + 1) * 100000 + 2 * 1000)).all()
E           assert False
E            +  where False = <built-in method all of numpy.ndarray object at 0x7ab1eca4a1b0>()
E            +    where <built-in method all of numpy.ndarray object at 0x7ab1eca4a1b0> = ((array([[[0]]]) // 1000) * 1000) == (((0 + 1) * 100000) + (2 * 1000)).all

XBrainLab/tests/backend/dataset/test_dataset_generator.py:510: AssertionError
----------------------------- Captured stdout call -----------------------------
WARNING: Validation set is empty! Please check your splitting configuration.
WARNING: Validation set is empty! Please check your splitting configuration.
WARNING: Validation set is empty! Please check your splitting configuration.
__________ test_dataset_generator_handle_individual_cross_validation ___________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1eca21d00>

    def test_dataset_generator_handle_individual_cross_validation(
        epochs, # noqa: F811
    ):
        train_type = TrainingType.IND
        is_cross_validation = True
        split_value = 1
        split_unit = SplitUnit.NUMBER
        test_splitter_list = [
            DataSplitter(SplitByType.SESSION, split_value, split_unit)
        ]
        split_value = 0.25
        split_unit = SplitUnit.RATIO
        val_splitter_list = [
            DataSplitter(ValSplitByType.TRIAL, split_value, split_unit)
        ]
        config = DataSplittingConfig(
            train_type, is_cross_validation, val_splitter_list, test_splitter_list
        )
        generator = DatasetGenerator(epochs, config)
        result = generator.generate()
        assert len(result) == len(subject_list) * len(session_list)
        for i in range(len(subject_list)):
                for j in range(len(session_list)):
                    idx = i * len(session_list) + j
                    assert (
                        result[idx].get_name() ==
                        str(idx) + '-Subject-' + str(i + 1) + '_' + str(j)
                    )
                    X, _ = result[idx].get_training_data()
>                   assert (
                        (X // 1000 * 1000) ==
                        ((i + 1) * 100000 + ((j + 1) % len(session_list) + 1) * 1000)
                    ).all()
E                   AssertionError: assert False
E                    +  where False = <built-in method all of numpy.ndarray object at 0x7ab1ec95e990>()
E                    +    where <built-in method all of numpy.ndarray object at 0x7ab1ec95e990> = ((array([[[0]]]) // 1000) * 1000) == (((0 + 1) * 100000) + ((((0 + 1) % 2) + 1) * 1000)).all
E                    +      where 2 = len(['1', '2'])

XBrainLab/tests/backend/dataset/test_dataset_generator.py:545: AssertionError
----------------------------- Captured stdout call -----------------------------
WARNING: Validation set is empty! Please check your splitting configuration.
WARNING: Validation set is empty! Please check your splitting configuration.
WARNING: Validation set is empty! Please check your splitting configuration.
WARNING: Validation set is empty! Please check your splitting configuration.
WARNING: Validation set is empty! Please check your splitting configuration.
WARNING: Validation set is empty! Please check your splitting configuration.
______________________ test_dataset_generator_handle_full ______________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1eca17ee0>

    def test_dataset_generator_handle_full(
        epochs, # noqa: F811
    ):
        train_type = TrainingType.FULL
        is_cross_validation = False
        split_value = 1
        split_unit = SplitUnit.NUMBER
        test_splitter_list = [
            DataSplitter(SplitByType.SUBJECT, split_value, split_unit)
        ]
        split_value = 1
        split_unit = SplitUnit.NUMBER
        val_splitter_list = [
            DataSplitter(ValSplitByType.SESSION, split_value, split_unit)
        ]
        config = DataSplittingConfig(
            train_type, is_cross_validation, val_splitter_list, test_splitter_list
        )
        generator = DatasetGenerator(epochs, config)
        result = generator.generate()
        assert len(result) == 1
        result = result[0]
        assert result.get_name() == '0-Group_0'
        X, _ = result.get_training_data()
        assert ((X // 100000 * 100000) != (1 * 100000)).all()
>       assert len(X) == block_size * ((len(subject_list) - 1) * (len(session_list) - 1))
E       AssertionError: assert 2 == (6 * ((3 - 1) * (2 - 1)))
E        +  where 2 = len(array([[[0]],\n\n       [[0]]]))
E        +  and   3 = len(['1', '2', '3'])
E        +  and   2 = len(['1', '2'])

XBrainLab/tests/backend/dataset/test_dataset_generator.py:585: AssertionError
_____________ test_dataset_generator_handle_full_cross_validation ______________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1eca0d580>

    def test_dataset_generator_handle_full_cross_validation(
        epochs, # noqa: F811
    ):
        train_type = TrainingType.FULL
        is_cross_validation = True
        split_value = 1
        split_unit = SplitUnit.NUMBER
        test_splitter_list = [
            DataSplitter(SplitByType.SUBJECT, split_value, split_unit)
        ]
        split_value = 1
        split_unit = SplitUnit.NUMBER
        val_splitter_list = [
            DataSplitter(ValSplitByType.SESSION, split_value, split_unit)
        ]
        config = DataSplittingConfig(
            train_type, is_cross_validation, val_splitter_list, test_splitter_list
        )
        generator = DatasetGenerator(epochs, config)
        result = generator.generate()
        assert len(result) == len(subject_list)
        for i in range(len(subject_list)):
    
            assert result[i].get_name() == str(i) + '-Group_' + str(i)
            X, _ = result[i].get_training_data()
            assert ((X // 100000 * 100000) != ((i + 1) * 100000)).all()
>           assert (
                len(X) ==
                block_size * ((len(subject_list) - 1) * (len(session_list) - 1))
            )
E           AssertionError: assert 2 == (6 * ((3 - 1) * (2 - 1)))
E            +  where 2 = len(array([[[0]],\n\n       [[0]]]))
E            +  and   3 = len(['1', '2', '3'])
E            +  and   2 = len(['1', '2'])

XBrainLab/tests/backend/dataset/test_dataset_generator.py:620: AssertionError
________________________ test_epochs_subject_attributes ________________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec8e5940>

    def test_epochs_subject_attributes(epochs):
        for subject in range(len(subject_list)):
            for session in range(len(session_list)):
                i = subject * len(session_list) + session
>               assert (
                    epochs.get_subject_list()[
                        i * block_size: (i + 1) * block_size
                    ] ==
                    subject
                ).all()
E               assert False
E                +  where False = <built-in method all of numpy.ndarray object at 0x7ab1ec8db990>()
E                +    where <built-in method all of numpy.ndarray object at 0x7ab1ec8db990> = array([0., 0., 1., 1., 2., 2.]) == 0.all

XBrainLab/tests/backend/dataset/test_epochs.py:66: AssertionError
________________________ test_epochs_session_attributes ________________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec8aeb20>

    def test_epochs_session_attributes(epochs):
        for subject in range(len(subject_list)):
            for session in range(len(session_list)):
                i = subject * len(session_list) + session
>               assert (
                    epochs.get_session_list()[
                        i * block_size: (i + 1) * block_size
                    ] ==
                    session
                ).all()
E               assert False
E                +  where False = <built-in method all of numpy.ndarray object at 0x7ab1ec8a4f90>()
E                +    where <built-in method all of numpy.ndarray object at 0x7ab1ec8a4f90> = array([0., 1., 0., 1., 0., 1.]) == 0.all

XBrainLab/tests/backend/dataset/test_epochs.py:79: AssertionError
_________________________ test_epochs_label_attributes _________________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec93adc0>

    def test_epochs_label_attributes(epochs):
        for subject in range(len(subject_list)):
            for session in range(len(session_list)):
                i = subject * len(session_list) + session
>               assert (
                    epochs.get_label_list()[
                        i * block_size: (i + 1) * block_size
                    ] ==
                    np.arange(n_class).repeat(n_trial)
                ).all()
E               assert False
E                +  where False = <built-in method all of numpy.ndarray object at 0x7ab1ec8d3870>()
E                +    where <built-in method all of numpy.ndarray object at 0x7ab1ec8d3870> = array([0., 0...., 0., 0., 0.]) == array([0, 0, 0, 1, 1, 1])
E                     
E                     Full diff:
E                     - array([0, 0, 0, 1, 1, 1])
E                     ?                 ^  ^  ^
E                     + array([0., 0., 0., 0., 0., 0.])
E                     ?         +   +   +  ^^  ^^  ^^.all

XBrainLab/tests/backend/dataset/test_epochs.py:91: AssertionError
___________________________ test_epochs_get_by_mask ____________________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec8ad9a0>

    def test_epochs_get_by_mask(epochs):
        mask = np.zeros(block_size * len(subject_list) * len(session_list), dtype=bool)
        mask[block_size:block_size * 2] = True
>       assert np.allclose(epochs.get_subject_list_by_mask(mask),
                           np.array([0] * block_size))

XBrainLab/tests/backend/dataset/test_epochs.py:108: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec8ad9a0>
mask = array([False, False, False, False, False, False,  True,  True,  True,
        True,  True,  True, False, False, False,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])

    def get_subject_list_by_mask(self, mask: np.ndarray) -> np.ndarray:
        """Return list of subject index of each epoch by mask.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
        """
>       return self.subject[mask]
E       IndexError: boolean index did not match indexed array along dimension 0; dimension is 6 but corresponding boolean dimension is 36

XBrainLab/backend/dataset/epochs.py:171: IndexError
___________________________ test_epochs_get_by_index ___________________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec974250>

    def test_epochs_get_by_index(epochs):
        for idx, name in enumerate(subject_list):
            assert epochs.get_subject_name(idx) == name
    
        for idx, name in enumerate(session_list):
            assert epochs.get_session_name(idx) == name
    
        for idx, name in enumerate(event_id):
>           assert epochs.get_label_name(idx) == name
E           AssertionError: assert 'test' == 'c1'
E             
E             - c1
E             + test

XBrainLab/tests/backend/dataset/test_epochs.py:130: AssertionError
_______________________________ test_epochs_info _______________________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec99dfa0>

    def test_epochs_info(epochs):
>       assert (
            epochs.get_data_length() ==
            block_size * len(subject_list) * len(session_list)
        )
E       AssertionError: assert 6 == ((6 * 3) * 2)
E        +  where 6 = get_data_length()
E        +    where get_data_length = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec99dfa0>.get_data_length
E        +  and   3 = len(['1', '2', '3'])
E        +  and   2 = len(['1', '2'])

XBrainLab/tests/backend/dataset/test_epochs.py:133: AssertionError
___________________ test_epochs_generate_mask_target_partial ___________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec9b1d90>

    def test_epochs_generate_mask_target_partial(epochs):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        mask[:block_size * len(session_list)] = False
>       filter_preview_mask = epochs._generate_mask_target(mask)

XBrainLab/tests/backend/dataset/test_epochs.py:184: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec9b1d90>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____________________ test_epochs_pick[False-selected_num0] _____________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1eca0d730>
selected_num = 0, is_partial = False

    @pytest.mark.parametrize('selected_num', np.arange(block_size + 2))
    @pytest.mark.parametrize('is_partial', [False, True])
    def test_epochs_pick(epochs, selected_num, is_partial):
        target_type = np.arange(block_size).repeat(len(subject_list) * len(session_list))
        mask = np.ones(len(target_type), dtype=bool)
        real_block_size = block_size
        if is_partial:
            mask[:block_size] = False
            real_block_size -= 1
        old_mask = mask.copy()
        clean_mask = None
        value = 0
        split_unit = 0
        group_idx = 0
    
        with patch.object(epochs, '_get_real_num', return_value=selected_num):
>           ret, new_mask = epochs._pick(
                target_type, mask, clean_mask, value, split_unit, group_idx
            )

XBrainLab/tests/backend/dataset/test_epochs.py:337: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:432: in _pick
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1eca0d730>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____________________ test_epochs_pick[False-selected_num1] _____________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f903e2b0>
selected_num = 1, is_partial = False

    @pytest.mark.parametrize('selected_num', np.arange(block_size + 2))
    @pytest.mark.parametrize('is_partial', [False, True])
    def test_epochs_pick(epochs, selected_num, is_partial):
        target_type = np.arange(block_size).repeat(len(subject_list) * len(session_list))
        mask = np.ones(len(target_type), dtype=bool)
        real_block_size = block_size
        if is_partial:
            mask[:block_size] = False
            real_block_size -= 1
        old_mask = mask.copy()
        clean_mask = None
        value = 0
        split_unit = 0
        group_idx = 0
    
        with patch.object(epochs, '_get_real_num', return_value=selected_num):
>           ret, new_mask = epochs._pick(
                target_type, mask, clean_mask, value, split_unit, group_idx
            )

XBrainLab/tests/backend/dataset/test_epochs.py:337: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:432: in _pick
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f903e2b0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____________________ test_epochs_pick[False-selected_num2] _____________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1eca27f10>
selected_num = 2, is_partial = False

    @pytest.mark.parametrize('selected_num', np.arange(block_size + 2))
    @pytest.mark.parametrize('is_partial', [False, True])
    def test_epochs_pick(epochs, selected_num, is_partial):
        target_type = np.arange(block_size).repeat(len(subject_list) * len(session_list))
        mask = np.ones(len(target_type), dtype=bool)
        real_block_size = block_size
        if is_partial:
            mask[:block_size] = False
            real_block_size -= 1
        old_mask = mask.copy()
        clean_mask = None
        value = 0
        split_unit = 0
        group_idx = 0
    
        with patch.object(epochs, '_get_real_num', return_value=selected_num):
>           ret, new_mask = epochs._pick(
                target_type, mask, clean_mask, value, split_unit, group_idx
            )

XBrainLab/tests/backend/dataset/test_epochs.py:337: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:432: in _pick
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1eca27f10>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____________________ test_epochs_pick[False-selected_num3] _____________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec8efd90>
selected_num = 3, is_partial = False

    @pytest.mark.parametrize('selected_num', np.arange(block_size + 2))
    @pytest.mark.parametrize('is_partial', [False, True])
    def test_epochs_pick(epochs, selected_num, is_partial):
        target_type = np.arange(block_size).repeat(len(subject_list) * len(session_list))
        mask = np.ones(len(target_type), dtype=bool)
        real_block_size = block_size
        if is_partial:
            mask[:block_size] = False
            real_block_size -= 1
        old_mask = mask.copy()
        clean_mask = None
        value = 0
        split_unit = 0
        group_idx = 0
    
        with patch.object(epochs, '_get_real_num', return_value=selected_num):
>           ret, new_mask = epochs._pick(
                target_type, mask, clean_mask, value, split_unit, group_idx
            )

XBrainLab/tests/backend/dataset/test_epochs.py:337: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:432: in _pick
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec8efd90>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____________________ test_epochs_pick[False-selected_num4] _____________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec9cb5e0>
selected_num = 4, is_partial = False

    @pytest.mark.parametrize('selected_num', np.arange(block_size + 2))
    @pytest.mark.parametrize('is_partial', [False, True])
    def test_epochs_pick(epochs, selected_num, is_partial):
        target_type = np.arange(block_size).repeat(len(subject_list) * len(session_list))
        mask = np.ones(len(target_type), dtype=bool)
        real_block_size = block_size
        if is_partial:
            mask[:block_size] = False
            real_block_size -= 1
        old_mask = mask.copy()
        clean_mask = None
        value = 0
        split_unit = 0
        group_idx = 0
    
        with patch.object(epochs, '_get_real_num', return_value=selected_num):
>           ret, new_mask = epochs._pick(
                target_type, mask, clean_mask, value, split_unit, group_idx
            )

XBrainLab/tests/backend/dataset/test_epochs.py:337: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:432: in _pick
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec9cb5e0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____________________ test_epochs_pick[False-selected_num5] _____________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7c5610>
selected_num = 5, is_partial = False

    @pytest.mark.parametrize('selected_num', np.arange(block_size + 2))
    @pytest.mark.parametrize('is_partial', [False, True])
    def test_epochs_pick(epochs, selected_num, is_partial):
        target_type = np.arange(block_size).repeat(len(subject_list) * len(session_list))
        mask = np.ones(len(target_type), dtype=bool)
        real_block_size = block_size
        if is_partial:
            mask[:block_size] = False
            real_block_size -= 1
        old_mask = mask.copy()
        clean_mask = None
        value = 0
        split_unit = 0
        group_idx = 0
    
        with patch.object(epochs, '_get_real_num', return_value=selected_num):
>           ret, new_mask = epochs._pick(
                target_type, mask, clean_mask, value, split_unit, group_idx
            )

XBrainLab/tests/backend/dataset/test_epochs.py:337: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:432: in _pick
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7c5610>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____________________ test_epochs_pick[False-selected_num6] _____________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f907abe0>
selected_num = 6, is_partial = False

    @pytest.mark.parametrize('selected_num', np.arange(block_size + 2))
    @pytest.mark.parametrize('is_partial', [False, True])
    def test_epochs_pick(epochs, selected_num, is_partial):
        target_type = np.arange(block_size).repeat(len(subject_list) * len(session_list))
        mask = np.ones(len(target_type), dtype=bool)
        real_block_size = block_size
        if is_partial:
            mask[:block_size] = False
            real_block_size -= 1
        old_mask = mask.copy()
        clean_mask = None
        value = 0
        split_unit = 0
        group_idx = 0
    
        with patch.object(epochs, '_get_real_num', return_value=selected_num):
>           ret, new_mask = epochs._pick(
                target_type, mask, clean_mask, value, split_unit, group_idx
            )

XBrainLab/tests/backend/dataset/test_epochs.py:337: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:432: in _pick
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f907abe0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____________________ test_epochs_pick[False-selected_num7] _____________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7c0c10>
selected_num = 7, is_partial = False

    @pytest.mark.parametrize('selected_num', np.arange(block_size + 2))
    @pytest.mark.parametrize('is_partial', [False, True])
    def test_epochs_pick(epochs, selected_num, is_partial):
        target_type = np.arange(block_size).repeat(len(subject_list) * len(session_list))
        mask = np.ones(len(target_type), dtype=bool)
        real_block_size = block_size
        if is_partial:
            mask[:block_size] = False
            real_block_size -= 1
        old_mask = mask.copy()
        clean_mask = None
        value = 0
        split_unit = 0
        group_idx = 0
    
        with patch.object(epochs, '_get_real_num', return_value=selected_num):
>           ret, new_mask = epochs._pick(
                target_type, mask, clean_mask, value, split_unit, group_idx
            )

XBrainLab/tests/backend/dataset/test_epochs.py:337: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:432: in _pick
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7c0c10>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____________________ test_epochs_pick[True-selected_num0] _____________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1eca27070>
selected_num = 0, is_partial = True

    @pytest.mark.parametrize('selected_num', np.arange(block_size + 2))
    @pytest.mark.parametrize('is_partial', [False, True])
    def test_epochs_pick(epochs, selected_num, is_partial):
        target_type = np.arange(block_size).repeat(len(subject_list) * len(session_list))
        mask = np.ones(len(target_type), dtype=bool)
        real_block_size = block_size
        if is_partial:
            mask[:block_size] = False
            real_block_size -= 1
        old_mask = mask.copy()
        clean_mask = None
        value = 0
        split_unit = 0
        group_idx = 0
    
        with patch.object(epochs, '_get_real_num', return_value=selected_num):
>           ret, new_mask = epochs._pick(
                target_type, mask, clean_mask, value, split_unit, group_idx
            )

XBrainLab/tests/backend/dataset/test_epochs.py:337: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:432: in _pick
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1eca27070>
mask = array([False, False, False, False, False, False,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____________________ test_epochs_pick[True-selected_num1] _____________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec9d9640>
selected_num = 1, is_partial = True

    @pytest.mark.parametrize('selected_num', np.arange(block_size + 2))
    @pytest.mark.parametrize('is_partial', [False, True])
    def test_epochs_pick(epochs, selected_num, is_partial):
        target_type = np.arange(block_size).repeat(len(subject_list) * len(session_list))
        mask = np.ones(len(target_type), dtype=bool)
        real_block_size = block_size
        if is_partial:
            mask[:block_size] = False
            real_block_size -= 1
        old_mask = mask.copy()
        clean_mask = None
        value = 0
        split_unit = 0
        group_idx = 0
    
        with patch.object(epochs, '_get_real_num', return_value=selected_num):
>           ret, new_mask = epochs._pick(
                target_type, mask, clean_mask, value, split_unit, group_idx
            )

XBrainLab/tests/backend/dataset/test_epochs.py:337: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:432: in _pick
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec9d9640>
mask = array([False, False, False, False, False, False,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____________________ test_epochs_pick[True-selected_num2] _____________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec9d45e0>
selected_num = 2, is_partial = True

    @pytest.mark.parametrize('selected_num', np.arange(block_size + 2))
    @pytest.mark.parametrize('is_partial', [False, True])
    def test_epochs_pick(epochs, selected_num, is_partial):
        target_type = np.arange(block_size).repeat(len(subject_list) * len(session_list))
        mask = np.ones(len(target_type), dtype=bool)
        real_block_size = block_size
        if is_partial:
            mask[:block_size] = False
            real_block_size -= 1
        old_mask = mask.copy()
        clean_mask = None
        value = 0
        split_unit = 0
        group_idx = 0
    
        with patch.object(epochs, '_get_real_num', return_value=selected_num):
>           ret, new_mask = epochs._pick(
                target_type, mask, clean_mask, value, split_unit, group_idx
            )

XBrainLab/tests/backend/dataset/test_epochs.py:337: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:432: in _pick
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec9d45e0>
mask = array([False, False, False, False, False, False,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____________________ test_epochs_pick[True-selected_num3] _____________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec873a60>
selected_num = 3, is_partial = True

    @pytest.mark.parametrize('selected_num', np.arange(block_size + 2))
    @pytest.mark.parametrize('is_partial', [False, True])
    def test_epochs_pick(epochs, selected_num, is_partial):
        target_type = np.arange(block_size).repeat(len(subject_list) * len(session_list))
        mask = np.ones(len(target_type), dtype=bool)
        real_block_size = block_size
        if is_partial:
            mask[:block_size] = False
            real_block_size -= 1
        old_mask = mask.copy()
        clean_mask = None
        value = 0
        split_unit = 0
        group_idx = 0
    
        with patch.object(epochs, '_get_real_num', return_value=selected_num):
>           ret, new_mask = epochs._pick(
                target_type, mask, clean_mask, value, split_unit, group_idx
            )

XBrainLab/tests/backend/dataset/test_epochs.py:337: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:432: in _pick
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec873a60>
mask = array([False, False, False, False, False, False,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____________________ test_epochs_pick[True-selected_num4] _____________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec9cb610>
selected_num = 4, is_partial = True

    @pytest.mark.parametrize('selected_num', np.arange(block_size + 2))
    @pytest.mark.parametrize('is_partial', [False, True])
    def test_epochs_pick(epochs, selected_num, is_partial):
        target_type = np.arange(block_size).repeat(len(subject_list) * len(session_list))
        mask = np.ones(len(target_type), dtype=bool)
        real_block_size = block_size
        if is_partial:
            mask[:block_size] = False
            real_block_size -= 1
        old_mask = mask.copy()
        clean_mask = None
        value = 0
        split_unit = 0
        group_idx = 0
    
        with patch.object(epochs, '_get_real_num', return_value=selected_num):
>           ret, new_mask = epochs._pick(
                target_type, mask, clean_mask, value, split_unit, group_idx
            )

XBrainLab/tests/backend/dataset/test_epochs.py:337: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:432: in _pick
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec9cb610>
mask = array([False, False, False, False, False, False,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____________________ test_epochs_pick[True-selected_num5] _____________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ecc19970>
selected_num = 5, is_partial = True

    @pytest.mark.parametrize('selected_num', np.arange(block_size + 2))
    @pytest.mark.parametrize('is_partial', [False, True])
    def test_epochs_pick(epochs, selected_num, is_partial):
        target_type = np.arange(block_size).repeat(len(subject_list) * len(session_list))
        mask = np.ones(len(target_type), dtype=bool)
        real_block_size = block_size
        if is_partial:
            mask[:block_size] = False
            real_block_size -= 1
        old_mask = mask.copy()
        clean_mask = None
        value = 0
        split_unit = 0
        group_idx = 0
    
        with patch.object(epochs, '_get_real_num', return_value=selected_num):
>           ret, new_mask = epochs._pick(
                target_type, mask, clean_mask, value, split_unit, group_idx
            )

XBrainLab/tests/backend/dataset/test_epochs.py:337: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:432: in _pick
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ecc19970>
mask = array([False, False, False, False, False, False,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____________________ test_epochs_pick[True-selected_num6] _____________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec99f130>
selected_num = 6, is_partial = True

    @pytest.mark.parametrize('selected_num', np.arange(block_size + 2))
    @pytest.mark.parametrize('is_partial', [False, True])
    def test_epochs_pick(epochs, selected_num, is_partial):
        target_type = np.arange(block_size).repeat(len(subject_list) * len(session_list))
        mask = np.ones(len(target_type), dtype=bool)
        real_block_size = block_size
        if is_partial:
            mask[:block_size] = False
            real_block_size -= 1
        old_mask = mask.copy()
        clean_mask = None
        value = 0
        split_unit = 0
        group_idx = 0
    
        with patch.object(epochs, '_get_real_num', return_value=selected_num):
>           ret, new_mask = epochs._pick(
                target_type, mask, clean_mask, value, split_unit, group_idx
            )

XBrainLab/tests/backend/dataset/test_epochs.py:337: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:432: in _pick
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec99f130>
mask = array([False, False, False, False, False, False,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____________________ test_epochs_pick[True-selected_num7] _____________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec901fa0>
selected_num = 7, is_partial = True

    @pytest.mark.parametrize('selected_num', np.arange(block_size + 2))
    @pytest.mark.parametrize('is_partial', [False, True])
    def test_epochs_pick(epochs, selected_num, is_partial):
        target_type = np.arange(block_size).repeat(len(subject_list) * len(session_list))
        mask = np.ones(len(target_type), dtype=bool)
        real_block_size = block_size
        if is_partial:
            mask[:block_size] = False
            real_block_size -= 1
        old_mask = mask.copy()
        clean_mask = None
        value = 0
        split_unit = 0
        group_idx = 0
    
        with patch.object(epochs, '_get_real_num', return_value=selected_num):
>           ret, new_mask = epochs._pick(
                target_type, mask, clean_mask, value, split_unit, group_idx
            )

XBrainLab/tests/backend/dataset/test_epochs.py:337: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:432: in _pick
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec901fa0>
mask = array([False, False, False, False, False, False,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-0-expected0-0-False] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7f8700>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 0
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7f8700>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-1-expected1-0-False] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec886df0>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 1
expected = array([False, False,  True, False, False, False, False, False, False,
       False, False, False, False, False, False,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec886df0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-2-expected2-0-False] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7ed370>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 2
expected = array([False, False,  True, False, False,  True, False, False, False,
       False, False, False, False, False, False,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7ed370>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-3-expected3-0-False] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec698a60>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 3
expected = array([False, False,  True, False, False,  True, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec698a60>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-4-expected4-0-False] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7c5340>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 4
expected = array([False, False,  True, False, False,  True, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7c5340>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-5-expected5-0-False] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6ecd60>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 5
expected = array([False, False,  True, False, False,  True, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False,  True,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6ecd60>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-6-expected6-0-False] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7ff4f0>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 6
expected = array([False, False,  True, False, False,  True, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False,  True,
       False, False,  True, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7ff4f0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-7-expected7-0-False] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec99f0d0>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 7
expected = array([False, False,  True, False, False,  True, False, False,  True,
       False, False, False, False, False,  True,...False, False, False, False, False, False,  True,
       False, False,  True, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec99f0d0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-8-expected8-0-False] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec9cb670>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 8
expected = array([False, False,  True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True,...False, False, False, False, False, False,  True,
       False, False,  True, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec9cb670>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-9-expected9-0-False] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6ae1c0>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 9
expected = array([False, False,  True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True,... True, False, False, False, False, False,  True,
       False, False,  True, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6ae1c0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-10-expected10-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7f8790>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 10
expected = array([False, False,  True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7f8790>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-11-expected11-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7d9940>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 11
expected = array([False, False,  True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7d9940>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-12-expected12-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec901f70>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 12
expected = array([False, False,  True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec901f70>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-13-expected13-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8ff5850>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 13
expected = array([False,  True,  True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8ff5850>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-14-expected14-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec9039d0>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 14
expected = array([False,  True,  True, False,  True,  True, False, False,  True,
       False, False,  True, False, False,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec9039d0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-15-expected15-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7540a0>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 15
expected = array([False,  True,  True, False,  True,  True, False, False,  True,
       False, False,  True, False,  True,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7540a0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-16-expected16-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7d5880>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 16
expected = array([False,  True,  True, False,  True,  True, False, False,  True,
       False, False,  True, False,  True,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7d5880>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-17-expected17-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7da370>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 17
expected = array([False,  True,  True, False,  True,  True, False, False,  True,
       False, False,  True, False,  True,  True,... True, False, False,  True, False,  True,  True,
       False, False,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7da370>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-18-expected18-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7e8490>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 18
expected = array([False,  True,  True, False,  True,  True, False, False,  True,
       False, False,  True, False,  True,  True,... True, False, False,  True, False,  True,  True,
       False,  True,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7e8490>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-19-expected19-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec78f9d0>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 19
expected = array([False,  True,  True, False,  True,  True, False,  True,  True,
       False, False,  True, False,  True,  True,... True, False, False,  True, False,  True,  True,
       False,  True,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec78f9d0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-20-expected20-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6aea30>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 20
expected = array([False,  True,  True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True,... True, False, False,  True, False,  True,  True,
       False,  True,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6aea30>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-21-expected21-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec794190>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 21
expected = array([False,  True,  True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True,... True, False, False,  True, False,  True,  True,
       False,  True,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec794190>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-22-expected22-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec8046a0>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 22
expected = array([False,  True,  True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec8046a0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-23-expected23-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec65fb20>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 23
expected = array([False,  True,  True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec65fb20>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-24-expected24-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6e7970>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 24
expected = array([False,  True,  True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6e7970>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-25-expected25-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec799760>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 25
expected = array([ True,  True,  True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec799760>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-26-expected26-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7bfa30>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 26
expected = array([ True,  True,  True,  True,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7bfa30>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-27-expected27-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7ef9a0>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 27
expected = array([ True,  True,  True,  True,  True,  True, False,  True,  True,
       False,  True,  True,  True,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7ef9a0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-28-expected28-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6f0c40>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 28
expected = array([ True,  True,  True,  True,  True,  True, False,  True,  True,
       False,  True,  True,  True,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6f0c40>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-29-expected29-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec79a130>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 29
expected = array([ True,  True,  True,  True,  True,  True, False,  True,  True,
       False,  True,  True,  True,  True,  True,... True, False,  True,  True,  True,  True,  True,
       False,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec79a130>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-30-expected30-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec65f5b0>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 30
expected = array([ True,  True,  True,  True,  True,  True, False,  True,  True,
       False,  True,  True,  True,  True,  True,... True, False,  True,  True,  True,  True,  True,
        True,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec65f5b0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-31-expected31-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec803f40>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 31
expected = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
       False,  True,  True,  True,  True,  True,... True, False,  True,  True,  True,  True,  True,
        True,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec803f40>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-32-expected32-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec901f70>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 32
expected = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True, False,  True,  True,  True,  True,  True,
        True,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec901f70>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-33-expected33-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec794100>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 33
expected = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True, False,  True,  True,  True,  True,  True,
        True,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec794100>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-34-expected34-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec71c5e0>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 34
expected = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec71c5e0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-35-expected35-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7da370>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 35
expected = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7da370>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-36-expected36-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec863100>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 36
expected = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec863100>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-37-expected37-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ecd39760>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 37
expected = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ecd39760>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____ test_epochs_pick_by_trial[None-SplitUnit.KFOLD-1-expected38-0-False] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec763e20>
clean_mask = None, split_unit = <SplitUnit.KFOLD: 'K Fold'>, value = 1
expected = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec763e20>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected39-0-False] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6284f0>
clean_mask = None, split_unit = <SplitUnit.KFOLD: 'K Fold'>, value = 10
expected = array([False, False,  True, False, False,  True, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6284f0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected40-1-False] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec61f880>
clean_mask = None, split_unit = <SplitUnit.KFOLD: 'K Fold'>, value = 10
expected = array([False, False,  True, False, False,  True, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 1, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec61f880>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected41-2-False] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7bdd90>
clean_mask = None, split_unit = <SplitUnit.KFOLD: 'K Fold'>, value = 10
expected = array([False, False,  True, False, False,  True, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 2, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7bdd90>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected42-6-False] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec799820>
clean_mask = None, split_unit = <SplitUnit.KFOLD: 'K Fold'>, value = 10
expected = array([False, False,  True, False, False,  True, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 6, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec799820>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.0-expected43-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec782bb0>
clean_mask = None, split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.0
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec782bb0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.1-expected44-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6f7df0>
clean_mask = None, split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.1
expected = array([False, False,  True, False, False,  True, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6f7df0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.2-expected45-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6f03d0>
clean_mask = None, split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.2
expected = array([False, False,  True, False, False,  True, False, False,  True,
       False, False, False, False, False,  True,...False, False, False, False, False, False,  True,
       False, False,  True, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6f03d0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.30000000000000004-expected46-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6ec970>
clean_mask = None, split_unit = <SplitUnit.RATIO: 'Ratio'>
value = 0.30000000000000004
expected = array([False, False,  True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6ec970>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.4-expected47-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec725430>
clean_mask = None, split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.4
expected = array([False,  True,  True, False,  True,  True, False, False,  True,
       False, False,  True, False, False,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec725430>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.5-expected48-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec79afa0>
clean_mask = None, split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.5
expected = array([False,  True,  True, False,  True,  True, False, False,  True,
       False, False,  True, False,  True,  True,... True, False, False,  True, False,  True,  True,
       False,  True,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec79afa0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.6000000000000001-expected49-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8fe1a30>
clean_mask = None, split_unit = <SplitUnit.RATIO: 'Ratio'>
value = 0.6000000000000001
expected = array([False,  True,  True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True,... True, False, False,  True, False,  True,  True,
       False,  True,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8fe1a30>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.7000000000000001-expected50-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7d3670>
clean_mask = None, split_unit = <SplitUnit.RATIO: 'Ratio'>
value = 0.7000000000000001
expected = array([ True,  True,  True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7d3670>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.8-expected51-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec91ba30>
clean_mask = None, split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.8
expected = array([ True,  True,  True,  True,  True,  True, False,  True,  True,
       False,  True,  True,  True,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec91ba30>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.9-expected52-0-False] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7fd220>
clean_mask = None, split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.9
expected = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True, False,  True,  True,  True,  True,  True,
        True,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7fd220>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-0-expected53-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6c0bb0>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 0
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6c0bb0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-1-expected54-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7bfcd0>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 1
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7bfcd0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-2-expected55-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5b64c0>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 2
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5b64c0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-3-expected56-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec64feb0>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 3
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False,  True,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec64feb0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-4-expected57-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5a6250>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 4
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False,  True,
       False, False,  True, False, False, False, False, False, False])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5a6250>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-5-expected58-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7e8040>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 5
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,... True, False, False, False, False, False,  True,
       False, False,  True, False, False, False, False, False, False])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7e8040>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-6-expected59-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6f03d0>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 6
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False, False, False, False, False])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6f03d0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-7-expected60-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec799040>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 7
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True, False, False, False])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec799040>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-8-expected61-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec747580>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 8
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec747580>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-9-expected62-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6e78b0>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 9
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False,  True,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6e78b0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-10-expected63-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec55c3d0>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 10
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False,  True,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec55c3d0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-11-expected64-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ecd39760>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 11
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False,  True,  True,... True, False, False,  True, False,  True,  True,
       False, False,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ecd39760>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-12-expected65-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec52ac40>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 12
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False,  True,  True,... True, False, False,  True, False,  True,  True,
       False,  True,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec52ac40>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-13-expected66-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec550940>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 13
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False,  True,  True,... True, False, False,  True, False,  True,  True,
       False,  True,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec550940>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-14-expected67-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6bc3a0>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 14
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6bc3a0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-15-expected68-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6b5c10>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 15
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True, False, False,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6b5c10>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-16-expected69-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6d26a0>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 16
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6d26a0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-17-expected70-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6d52b0>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 17
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6d52b0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-18-expected71-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec76c160>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 18
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec76c160>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-19-expected72-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec576700>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 19
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True, False,  True,  True,  True,  True,  True,
       False,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec576700>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-20-expected73-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5b6b20>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 20
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True, False,  True,  True,  True,  True,  True,
        True,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5b6b20>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-21-expected74-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6bc9d0>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 21
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True, False,  True,  True,  True,  True,  True,
        True,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6bc9d0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-22-expected75-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7631c0>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 22
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7631c0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-23-expected76-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec863400>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 23
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True, False,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec863400>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-24-expected77-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5e38b0>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 24
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5e38b0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-25-expected78-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5cdbe0>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 25
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5cdbe0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-26-expected79-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec55c970>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 26
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec55c970>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-27-expected80-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec646d90>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 27
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec646d90>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-28-expected81-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5e0b20>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 28
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5e0b20>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-29-expected82-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec57cd90>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 29
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec57cd90>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-30-expected83-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8febc70>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 30
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8febc70>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-31-expected84-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec52b880>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 31
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec52b880>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-32-expected85-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7fd970>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 32
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7fd970>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-33-expected86-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec9017c0>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 33
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec9017c0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-34-expected87-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4f4820>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 34
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4f4820>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-35-expected88-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec9d46a0>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 35
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec9d46a0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-36-expected89-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5440a0>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 36
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5440a0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.NUMBER-37-expected90-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec886c70>
clean_mask = None, split_unit = <SplitUnit.NUMBER: 'Number'>, value = 37
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec886c70>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____ test_epochs_pick_by_trial[None-SplitUnit.KFOLD-1-expected91-0-True] ______

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec675790>
clean_mask = None, split_unit = <SplitUnit.KFOLD: 'K Fold'>, value = 1
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec675790>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____ test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected92-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6f7940>
clean_mask = None, split_unit = <SplitUnit.KFOLD: 'K Fold'>, value = 10
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False,  True,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6f7940>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____ test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected93-1-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6030d0>
clean_mask = None, split_unit = <SplitUnit.KFOLD: 'K Fold'>, value = 10
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False,  True,
       False, False, False, False, False, False, False, False, False])
group_idx = 1, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6030d0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____ test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected94-2-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec76ce80>
clean_mask = None, split_unit = <SplitUnit.KFOLD: 'K Fold'>, value = 10
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False,  True,
       False, False, False, False, False, False, False, False, False])
group_idx = 2, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec76ce80>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____ test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected95-3-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec57c8e0>
clean_mask = None, split_unit = <SplitUnit.KFOLD: 'K Fold'>, value = 10
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False,  True,
       False, False, False, False, False, False, False, False, False])
group_idx = 3, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec57c8e0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____ test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected96-4-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6efa90>
clean_mask = None, split_unit = <SplitUnit.KFOLD: 'K Fold'>, value = 10
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 4, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6efa90>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_____ test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected97-5-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6b58b0>
clean_mask = None, split_unit = <SplitUnit.KFOLD: 'K Fold'>, value = 10
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 5, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6b58b0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.0-expected98-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec63eb80>
clean_mask = None, split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.0
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec63eb80>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.1-expected99-0-True] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4c7fd0>
clean_mask = None, split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.1
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4c7fd0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.2-expected100-0-True] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec668d30>
clean_mask = None, split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.2
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False,  True,
       False, False,  True, False, False, False, False, False, False])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec668d30>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.30000000000000004-expected101-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec630580>
clean_mask = None, split_unit = <SplitUnit.RATIO: 'Ratio'>
value = 0.30000000000000004
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True, False, False, False])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec630580>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.4-expected102-0-True] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec723910>
clean_mask = None, split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.4
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False,  True,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec723910>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.5-expected103-0-True] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec78cb80>
clean_mask = None, split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.5
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False,  True,  True,... True, False, False,  True, False,  True,  True,
       False,  True,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec78cb80>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.6000000000000001-expected104-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4bceb0>
clean_mask = None, split_unit = <SplitUnit.RATIO: 'Ratio'>
value = 0.6000000000000001
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4bceb0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.7000000000000001-expected105-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec723220>
clean_mask = None, split_unit = <SplitUnit.RATIO: 'Ratio'>
value = 0.7000000000000001
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec723220>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.8-expected106-0-True] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec57e340>
clean_mask = None, split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.8
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True, False,  True,  True,  True,  True,  True,
       False,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec57e340>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
____ test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.9-expected107-0-True] ____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec603490>
clean_mask = None, split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.9
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True, False,  True,  True,  True,  True,  True,
        True,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec603490>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-0-expected0-0-False] __

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec75cb50>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 0
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec75cb50>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-1-expected1-0-False] __

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4a2d00>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 1
expected = array([False, False,  True, False, False, False, False, False, False,
       False, False, False, False, False, False,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4a2d00>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-2-expected2-0-False] __

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4ca4f0>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 2
expected = array([False, False,  True, False, False,  True, False, False, False,
       False, False, False, False, False, False,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4ca4f0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-3-expected3-0-False] __

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4ea6d0>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 3
expected = array([False, False,  True, False, False,  True, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4ea6d0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-4-expected4-0-False] __

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6bcd60>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 4
expected = array([False, False,  True, False, False,  True, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6bcd60>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-5-expected5-0-False] __

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec556340>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 5
expected = array([False, False,  True, False, False,  True, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False,  True,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec556340>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-6-expected6-0-False] __

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5a7a30>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 6
expected = array([False, False,  True, False, False,  True, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False,  True,
       False, False,  True, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5a7a30>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-7-expected7-0-False] __

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec52b340>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 7
expected = array([False, False,  True, False, False,  True, False, False,  True,
       False, False, False, False, False,  True,...False, False, False, False, False, False,  True,
       False, False,  True, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec52b340>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-8-expected8-0-False] __

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec574430>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 8
expected = array([False, False,  True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True,...False, False, False, False, False, False,  True,
       False, False,  True, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec574430>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-9-expected9-0-False] __

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4441f0>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 9
expected = array([False, False,  True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True,... True, False, False, False, False, False,  True,
       False, False,  True, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4441f0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-10-expected10-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec43d100>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 10
expected = array([False, False,  True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec43d100>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-11-expected11-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec64ed00>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 11
expected = array([False, False,  True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec64ed00>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-12-expected12-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec576970>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 12
expected = array([False, False,  True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec576970>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-13-expected13-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5e0070>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 13
expected = array([False,  True,  True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5e0070>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-14-expected14-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5a6d30>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 14
expected = array([False,  True,  True, False,  True,  True, False, False,  True,
       False, False,  True, False, False,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5a6d30>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-15-expected15-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5bcb20>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 15
expected = array([False,  True,  True, False,  True,  True, False, False,  True,
       False, False,  True, False,  True,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5bcb20>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-16-expected16-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec541d60>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 16
expected = array([False,  True,  True, False,  True,  True, False, False,  True,
       False, False,  True, False,  True,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec541d60>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-17-expected17-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7e8ee0>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 17
expected = array([False,  True,  True, False,  True,  True, False, False,  True,
       False, False,  True, False,  True,  True,... True, False, False,  True, False,  True,  True,
       False, False,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7e8ee0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-18-expected18-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4d9880>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 18
expected = array([False,  True,  True, False,  True,  True, False, False,  True,
       False, False,  True, False,  True,  True,... True, False, False,  True, False,  True,  True,
       False,  True,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4d9880>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-19-expected19-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec708700>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 19
expected = array([False,  True,  True, False,  True,  True, False,  True,  True,
       False, False,  True, False,  True,  True,... True, False, False,  True, False,  True,  True,
       False,  True,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec708700>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-20-expected20-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec488190>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 20
expected = array([False,  True,  True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True,... True, False, False,  True, False,  True,  True,
       False,  True,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec488190>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-21-expected21-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec863130>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 21
expected = array([False,  True,  True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True,... True, False, False,  True, False,  True,  True,
       False,  True,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec863130>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-22-expected22-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8f784c0>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 22
expected = array([False,  True,  True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8f784c0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-23-expected23-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4e2670>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 23
expected = array([False,  True,  True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4e2670>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-24-expected24-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec653fa0>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 24
expected = array([False,  True,  True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec653fa0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-25-expected25-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec53f340>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 25
expected = array([ True,  True,  True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec53f340>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-26-expected26-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7d30d0>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 26
expected = array([ True,  True,  True,  True,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7d30d0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-27-expected27-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4b23d0>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 27
expected = array([ True,  True,  True,  True,  True,  True, False,  True,  True,
       False,  True,  True,  True,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4b23d0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-28-expected28-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6ce8e0>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 28
expected = array([ True,  True,  True,  True,  True,  True, False,  True,  True,
       False,  True,  True,  True,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6ce8e0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-29-expected29-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec39cdf0>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 29
expected = array([ True,  True,  True,  True,  True,  True, False,  True,  True,
       False,  True,  True,  True,  True,  True,... True, False,  True,  True,  True,  True,  True,
       False,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec39cdf0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-30-expected30-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5e22b0>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 30
expected = array([ True,  True,  True,  True,  True,  True, False,  True,  True,
       False,  True,  True,  True,  True,  True,... True, False,  True,  True,  True,  True,  True,
        True,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5e22b0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-31-expected31-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7e8ee0>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 31
expected = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
       False,  True,  True,  True,  True,  True,... True, False,  True,  True,  True,  True,  True,
        True,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7e8ee0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-32-expected32-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec675400>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 32
expected = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True, False,  True,  True,  True,  True,  True,
        True,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec675400>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-33-expected33-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5c46a0>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 33
expected = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True, False,  True,  True,  True,  True,  True,
        True,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5c46a0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-34-expected34-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec739670>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 34
expected = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec739670>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-35-expected35-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4bca30>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 35
expected = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4bca30>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-36-expected36-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4afcd0>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 36
expected = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4afcd0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-37-expected37-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8f95790>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 37
expected = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8f95790>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-1-expected38-0-False] __

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec3d4d00>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.KFOLD: 'K Fold'>, value = 1
expected = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec3d4d00>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected39-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec3f2910>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.KFOLD: 'K Fold'>, value = 10
expected = array([False, False,  True, False, False,  True, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec3f2910>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected40-1-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5e26a0>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.KFOLD: 'K Fold'>, value = 10
expected = array([False, False,  True, False, False,  True, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 1, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5e26a0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected41-2-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec574fa0>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.KFOLD: 'K Fold'>, value = 10
expected = array([False, False,  True, False, False,  True, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 2, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec574fa0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected42-6-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec3a9340>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.KFOLD: 'K Fold'>, value = 10
expected = array([False, False,  True, False, False,  True, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 6, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec3a9340>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.0-expected43-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5eee50>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.0
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5eee50>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.1-expected44-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec542d60>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.1
expected = array([False, False,  True, False, False,  True, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec542d60>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.2-expected45-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec488550>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.2
expected = array([False, False,  True, False, False,  True, False, False,  True,
       False, False, False, False, False,  True,...False, False, False, False, False, False,  True,
       False, False,  True, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec488550>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.30000000000000004-expected46-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec45c3d0>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.30000000000000004
expected = array([False, False,  True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False, False, False, False, False])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec45c3d0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.4-expected47-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec725e20>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.4
expected = array([False,  True,  True, False,  True,  True, False, False,  True,
       False, False,  True, False, False,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec725e20>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.5-expected48-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec3ead90>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.5
expected = array([False,  True,  True, False,  True,  True, False, False,  True,
       False, False,  True, False,  True,  True,... True, False, False,  True, False,  True,  True,
       False,  True,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec3ead90>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.6000000000000001-expected49-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec472bb0>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.6000000000000001
expected = array([False,  True,  True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True,... True, False, False,  True, False,  True,  True,
       False,  True,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec472bb0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.7000000000000001-expected50-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec41da30>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.7000000000000001
expected = array([ True,  True,  True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec41da30>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.8-expected51-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6d4850>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.8
expected = array([ True,  True,  True,  True,  True,  True, False,  True,  True,
       False,  True,  True,  True,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec6d4850>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.9-expected52-0-False] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec47d6a0>
clean_mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.9
expected = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True, False,  True,  True,  True,  True,  True,
        True,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = False

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec47d6a0>
mask = array([ True,  True,  True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-0-expected53-0-True] __

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec57d0d0>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 0
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec57d0d0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-1-expected54-0-True] __

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec32b4f0>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 1
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec32b4f0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-2-expected55-0-True] __

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4199a0>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 2
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4199a0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-3-expected56-0-True] __

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4f6520>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 3
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False,  True,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4f6520>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-4-expected57-0-True] __

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec372d90>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 4
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False,  True,
       False, False,  True, False, False, False, False, False, False])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec372d90>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-5-expected58-0-True] __

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec3eadc0>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 5
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,... True, False, False, False, False, False,  True,
       False, False,  True, False, False, False, False, False, False])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec3eadc0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-6-expected59-0-True] __

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5420a0>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 6
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False, False, False, False, False])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5420a0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-7-expected60-0-True] __

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec497d30>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 7
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True, False, False, False])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec497d30>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-8-expected61-0-True] __

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec339ee0>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 8
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec339ee0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-9-expected62-0-True] __

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec45a9a0>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 9
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False,  True,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec45a9a0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-10-expected63-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec33abe0>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 10
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False,  True,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec33abe0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-11-expected64-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec2ff550>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 11
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False,  True,  True,... True, False, False,  True, False,  True,  True,
       False, False,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec2ff550>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-12-expected65-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4f6280>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 12
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False,  True,  True,... True, False, False,  True, False,  True,  True,
       False,  True,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4f6280>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-13-expected66-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4197f0>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 13
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False,  True,  True,... True, False, False,  True, False,  True,  True,
       False,  True,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4197f0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-14-expected67-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4ea910>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 14
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4ea910>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-15-expected68-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5b5820>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 15
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True, False, False,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5b5820>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-16-expected69-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec3b2be0>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 16
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec3b2be0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-17-expected70-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5714c0>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 17
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5714c0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-18-expected71-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec497c10>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 18
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec497c10>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-19-expected72-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec3d00a0>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 19
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True, False,  True,  True,  True,  True,  True,
       False,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec3d00a0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-20-expected73-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4e2790>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 20
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True, False,  True,  True,  True,  True,  True,
        True,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4e2790>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-21-expected74-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec2980d0>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 21
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True, False,  True,  True,  True,  True,  True,
        True,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec2980d0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-22-expected75-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4af1f0>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 22
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4af1f0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-23-expected76-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec2533a0>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 23
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True, False,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec2533a0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-24-expected77-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec3be820>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 24
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec3be820>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-25-expected78-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7d3ca0>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 25
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec7d3ca0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-26-expected79-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4cfa30>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 26
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4cfa30>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-27-expected80-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec367310>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 27
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec367310>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-28-expected81-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec472370>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 28
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec472370>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-29-expected82-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec324eb0>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 29
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec324eb0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-30-expected83-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec57afa0>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 30
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec57afa0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-31-expected84-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec63e340>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 31
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec63e340>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-32-expected85-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec32be50>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 32
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec32be50>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-33-expected86-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec3d7040>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 33
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec3d7040>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-34-expected87-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec2e9f70>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 34
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec2e9f70>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-35-expected88-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec275cd0>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 35
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec275cd0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-36-expected89-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec3d7ac0>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 36
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec3d7ac0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-37-expected90-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4cb9d0>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.NUMBER: 'Number'>, value = 37
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4cb9d0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
__ test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-1-expected91-0-True] __

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5296d0>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.KFOLD: 'K Fold'>, value = 1
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec5296d0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected92-0-True] __

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec330160>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.KFOLD: 'K Fold'>, value = 10
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False,  True,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec330160>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected93-1-True] __

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec277430>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.KFOLD: 'K Fold'>, value = 10
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False,  True,
       False, False, False, False, False, False, False, False, False])
group_idx = 1, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec277430>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected94-2-True] __

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec2cb100>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.KFOLD: 'K Fold'>, value = 10
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False,  True,
       False, False, False, False, False, False, False, False, False])
group_idx = 2, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec2cb100>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected95-3-True] __

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8f95370>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.KFOLD: 'K Fold'>, value = 10
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False,  True,
       False, False, False, False, False, False, False, False, False])
group_idx = 3, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8f95370>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected96-4-True] __

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec275220>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.KFOLD: 'K Fold'>, value = 10
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 4, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec275220>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected97-5-True] __

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec489280>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.KFOLD: 'K Fold'>, value = 10
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 5, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec489280>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.0-expected98-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec2fac40>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.0
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False, False,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec2fac40>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.1-expected99-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec339940>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.1
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False, False,
       False, False, False, False, False, False, False, False, False])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec339940>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.2-expected100-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec63c820>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.2
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,...False, False, False, False, False, False,  True,
       False, False,  True, False, False, False, False, False, False])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec63c820>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.30000000000000004-expected101-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec293160>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.30000000000000004
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False, False,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True, False, False, False])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec293160>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.4-expected102-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec3a0ac0>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.4
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False,  True,  True,... True, False, False,  True, False, False,  True,
       False, False,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec3a0ac0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.5-expected103-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8f43280>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.5
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False,  True,  True,... True, False, False,  True, False,  True,  True,
       False,  True,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8f43280>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.6000000000000001-expected104-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec3a88e0>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.6000000000000001
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False, False,  True, False, False,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec3a88e0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.7000000000000001-expected105-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec3d64c0>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.7000000000000001
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False, False,  True,  True,... True, False,  True,  True, False,  True,  True,
       False,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec3d64c0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.8-expected106-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec367af0>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.8
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True, False,  True,  True,  True,  True,  True,
       False,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec367af0>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
_ test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.9-expected107-0-True] _

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec275160>
clean_mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])
split_unit = <SplitUnit.RATIO: 'Ratio'>, value = 0.9
expected = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True, False,  True,  True,  True,  True,  True,
        True,  True,  True, False,  True,  True, False,  True,  True])
group_idx = 0, is_partial = True

    @pytest.mark.parametrize(
            'split_unit, value, expected, group_idx, is_partial',
            _test_epochs_pick_by_trial_param()
        )
    @pytest.mark.parametrize('clean_mask', [
        None, np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
    ])
    def test_epochs_pick_by_trial(
        epochs, clean_mask,
        split_unit, value, expected,
        group_idx, is_partial
    ):
        mask = np.ones(block_size * len(subject_list) * len(session_list), dtype=bool)
        if is_partial:
            if clean_mask is not None:
                clean_mask[:block_size  * len(session_list)] = False
            mask[:block_size  * len(session_list)] = False
>       result, new_mask = epochs.pick_trial(
            mask, clean_mask, value, split_unit, group_idx
        )

XBrainLab/tests/backend/dataset/test_epochs.py:545: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/dataset/epochs.py:583: in pick_trial
    filter_preview_mask = self._generate_mask_target(mask)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec275160>
mask = array([False, False, False, False, False, False, False, False, False,
       False, False, False,  True,  True,  True,... True,  True,  True,  True,  True,  True,  True,
        True,  True,  True,  True,  True,  True,  True,  True,  True])

    def _generate_mask_target(self, mask: np.ndarray) -> dict:
        """Return mask-counter pair, group by label, subject, and session.
    
        Args:
            mask: Mask to filter out remaining epochs. 1D np.ndarray of bool.
    
        Returns:
            dict[label_idx][subject_idx][session_idx] = [target_filter_mask, count]
        """
        filter_preview_mask = {}
        unique_label_idx = np.unique(self.get_label_list())
        unique_subject_idx = np.unique(self.get_subject_list())
        unique_session_idx = np.unique(self.get_session_list())
        for label_idx in unique_label_idx:
            if label_idx not in filter_preview_mask:
                filter_preview_mask[label_idx] = {}
            for subject_idx in unique_subject_idx:
                if subject_idx not in filter_preview_mask[label_idx]:
                    filter_preview_mask[label_idx][subject_idx] = {}
                for session_idx in unique_session_idx:
                    filter_mask = (
                        (self.label == label_idx) &
                        (self.subject == subject_idx) &
                        (self.session == session_idx)
                    )
>                   target_filter_mask = filter_mask & mask
E                   ValueError: operands could not be broadcast together with shapes (6,) (36,)

XBrainLab/backend/dataset/epochs.py:302: ValueError
___________________________ test_epochs_pick_subject ___________________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec4e2dc0>

    def test_epochs_pick_subject(epochs):
        # Test picking subjects without mocks
        mask = np.ones(epochs.get_data_length(), dtype=bool)
        clean_mask = None
    
        # Pick 1 subject
        selected_mask, remaining_mask = epochs.pick_subject(
            mask, clean_mask, 1, SplitUnit.NUMBER, 0
        )
    
        # Verify selection
        selected_subjects = epochs.get_subject_list()[selected_mask]
        unique_selected = np.unique(selected_subjects)
        assert len(unique_selected) == 1
>       assert sum(selected_mask) == block_size * len(session_list) # 1 subject * sessions * trials
E       AssertionError: assert 2 == (6 * 2)
E        +  where 2 = sum(array([ True,  True, False, False, False, False]))
E        +  and   2 = len(['1', '2'])

XBrainLab/tests/backend/dataset/test_epochs.py:570: AssertionError
___________________________ test_epochs_pick_session ___________________________

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1ec240400>

    def test_epochs_pick_session(epochs):
        # Test picking sessions without mocks
        mask = np.ones(epochs.get_data_length(), dtype=bool)
        clean_mask = None
    
        # Pick 1 session
        selected_mask, remaining_mask = epochs.pick_session(
            mask, clean_mask, 1, SplitUnit.NUMBER, 0
        )
    
        # Verify selection
        selected_sessions = epochs.get_session_list()[selected_mask]
        unique_selected = np.unique(selected_sessions)
        assert len(unique_selected) == 1
>       assert sum(selected_mask) == block_size * len(subject_list) # 1 session * subjects * trials
E       AssertionError: assert 3 == (6 * 3)
E        +  where 3 = sum(array([ True, False,  True, False,  True, False]))
E        +  and   3 = len(['1', '2', '3'])

XBrainLab/tests/backend/dataset/test_epochs.py:601: AssertionError
_________________________ test_raw_data_loader_append __________________________

    def test_raw_data_loader_append():
        raw_mne = _generate_mne(500, ['Fp1', 'Fp2', 'F3', 'F4'], 'eeg')
>       raw_1 = _generate_epoch('1', raw_mne, 0.1)

XBrainLab/tests/backend/load_data/test_data_loader.py:40: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/tests/backend/load_data/test_data_loader.py:30: in _generate_epoch
    return Raw(
XBrainLab/backend/load_data/raw.py:43: in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = <MagicMock name='mock.Epochs()' id='134904589852928'>
type_class = (<class 'conftest.MockBaseRaw'>, <class 'conftest.MockBaseEpochs'>)
message_name = 'mne_data'

    def validate_type(instance: object,
                      type_class: type | tuple[type],
                      message_name: str) -> None:
        """Validate the type of an instance.
    
        Args:
            instance: The instance to be validated.
            type_class: Acceptable type(s) of the instance.
                        Can be a single type or a tuple of types.
            message_name: The name of the instance to be displayed in the error message.
    
        Raises:
            TypeError: If the instance is not an instance of the acceptable type(s).
        """
        if not isinstance(type_class, (list, tuple)):
            type_class = (type_class, )
        if not isinstance(instance, type_class):
            if len(type_class) == 1:
                type_class = type_class[0]
                type_name = _get_type_name(type_class)
            else:
                type_name_list = [_get_type_name(c) for c in type_class]
                type_name = ' or '.join(type_name_list)
>           raise TypeError(
                f"{message_name} must be an instance of {type_name}, "
                f"got {type(instance)} instead.")
E           TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.

XBrainLab/backend/utils/check.py:31: TypeError
______________________ test_raw_data_loader_append_error _______________________

    def test_raw_data_loader_append_error():
        raw_mne = _generate_mne(500, ['Fp1', 'Fp2', 'F3', 'F4'], 'eeg')
>       raw_1 = _generate_epoch('1', raw_mne, 0.1)

XBrainLab/tests/backend/load_data/test_data_loader.py:62: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/tests/backend/load_data/test_data_loader.py:30: in _generate_epoch
    return Raw(
XBrainLab/backend/load_data/raw.py:43: in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = <MagicMock name='mock.Epochs()' id='134904589852928'>
type_class = (<class 'conftest.MockBaseRaw'>, <class 'conftest.MockBaseEpochs'>)
message_name = 'mne_data'

    def validate_type(instance: object,
                      type_class: type | tuple[type],
                      message_name: str) -> None:
        """Validate the type of an instance.
    
        Args:
            instance: The instance to be validated.
            type_class: Acceptable type(s) of the instance.
                        Can be a single type or a tuple of types.
            message_name: The name of the instance to be displayed in the error message.
    
        Raises:
            TypeError: If the instance is not an instance of the acceptable type(s).
        """
        if not isinstance(type_class, (list, tuple)):
            type_class = (type_class, )
        if not isinstance(instance, type_class):
            if len(type_class) == 1:
                type_class = type_class[0]
                type_name = _get_type_name(type_class)
            else:
                type_name_list = [_get_type_name(c) for c in type_class]
                type_name = ' or '.join(type_name_list)
>           raise TypeError(
                f"{message_name} must be an instance of {type_name}, "
                f"got {type(instance)} instead.")
E           TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.

XBrainLab/backend/utils/check.py:31: TypeError
________________________ test_create_event_from_1d_list ________________________

raw = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ec4fb700>

    def test_create_event_from_1d_list(raw): # noqa: F811
        event_loader = EventLoader(raw)
        # Simulate labels loaded from label_loader (1D list/array)
        event_loader.label_list = [1, 2, 3, 4]
    
        with pytest.raises(ValueError, match='Event name cannot be empty.'):
            event_loader.create_event({0: ''})
    
        # Map 1->new 1, 2->new 2, etc.
        mapping = {1: 'new 1', 2: 'new 2', 3: 'new 3', 4: 'new 4'}
>       event_loader.create_event(mapping)

XBrainLab/tests/backend/load_data/test_event_loader.py:32: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.load_data.event_loader.EventLoader object at 0x7ab1ec4fb820>
event_name_map = {1: 'new 1', 2: 'new 2', 3: 'new 3', 4: 'new 4'}

    def create_event(self, event_name_map: dict[int, str]) -> tuple:
        """Create event array and event id.
    
        Args:
            event_name_map: Mapping from event code to event name.
    
        Returns:
            Tuple of event array and event id.
        """
        if self.label_list is not None and len(self.label_list) > 0:
            # check if new event name is valid
            for e in event_name_map:
                if not event_name_map[e].strip():
                    raise ValueError("Event name cannot be empty.")
    
            self.label_list = np.array(self.label_list)
            # label_list in (n,3) format
            if len(self.label_list.shape) > 1:
                # get new event id mapping
                event_id = {
                    event_name_map[i]: i
                    for i in np.unique(self.label_list[:, -1])
                }
                events = self.label_list
            # label_list in (n,) format
            else:
                # get new event id mapping
                event_id = {event_name_map[i]: i for i in np.unique(self.label_list)}
    
                # create new event array
                events = np.zeros((len(self.label_list), 3), dtype=int)
    
                # Try to sync with existing events (Timestamps)
                # This works for both Raw (GDF triggers) and Epochs
                existing_events = None
                try:
                    if self.raw.has_event():
                        existing_events, _ = self.raw.get_event_list()
                except Exception:
                    pass
    
                if existing_events is not None and len(existing_events) == len(self.label_list):
                    events[:, 0] = existing_events[:, 0] # Copy timestamps
                    # Copy previous value (column 1) if available
                    if existing_events.shape[1] >= 2:
                        events[:, 1] = existing_events[:, 1]
                else:
                    # Fallback: Create artificial timestamps
                    if self.raw.is_raw():
>                        raise ValueError(
                            'Could not sync with existing events (count mismatch or no events found). '
                            'Cannot import labels for Raw data without valid event markers.'
                        )
E                        ValueError: Could not sync with existing events (count mismatch or no events found). Cannot import labels for Raw data without valid event markers.

XBrainLab/backend/load_data/event_loader.py:82: ValueError
_________________ test_event_loader_raw_no_events_raises_error _________________

    def test_event_loader_raw_no_events_raises_error():
        """Test that loading labels for Raw data without events raises ValueError."""
        raw_mne = _generate_mne_raw()
        raw = Raw('test.fif', raw_mne)
    
        # Ensure no events
>       assert not raw.has_event()
E       assert not True
E        +  where True = has_event()
E        +    where has_event = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ec426d30>.has_event

XBrainLab/tests/backend/load_data/test_event_loader_strict.py:18: AssertionError
_____________________ test_event_loader_epochs_fallback_ok _____________________

    def test_event_loader_epochs_fallback_ok():
        """Test that Epochs data still allows artificial timestamps (indices)."""
        raw_mne = _generate_mne_raw()
        events = np.array([[10, 0, 1], [20, 0, 1]])
        event_id = {'A': 1}
        epochs_mne = mne.Epochs(raw_mne, events, event_id, tmin=0, tmax=0.1, baseline=None)
    
>       raw_epochs = Raw('test.fif', epochs_mne)

XBrainLab/tests/backend/load_data/test_event_loader_strict.py:52: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/load_data/raw.py:43: in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = <MagicMock name='mock.Epochs()' id='134904589852928'>
type_class = (<class 'conftest.MockBaseRaw'>, <class 'conftest.MockBaseEpochs'>)
message_name = 'mne_data'

    def validate_type(instance: object,
                      type_class: type | tuple[type],
                      message_name: str) -> None:
        """Validate the type of an instance.
    
        Args:
            instance: The instance to be validated.
            type_class: Acceptable type(s) of the instance.
                        Can be a single type or a tuple of types.
            message_name: The name of the instance to be displayed in the error message.
    
        Raises:
            TypeError: If the instance is not an instance of the acceptable type(s).
        """
        if not isinstance(type_class, (list, tuple)):
            type_class = (type_class, )
        if not isinstance(instance, type_class):
            if len(type_class) == 1:
                type_class = type_class[0]
                type_name = _get_type_name(type_class)
            else:
                type_name_list = [_get_type_name(c) for c in type_class]
                type_name = ' or '.join(type_name_list)
>           raise TypeError(
                f"{message_name} must be an instance of {type_name}, "
                f"got {type(instance)} instead.")
E           TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.

XBrainLab/backend/utils/check.py:31: TypeError
________________________ TestLoaders.test_load_bdf_file ________________________

self = <load_data.test_loaders.TestLoaders testMethod=test_load_bdf_file>
mock_read = <MagicMock name='read_raw_bdf' id='134904588627728'>

    @patch('mne.io.read_raw_bdf')
    def test_load_bdf_file(self, mock_read):
        mock_read.return_value = MagicMock()
        result = load_bdf_file('test.bdf')
        self.assertIsInstance(result, Raw)
>       mock_read.assert_called_with('test.bdf', preload=True)

XBrainLab/tests/backend/load_data/test_loaders.py:38: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock name='read_raw_bdf' id='134904588627728'>
args = ('test.bdf',), kwargs = {'preload': True}
expected = "read_raw_bdf('test.bdf', preload=True)", actual = 'not called.'
error_message = "expected call not found.\nExpected: read_raw_bdf('test.bdf', preload=True)\nActual: not called."

    def assert_called_with(self, /, *args, **kwargs):
        """assert that the last call was made with the specified arguments.
    
        Raises an AssertionError if the args and keyword args passed in are
        different to the last call to the mock."""
        if self.call_args is None:
            expected = self._format_mock_call_signature(args, kwargs)
            actual = 'not called.'
            error_message = ('expected call not found.\nExpected: %s\nActual: %s'
                    % (expected, actual))
>           raise AssertionError(error_message)
E           AssertionError: expected call not found.
E           Expected: read_raw_bdf('test.bdf', preload=True)
E           Actual: not called.

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:898: AssertionError
____________________ TestLoaders.test_load_brainvision_file ____________________

self = <load_data.test_loaders.TestLoaders testMethod=test_load_brainvision_file>
mock_read = <MagicMock name='read_raw_brainvision' id='134904590125904'>

    @patch('mne.io.read_raw_brainvision')
    def test_load_brainvision_file(self, mock_read):
        mock_read.return_value = MagicMock()
        result = load_brainvision_file('test.vhdr')
        self.assertIsInstance(result, Raw)
>       mock_read.assert_called_with('test.vhdr', preload=True)

XBrainLab/tests/backend/load_data/test_loaders.py:52: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock name='read_raw_brainvision' id='134904590125904'>
args = ('test.vhdr',), kwargs = {'preload': True}
expected = "read_raw_brainvision('test.vhdr', preload=True)"
actual = 'not called.'
error_message = "expected call not found.\nExpected: read_raw_brainvision('test.vhdr', preload=True)\nActual: not called."

    def assert_called_with(self, /, *args, **kwargs):
        """assert that the last call was made with the specified arguments.
    
        Raises an AssertionError if the args and keyword args passed in are
        different to the last call to the mock."""
        if self.call_args is None:
            expected = self._format_mock_call_signature(args, kwargs)
            actual = 'not called.'
            error_message = ('expected call not found.\nExpected: %s\nActual: %s'
                    % (expected, actual))
>           raise AssertionError(error_message)
E           AssertionError: expected call not found.
E           Expected: read_raw_brainvision('test.vhdr', preload=True)
E           Actual: not called.

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:898: AssertionError
________________________ TestLoaders.test_load_cnt_file ________________________

self = <load_data.test_loaders.TestLoaders testMethod=test_load_cnt_file>
mock_read = <MagicMock name='read_raw_cnt' id='134904589884720'>

    @patch('mne.io.read_raw_cnt')
    def test_load_cnt_file(self, mock_read):
        mock_read.return_value = MagicMock()
        result = load_cnt_file('test.cnt')
        self.assertIsInstance(result, Raw)
>       mock_read.assert_called_with('test.cnt', preload=True)

XBrainLab/tests/backend/load_data/test_loaders.py:45: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock name='read_raw_cnt' id='134904589884720'>
args = ('test.cnt',), kwargs = {'preload': True}
expected = "read_raw_cnt('test.cnt', preload=True)", actual = 'not called.'
error_message = "expected call not found.\nExpected: read_raw_cnt('test.cnt', preload=True)\nActual: not called."

    def assert_called_with(self, /, *args, **kwargs):
        """assert that the last call was made with the specified arguments.
    
        Raises an AssertionError if the args and keyword args passed in are
        different to the last call to the mock."""
        if self.call_args is None:
            expected = self._format_mock_call_signature(args, kwargs)
            actual = 'not called.'
            error_message = ('expected call not found.\nExpected: %s\nActual: %s'
                    % (expected, actual))
>           raise AssertionError(error_message)
E           AssertionError: expected call not found.
E           Expected: read_raw_cnt('test.cnt', preload=True)
E           Actual: not called.

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:898: AssertionError
________________________ TestLoaders.test_load_edf_file ________________________

self = <load_data.test_loaders.TestLoaders testMethod=test_load_edf_file>
mock_read = <MagicMock name='read_raw_edf' id='134904588434256'>

    @patch('mne.io.read_raw_edf')
    def test_load_edf_file(self, mock_read):
        mock_read.return_value = MagicMock()
        result = load_edf_file('test.edf')
        self.assertIsInstance(result, Raw)
>       mock_read.assert_called_with('test.edf', preload=True)

XBrainLab/tests/backend/load_data/test_loaders.py:31: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock name='read_raw_edf' id='134904588434256'>
args = ('test.edf',), kwargs = {'preload': True}
expected = "read_raw_edf('test.edf', preload=True)", actual = 'not called.'
error_message = "expected call not found.\nExpected: read_raw_edf('test.edf', preload=True)\nActual: not called."

    def assert_called_with(self, /, *args, **kwargs):
        """assert that the last call was made with the specified arguments.
    
        Raises an AssertionError if the args and keyword args passed in are
        different to the last call to the mock."""
        if self.call_args is None:
            expected = self._format_mock_call_signature(args, kwargs)
            actual = 'not called.'
            error_message = ('expected call not found.\nExpected: %s\nActual: %s'
                    % (expected, actual))
>           raise AssertionError(error_message)
E           AssertionError: expected call not found.
E           Expected: read_raw_edf('test.edf', preload=True)
E           Actual: not called.

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:898: AssertionError
______________________ TestLoaders.test_load_fif_failure _______________________

self = <load_data.test_loaders.TestLoaders testMethod=test_load_fif_failure>
mock_read = <MagicMock name='read_raw_fif' id='134904588498736'>

    @patch('mne.io.read_raw_fif')
    def test_load_fif_failure(self, mock_read):
        mock_read.side_effect = Exception("Load failed")
        result = load_fif_file('test.fif')
>       self.assertIsNone(result)
E       AssertionError: <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ec143520> is not None

XBrainLab/tests/backend/load_data/test_loaders.py:58: AssertionError
________________________ TestLoaders.test_load_fif_file ________________________

self = <load_data.test_loaders.TestLoaders testMethod=test_load_fif_file>
mock_read = <MagicMock name='read_raw_fif' id='134904588303568'>

    @patch('mne.io.read_raw_fif')
    def test_load_fif_file(self, mock_read):
        mock_read.return_value = MagicMock()
        result = load_fif_file('test.fif')
        self.assertIsInstance(result, Raw)
>       mock_read.assert_called_with('test.fif', preload=True)

XBrainLab/tests/backend/load_data/test_loaders.py:24: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock name='read_raw_fif' id='134904588303568'>
args = ('test.fif',), kwargs = {'preload': True}
expected = "read_raw_fif('test.fif', preload=True)", actual = 'not called.'
error_message = "expected call not found.\nExpected: read_raw_fif('test.fif', preload=True)\nActual: not called."

    def assert_called_with(self, /, *args, **kwargs):
        """assert that the last call was made with the specified arguments.
    
        Raises an AssertionError if the args and keyword args passed in are
        different to the last call to the mock."""
        if self.call_args is None:
            expected = self._format_mock_call_signature(args, kwargs)
            actual = 'not called.'
            error_message = ('expected call not found.\nExpected: %s\nActual: %s'
                    % (expected, actual))
>           raise AssertionError(error_message)
E           AssertionError: expected call not found.
E           Expected: read_raw_fif('test.fif', preload=True)
E           Actual: not called.

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:898: AssertionError
______________________________ test_mne_raw_info _______________________________

mne_raw = <conftest.MockBaseRaw object at 0x7ab1ec2fa580>
raw = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ec2fa880>

    def test_mne_raw_info(mne_raw, raw):
        assert mne_raw == raw.get_mne()
        assert raw.get_tmin() == 0.0
>       assert raw.get_nchan() == 4
E       assert 1 == 4
E        +  where 1 = get_nchan()
E        +    where get_nchan = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ec2fa880>.get_nchan

XBrainLab/tests/backend/load_data/test_raw.py:105: AssertionError
_____________________________ test_mne_raw_2_info ______________________________

mne_raw_2 = <conftest.MockBaseRaw object at 0x7ab1ec44abb0>
raw = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ec44a850>

    def test_mne_raw_2_info(mne_raw_2, raw):
>       raw.set_mne(mne_raw_2)

XBrainLab/tests/backend/load_data/test_raw.py:118: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ec44a850>
data = <conftest.MockBaseRaw object at 0x7ab1ec44abb0>

    def set_mne(self, data: mne.io.BaseRaw | mne.BaseEpochs) -> None:
        """Set new mne data.
    
        Args:
            data: New mne data.
        """
        # set loaded event to new data
        if (
>           isinstance(data, mne.epochs.BaseEpochs) and
            self.raw_event_id
        ):
E       TypeError: isinstance() arg 2 must be a type or tuple of types

XBrainLab/backend/load_data/raw.py:133: TypeError
_____________________________ test_raw_empty_event _____________________________

raw = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ec5b12e0>

    def test_raw_empty_event(raw):
>       assert raw.has_event_str() == 'no'
E       AssertionError: assert 'yes' == 'no'
E         
E         - no
E         + yes

XBrainLab/tests/backend/load_data/test_raw.py:138: AssertionError
______________________ test_raw_set_event_on_empty_event _______________________

raw = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ec13a220>

    def test_raw_set_event_on_empty_event(raw):
        test_set_event(raw)
        # check raw event
        events, event_id = raw.get_raw_event_list()
>       assert len(events) == 0
E       assert 1 == 0
E        +  where 1 = len(array([[0, 0, 1]]))

XBrainLab/tests/backend/load_data/test_raw.py:151: AssertionError
_____________________________ test_raw_stim_event ______________________________

stim_raw = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ec239a90>

    def test_raw_stim_event(stim_raw):
        assert stim_raw.has_event_str() == 'yes'
>       assert stim_raw.get_event_name_list_str() == '1,2,3'
E       AssertionError: assert 'test' == '1,2,3'
E         
E         - 1,2,3
E         + test

XBrainLab/tests/backend/load_data/test_raw.py:174: AssertionError
_______________________ test_raw_set_event_on_stim_event _______________________

stim_raw = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ec407be0>

    def test_raw_set_event_on_stim_event(stim_raw):
        test_set_event(stim_raw)
        events, event_id = stim_raw.get_raw_event_list()
>       assert len(events) == 3
E       assert 1 == 3
E        +  where 1 = len(array([[0, 0, 1]]))

XBrainLab/tests/backend/load_data/test_raw.py:185: AssertionError
_____________________________ test_set_mne_1[raw] ______________________________

mne_raw_2 = <conftest.MockBaseRaw object at 0x7ab1ec1264c0>
target = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ec1265b0>
request = <FixtureRequest for <Function test_set_mne_1[raw]>>

    @pytest.mark.parametrize('target', ['raw', 'epoch'])
    def test_set_mne_1(mne_raw_2, target, request):
        target = request.getfixturevalue(target)
>       target.set_mne(mne_raw_2)

XBrainLab/tests/backend/load_data/test_raw.py:274: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ec1265b0>
data = <conftest.MockBaseRaw object at 0x7ab1ec1264c0>

    def set_mne(self, data: mne.io.BaseRaw | mne.BaseEpochs) -> None:
        """Set new mne data.
    
        Args:
            data: New mne data.
        """
        # set loaded event to new data
        if (
>           isinstance(data, mne.epochs.BaseEpochs) and
            self.raw_event_id
        ):
E       TypeError: isinstance() arg 2 must be a type or tuple of types

XBrainLab/backend/load_data/raw.py:133: TypeError
____________________________ test_set_mne_1[epoch] _____________________________

mne_raw_2 = <conftest.MockBaseRaw object at 0x7ab1ec3ac6a0>, target = 'epoch'
request = <FixtureRequest for <Function test_set_mne_1[epoch]>>

    @pytest.mark.parametrize('target', ['raw', 'epoch'])
    def test_set_mne_1(mne_raw_2, target, request):
>       target = request.getfixturevalue(target)

XBrainLab/tests/backend/load_data/test_raw.py:273: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:549: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:640: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:1128: in execute
    result = ihook.pytest_fixture_setup(fixturedef=self, request=request)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:1196: in pytest_fixture_setup
    result = call_fixture_func(fixturefunc, request, kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:930: in call_fixture_func
    fixture_result = fixturefunc(**kwargs)
XBrainLab/tests/backend/load_data/test_raw.py:238: in epoch
    return Raw(path, mne_epoch)
XBrainLab/backend/load_data/raw.py:43: in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = <MagicMock name='mock.Epochs()' id='134904589852928'>
type_class = (<class 'conftest.MockBaseRaw'>, <class 'conftest.MockBaseEpochs'>)
message_name = 'mne_data'

    def validate_type(instance: object,
                      type_class: type | tuple[type],
                      message_name: str) -> None:
        """Validate the type of an instance.
    
        Args:
            instance: The instance to be validated.
            type_class: Acceptable type(s) of the instance.
                        Can be a single type or a tuple of types.
            message_name: The name of the instance to be displayed in the error message.
    
        Raises:
            TypeError: If the instance is not an instance of the acceptable type(s).
        """
        if not isinstance(type_class, (list, tuple)):
            type_class = (type_class, )
        if not isinstance(instance, type_class):
            if len(type_class) == 1:
                type_class = type_class[0]
                type_name = _get_type_name(type_class)
            else:
                type_name_list = [_get_type_name(c) for c in type_class]
                type_name = ' or '.join(type_name_list)
>           raise TypeError(
                f"{message_name} must be an instance of {type_name}, "
                f"got {type(instance)} instead.")
E           TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.

XBrainLab/backend/utils/check.py:31: TypeError
_____________________________ test_set_mne_2[raw] ______________________________

mne_epoch = <MagicMock name='mock.Epochs()' id='134904589852928'>
target = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ec03c3d0>
request = <FixtureRequest for <Function test_set_mne_2[raw]>>

    @pytest.mark.parametrize('target', ['raw', 'epoch'])
    def test_set_mne_2(mne_epoch, target, request):
        target = request.getfixturevalue(target)
>       target.set_mne(mne_epoch)

XBrainLab/tests/backend/load_data/test_raw.py:280: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ec03c3d0>
data = <MagicMock name='mock.Epochs()' id='134904589852928'>

    def set_mne(self, data: mne.io.BaseRaw | mne.BaseEpochs) -> None:
        """Set new mne data.
    
        Args:
            data: New mne data.
        """
        # set loaded event to new data
        if (
>           isinstance(data, mne.epochs.BaseEpochs) and
            self.raw_event_id
        ):
E       TypeError: isinstance() arg 2 must be a type or tuple of types

XBrainLab/backend/load_data/raw.py:133: TypeError
____________________________ test_set_mne_2[epoch] _____________________________

mne_epoch = <MagicMock name='mock.Epochs()' id='134904589852928'>
target = 'epoch'
request = <FixtureRequest for <Function test_set_mne_2[epoch]>>

    @pytest.mark.parametrize('target', ['raw', 'epoch'])
    def test_set_mne_2(mne_epoch, target, request):
>       target = request.getfixturevalue(target)

XBrainLab/tests/backend/load_data/test_raw.py:279: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:549: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:640: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:1128: in execute
    result = ihook.pytest_fixture_setup(fixturedef=self, request=request)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:1196: in pytest_fixture_setup
    result = call_fixture_func(fixturefunc, request, kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:930: in call_fixture_func
    fixture_result = fixturefunc(**kwargs)
XBrainLab/tests/backend/load_data/test_raw.py:238: in epoch
    return Raw(path, mne_epoch)
XBrainLab/backend/load_data/raw.py:43: in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = <MagicMock name='mock.Epochs()' id='134904589852928'>
type_class = (<class 'conftest.MockBaseRaw'>, <class 'conftest.MockBaseEpochs'>)
message_name = 'mne_data'

    def validate_type(instance: object,
                      type_class: type | tuple[type],
                      message_name: str) -> None:
        """Validate the type of an instance.
    
        Args:
            instance: The instance to be validated.
            type_class: Acceptable type(s) of the instance.
                        Can be a single type or a tuple of types.
            message_name: The name of the instance to be displayed in the error message.
    
        Raises:
            TypeError: If the instance is not an instance of the acceptable type(s).
        """
        if not isinstance(type_class, (list, tuple)):
            type_class = (type_class, )
        if not isinstance(instance, type_class):
            if len(type_class) == 1:
                type_class = type_class[0]
                type_name = _get_type_name(type_class)
            else:
                type_name_list = [_get_type_name(c) for c in type_class]
                type_name = ' or '.join(type_name_list)
>           raise TypeError(
                f"{message_name} must be an instance of {type_name}, "
                f"got {type(instance)} instead.")
E           TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.

XBrainLab/backend/utils/check.py:31: TypeError
_____________________ test_set_mne_after_set_event_1[raw] ______________________

mne_raw_2 = <conftest.MockBaseRaw object at 0x7ab1ec0634f0>
target = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ec063e20>
request = <FixtureRequest for <Function test_set_mne_after_set_event_1[raw]>>

    @pytest.mark.parametrize('target', ['raw', 'epoch'])
    def test_set_mne_after_set_event_1(mne_raw_2, target, request):
        target = request.getfixturevalue(target)
        test_set_event(target)
>       target.set_mne(mne_raw_2)

XBrainLab/tests/backend/load_data/test_raw.py:287: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ec063e20>
data = <conftest.MockBaseRaw object at 0x7ab1ec0634f0>

    def set_mne(self, data: mne.io.BaseRaw | mne.BaseEpochs) -> None:
        """Set new mne data.
    
        Args:
            data: New mne data.
        """
        # set loaded event to new data
        if (
>           isinstance(data, mne.epochs.BaseEpochs) and
            self.raw_event_id
        ):
E       TypeError: isinstance() arg 2 must be a type or tuple of types

XBrainLab/backend/load_data/raw.py:133: TypeError
____________________ test_set_mne_after_set_event_1[epoch] _____________________

mne_raw_2 = <conftest.MockBaseRaw object at 0x7ab1ec357970>, target = 'epoch'
request = <FixtureRequest for <Function test_set_mne_after_set_event_1[epoch]>>

    @pytest.mark.parametrize('target', ['raw', 'epoch'])
    def test_set_mne_after_set_event_1(mne_raw_2, target, request):
>       target = request.getfixturevalue(target)

XBrainLab/tests/backend/load_data/test_raw.py:285: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:549: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:640: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:1128: in execute
    result = ihook.pytest_fixture_setup(fixturedef=self, request=request)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:1196: in pytest_fixture_setup
    result = call_fixture_func(fixturefunc, request, kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:930: in call_fixture_func
    fixture_result = fixturefunc(**kwargs)
XBrainLab/tests/backend/load_data/test_raw.py:238: in epoch
    return Raw(path, mne_epoch)
XBrainLab/backend/load_data/raw.py:43: in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = <MagicMock name='mock.Epochs()' id='134904589852928'>
type_class = (<class 'conftest.MockBaseRaw'>, <class 'conftest.MockBaseEpochs'>)
message_name = 'mne_data'

    def validate_type(instance: object,
                      type_class: type | tuple[type],
                      message_name: str) -> None:
        """Validate the type of an instance.
    
        Args:
            instance: The instance to be validated.
            type_class: Acceptable type(s) of the instance.
                        Can be a single type or a tuple of types.
            message_name: The name of the instance to be displayed in the error message.
    
        Raises:
            TypeError: If the instance is not an instance of the acceptable type(s).
        """
        if not isinstance(type_class, (list, tuple)):
            type_class = (type_class, )
        if not isinstance(instance, type_class):
            if len(type_class) == 1:
                type_class = type_class[0]
                type_name = _get_type_name(type_class)
            else:
                type_name_list = [_get_type_name(c) for c in type_class]
                type_name = ' or '.join(type_name_list)
>           raise TypeError(
                f"{message_name} must be an instance of {type_name}, "
                f"got {type(instance)} instead.")
E           TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.

XBrainLab/backend/utils/check.py:31: TypeError
_____________________ test_set_mne_after_set_event_2[raw] ______________________

mne_epoch = <MagicMock name='mock.Epochs()' id='134904589852928'>
target = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ebe61700>
request = <FixtureRequest for <Function test_set_mne_after_set_event_2[raw]>>

    @pytest.mark.parametrize('target', ['raw', 'epoch'])
    def test_set_mne_after_set_event_2(mne_epoch, target, request):
        target = request.getfixturevalue(target)
        test_set_event(target)
>       target.set_mne(mne_epoch)

XBrainLab/tests/backend/load_data/test_raw.py:301: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ebe61700>
data = <MagicMock name='mock.Epochs()' id='134904589852928'>

    def set_mne(self, data: mne.io.BaseRaw | mne.BaseEpochs) -> None:
        """Set new mne data.
    
        Args:
            data: New mne data.
        """
        # set loaded event to new data
        if (
>           isinstance(data, mne.epochs.BaseEpochs) and
            self.raw_event_id
        ):
E       TypeError: isinstance() arg 2 must be a type or tuple of types

XBrainLab/backend/load_data/raw.py:133: TypeError
____________________ test_set_mne_after_set_event_2[epoch] _____________________

mne_epoch = <MagicMock name='mock.Epochs()' id='134904589852928'>
target = 'epoch'
request = <FixtureRequest for <Function test_set_mne_after_set_event_2[epoch]>>

    @pytest.mark.parametrize('target', ['raw', 'epoch'])
    def test_set_mne_after_set_event_2(mne_epoch, target, request):
>       target = request.getfixturevalue(target)

XBrainLab/tests/backend/load_data/test_raw.py:299: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:549: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:640: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:1128: in execute
    result = ihook.pytest_fixture_setup(fixturedef=self, request=request)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:1196: in pytest_fixture_setup
    result = call_fixture_func(fixturefunc, request, kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:930: in call_fixture_func
    fixture_result = fixturefunc(**kwargs)
XBrainLab/tests/backend/load_data/test_raw.py:238: in epoch
    return Raw(path, mne_epoch)
XBrainLab/backend/load_data/raw.py:43: in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = <MagicMock name='mock.Epochs()' id='134904589852928'>
type_class = (<class 'conftest.MockBaseRaw'>, <class 'conftest.MockBaseEpochs'>)
message_name = 'mne_data'

    def validate_type(instance: object,
                      type_class: type | tuple[type],
                      message_name: str) -> None:
        """Validate the type of an instance.
    
        Args:
            instance: The instance to be validated.
            type_class: Acceptable type(s) of the instance.
                        Can be a single type or a tuple of types.
            message_name: The name of the instance to be displayed in the error message.
    
        Raises:
            TypeError: If the instance is not an instance of the acceptable type(s).
        """
        if not isinstance(type_class, (list, tuple)):
            type_class = (type_class, )
        if not isinstance(instance, type_class):
            if len(type_class) == 1:
                type_class = type_class[0]
                type_name = _get_type_name(type_class)
            else:
                type_name_list = [_get_type_name(c) for c in type_class]
                type_name = ' or '.join(type_name_list)
>           raise TypeError(
                f"{message_name} must be an instance of {type_name}, "
                f"got {type(instance)} instead.")
E           TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.

XBrainLab/backend/utils/check.py:31: TypeError
_____________________ test_set_mne_and_wipe_events_1[raw] ______________________

mne_raw_2 = <conftest.MockBaseRaw object at 0x7ab1ec1756a0>
target = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ec175ac0>
request = <FixtureRequest for <Function test_set_mne_and_wipe_events_1[raw]>>

    @pytest.mark.parametrize('target', ['raw', 'epoch'])
    def test_set_mne_and_wipe_events_1(mne_raw_2, target, request):
        target = request.getfixturevalue(target)
        target.set_mne_and_wipe_events(mne_raw_2)
>       test_mne_raw_2_info(mne_raw_2, target)

XBrainLab/tests/backend/load_data/test_raw.py:320: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/tests/backend/load_data/test_raw.py:118: in test_mne_raw_2_info
    raw.set_mne(mne_raw_2)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ec175ac0>
data = <conftest.MockBaseRaw object at 0x7ab1ec1756a0>

    def set_mne(self, data: mne.io.BaseRaw | mne.BaseEpochs) -> None:
        """Set new mne data.
    
        Args:
            data: New mne data.
        """
        # set loaded event to new data
        if (
>           isinstance(data, mne.epochs.BaseEpochs) and
            self.raw_event_id
        ):
E       TypeError: isinstance() arg 2 must be a type or tuple of types

XBrainLab/backend/load_data/raw.py:133: TypeError
____________________ test_set_mne_and_wipe_events_1[epoch] _____________________

mne_raw_2 = <conftest.MockBaseRaw object at 0x7ab1ec5f6f70>, target = 'epoch'
request = <FixtureRequest for <Function test_set_mne_and_wipe_events_1[epoch]>>

    @pytest.mark.parametrize('target', ['raw', 'epoch'])
    def test_set_mne_and_wipe_events_1(mne_raw_2, target, request):
>       target = request.getfixturevalue(target)

XBrainLab/tests/backend/load_data/test_raw.py:318: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:549: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:640: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:1128: in execute
    result = ihook.pytest_fixture_setup(fixturedef=self, request=request)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:1196: in pytest_fixture_setup
    result = call_fixture_func(fixturefunc, request, kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:930: in call_fixture_func
    fixture_result = fixturefunc(**kwargs)
XBrainLab/tests/backend/load_data/test_raw.py:238: in epoch
    return Raw(path, mne_epoch)
XBrainLab/backend/load_data/raw.py:43: in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = <MagicMock name='mock.Epochs()' id='134904589852928'>
type_class = (<class 'conftest.MockBaseRaw'>, <class 'conftest.MockBaseEpochs'>)
message_name = 'mne_data'

    def validate_type(instance: object,
                      type_class: type | tuple[type],
                      message_name: str) -> None:
        """Validate the type of an instance.
    
        Args:
            instance: The instance to be validated.
            type_class: Acceptable type(s) of the instance.
                        Can be a single type or a tuple of types.
            message_name: The name of the instance to be displayed in the error message.
    
        Raises:
            TypeError: If the instance is not an instance of the acceptable type(s).
        """
        if not isinstance(type_class, (list, tuple)):
            type_class = (type_class, )
        if not isinstance(instance, type_class):
            if len(type_class) == 1:
                type_class = type_class[0]
                type_name = _get_type_name(type_class)
            else:
                type_name_list = [_get_type_name(c) for c in type_class]
                type_name = ' or '.join(type_name_list)
>           raise TypeError(
                f"{message_name} must be an instance of {type_name}, "
                f"got {type(instance)} instead.")
E           TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.

XBrainLab/backend/utils/check.py:31: TypeError
_____________________ test_set_mne_and_wipe_events_2[raw] ______________________

mne_epoch = <MagicMock name='mock.Epochs()' id='134904589852928'>
target = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ebda7370>
request = <FixtureRequest for <Function test_set_mne_and_wipe_events_2[raw]>>

    @pytest.mark.parametrize('target', ['raw', 'epoch'])
    def test_set_mne_and_wipe_events_2(mne_epoch, target, request):
        target = request.getfixturevalue(target)
        target.set_mne_and_wipe_events(mne_epoch)
>       test_mne_epoch_info(mne_epoch, target)

XBrainLab/tests/backend/load_data/test_raw.py:326: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

mne_epoch = <MagicMock name='mock.Epochs()' id='134904589852928'>
epoch = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ebda7370>

    def test_mne_epoch_info(mne_epoch, epoch):
        assert mne_epoch == epoch.get_mne()
>       assert epoch.get_tmin() == 0.0
E       AssertionError: assert <MagicMock name='mock.Epochs().tmin' id='134904588006496'> == 0.0
E        +  where <MagicMock name='mock.Epochs().tmin' id='134904588006496'> = get_tmin()
E        +    where get_tmin = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ebda7370>.get_tmin

XBrainLab/tests/backend/load_data/test_raw.py:242: AssertionError
____________________ test_set_mne_and_wipe_events_2[epoch] _____________________

mne_epoch = <MagicMock name='mock.Epochs()' id='134904589852928'>
target = 'epoch'
request = <FixtureRequest for <Function test_set_mne_and_wipe_events_2[epoch]>>

    @pytest.mark.parametrize('target', ['raw', 'epoch'])
    def test_set_mne_and_wipe_events_2(mne_epoch, target, request):
>       target = request.getfixturevalue(target)

XBrainLab/tests/backend/load_data/test_raw.py:324: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:549: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:640: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:1128: in execute
    result = ihook.pytest_fixture_setup(fixturedef=self, request=request)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:1196: in pytest_fixture_setup
    result = call_fixture_func(fixturefunc, request, kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:930: in call_fixture_func
    fixture_result = fixturefunc(**kwargs)
XBrainLab/tests/backend/load_data/test_raw.py:238: in epoch
    return Raw(path, mne_epoch)
XBrainLab/backend/load_data/raw.py:43: in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = <MagicMock name='mock.Epochs()' id='134904589852928'>
type_class = (<class 'conftest.MockBaseRaw'>, <class 'conftest.MockBaseEpochs'>)
message_name = 'mne_data'

    def validate_type(instance: object,
                      type_class: type | tuple[type],
                      message_name: str) -> None:
        """Validate the type of an instance.
    
        Args:
            instance: The instance to be validated.
            type_class: Acceptable type(s) of the instance.
                        Can be a single type or a tuple of types.
            message_name: The name of the instance to be displayed in the error message.
    
        Raises:
            TypeError: If the instance is not an instance of the acceptable type(s).
        """
        if not isinstance(type_class, (list, tuple)):
            type_class = (type_class, )
        if not isinstance(instance, type_class):
            if len(type_class) == 1:
                type_class = type_class[0]
                type_name = _get_type_name(type_class)
            else:
                type_name_list = [_get_type_name(c) for c in type_class]
                type_name = ' or '.join(type_name_list)
>           raise TypeError(
                f"{message_name} must be an instance of {type_name}, "
                f"got {type(instance)} instead.")
E           TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.

XBrainLab/backend/utils/check.py:31: TypeError
___________________________ test_filtering_bandpass ____________________________

mock_raw_data = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ebeded30>

    def test_filtering_bandpass(mock_raw_data):
        """Test standard bandpass filtering."""
        filt = Filtering([mock_raw_data])
    
        # Apply 1-40Hz bandpass
>       filt.data_preprocess(l_freq=1.0, h_freq=40.0)

XBrainLab/tests/backend/preprocessor/test_filtering.py:27: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/preprocessor/base.py:41: in data_preprocess
    self._data_preprocess(preprocessed_data, *args, **kargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.preprocessor.filtering.Filtering object at 0x7ab1ebeded60>
preprocessed_data = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ebedee50>
l_freq = 1.0, h_freq = 40.0, notch_freqs = None

    def _data_preprocess(self, preprocessed_data: Raw, l_freq: float, h_freq: float, notch_freqs=None):
>       preprocessed_data.get_mne().load_data()
E       AttributeError: 'MockBaseRaw' object has no attribute 'load_data'

XBrainLab/backend/preprocessor/filtering.py:24: AttributeError
_____________________________ test_filtering_notch _____________________________

mock_raw_data = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ebef5e80>

    def test_filtering_notch(mock_raw_data):
        """Test notch filtering."""
        filt = Filtering([mock_raw_data])
    
        # Apply Notch at 50Hz
>       filt.data_preprocess(l_freq=None, h_freq=None, notch_freqs=50.0)

XBrainLab/tests/backend/preprocessor/test_filtering.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/preprocessor/base.py:41: in data_preprocess
    self._data_preprocess(preprocessed_data, *args, **kargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.preprocessor.filtering.Filtering object at 0x7ab1ebef5e20>
preprocessed_data = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ebef5e50>
l_freq = None, h_freq = None, notch_freqs = 50.0

    def _data_preprocess(self, preprocessed_data: Raw, l_freq: float, h_freq: float, notch_freqs=None):
>       preprocessed_data.get_mne().load_data()
E       AttributeError: 'MockBaseRaw' object has no attribute 'load_data'

XBrainLab/backend/preprocessor/filtering.py:24: AttributeError
___________________________ test_filtering_combined ____________________________

mock_raw_data = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ebee9cd0>

    def test_filtering_combined(mock_raw_data):
        """Test combined bandpass and notch filtering."""
        filt = Filtering([mock_raw_data])
    
>       filt.data_preprocess(l_freq=1.0, h_freq=100.0, notch_freqs=50.0)

XBrainLab/tests/backend/preprocessor/test_filtering.py:75: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/preprocessor/base.py:41: in data_preprocess
    self._data_preprocess(preprocessed_data, *args, **kargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.preprocessor.filtering.Filtering object at 0x7ab1ebee96a0>
preprocessed_data = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ebee9610>
l_freq = 1.0, h_freq = 100.0, notch_freqs = 50.0

    def _data_preprocess(self, preprocessed_data: Raw, l_freq: float, h_freq: float, notch_freqs=None):
>       preprocessed_data.get_mne().load_data()
E       AttributeError: 'MockBaseRaw' object has no attribute 'load_data'

XBrainLab/backend/preprocessor/filtering.py:24: AttributeError
______________________ test_ica_picard_missing_dependency ______________________

mock_raw_data = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ebef8e20>

    def test_ica_picard_missing_dependency(mock_raw_data):
        """Test that ICA raises ImportError when picard is selected but missing."""
        ica_processor = ICA([mock_raw_data])
    
        # Mock import failure
        with patch.dict('sys.modules', {'picard': None}):
            with pytest.raises(ImportError, match="The 'picard' package is required"):
>               ica_processor.data_preprocess(n_components=5, method='picard')

XBrainLab/tests/backend/preprocessor/test_ica.py:33: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/preprocessor/base.py:41: in data_preprocess
    self._data_preprocess(preprocessed_data, *args, **kargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.preprocessor.ica.ICA object at 0x7ab1ebef8cd0>
preprocessed_data = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ebef8d30>
n_components = 5, method = 'picard', random_state = 97

    def _data_preprocess(self, preprocessed_data: Raw, n_components: int, method: str = 'fastica', random_state: int = 97):
>       preprocessed_data.get_mne().load_data()
E       AttributeError: 'MockBaseRaw' object has no attribute 'load_data'

XBrainLab/backend/preprocessor/ica.py:19: AttributeError
______________________________ test_ica_fit_apply ______________________________

mock_raw_data = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ebef54c0>

    def test_ica_fit_apply(mock_raw_data):
        # Test basic ICA initialization and application
        ica_proc = ICA([mock_raw_data])
    
        # Apply ICA with 3 components
        # Using 'fastica'
>       ica_proc.data_preprocess(n_components=3, method='fastica', random_state=42)

XBrainLab/tests/backend/preprocessor/test_ica.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/preprocessor/base.py:41: in data_preprocess
    self._data_preprocess(preprocessed_data, *args, **kargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.preprocessor.ica.ICA object at 0x7ab1ebef54f0>
preprocessed_data = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ebef5ca0>
n_components = 3, method = 'fastica', random_state = 42

    def _data_preprocess(self, preprocessed_data: Raw, n_components: int, method: str = 'fastica', random_state: int = 97):
>       preprocessed_data.get_mne().load_data()
E       AttributeError: 'MockBaseRaw' object has no attribute 'load_data'

XBrainLab/backend/preprocessor/ica.py:19: AttributeError
_________________________ test_channel_selection[raw] __________________________

target = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ebda8f10>
request = <FixtureRequest for <Function test_channel_selection[raw]>>

    @pytest.mark.parametrize('target', ['raw', 'epoch'])
    def test_channel_selection(target, request):
        target = request.getfixturevalue(target)
        processor = preprocessor.ChannelSelection([target])
    
        with pytest.raises(ValueError):
            processor.data_preprocess([])
    
>       processor.data_preprocess(['Fp1', 'Fp2'])

XBrainLab/tests/backend/preprocessor/test_preprocess.py:41: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/preprocessor/base.py:41: in data_preprocess
    self._data_preprocess(preprocessed_data, *args, **kargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.preprocessor.channel_selection.ChannelSelection object at 0x7ab1ebda88b0>
preprocessed_data = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ebda87f0>
selected_channels = ['Fp1', 'Fp2']

    def _data_preprocess(self, preprocessed_data: Raw, selected_channels: List[str]):
        # Check if channel is selected
        if len(selected_channels) == 0:
            raise ValueError("No Channel is Selected")
>       preprocessed_data.get_mne().pick_channels(selected_channels)
E       AttributeError: 'MockBaseRaw' object has no attribute 'pick_channels'

XBrainLab/backend/preprocessor/channel_selection.py:21: AttributeError
________________________ test_channel_selection[epoch] _________________________

target = 'epoch'
request = <FixtureRequest for <Function test_channel_selection[epoch]>>

    @pytest.mark.parametrize('target', ['raw', 'epoch'])
    def test_channel_selection(target, request):
>       target = request.getfixturevalue(target)

XBrainLab/tests/backend/preprocessor/test_preprocess.py:35: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:549: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:640: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:1128: in execute
    result = ihook.pytest_fixture_setup(fixturedef=self, request=request)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:1196: in pytest_fixture_setup
    result = call_fixture_func(fixturefunc, request, kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:930: in call_fixture_func
    fixture_result = fixturefunc(**kwargs)
XBrainLab/tests/backend/preprocessor/test_preprocess.py:30: in epoch
    return Raw(path, mne_epoch)
XBrainLab/backend/load_data/raw.py:43: in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = <MagicMock name='mock.Epochs()' id='134904589852928'>
type_class = (<class 'conftest.MockBaseRaw'>, <class 'conftest.MockBaseEpochs'>)
message_name = 'mne_data'

    def validate_type(instance: object,
                      type_class: type | tuple[type],
                      message_name: str) -> None:
        """Validate the type of an instance.
    
        Args:
            instance: The instance to be validated.
            type_class: Acceptable type(s) of the instance.
                        Can be a single type or a tuple of types.
            message_name: The name of the instance to be displayed in the error message.
    
        Raises:
            TypeError: If the instance is not an instance of the acceptable type(s).
        """
        if not isinstance(type_class, (list, tuple)):
            type_class = (type_class, )
        if not isinstance(instance, type_class):
            if len(type_class) == 1:
                type_class = type_class[0]
                type_name = _get_type_name(type_class)
            else:
                type_name_list = [_get_type_name(c) for c in type_class]
                type_name = ' or '.join(type_name_list)
>           raise TypeError(
                f"{message_name} must be an instance of {type_name}, "
                f"got {type(instance)} instead.")
E           TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.

XBrainLab/backend/utils/check.py:31: TypeError
_______________________________ test_export[raw] _______________________________

target_str = 'raw', request = <FixtureRequest for <Function test_export[raw]>>

    @pytest.mark.parametrize('target_str', ['raw', 'epoch'])
    def test_export(target_str, request):
        from unittest.mock import patch
    
        target = request.getfixturevalue(target_str)
        # to ensure history is not empty
        processor2 = preprocessor.ChannelSelection([target])
>       processor2.data_preprocess(['Fp1', 'Fp2'])

XBrainLab/tests/backend/preprocessor/test_preprocess.py:124: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/preprocessor/base.py:41: in data_preprocess
    self._data_preprocess(preprocessed_data, *args, **kargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.preprocessor.channel_selection.ChannelSelection object at 0x7ab1ebdada90>
preprocessed_data = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ebdad0d0>
selected_channels = ['Fp1', 'Fp2']

    def _data_preprocess(self, preprocessed_data: Raw, selected_channels: List[str]):
        # Check if channel is selected
        if len(selected_channels) == 0:
            raise ValueError("No Channel is Selected")
>       preprocessed_data.get_mne().pick_channels(selected_channels)
E       AttributeError: 'MockBaseRaw' object has no attribute 'pick_channels'

XBrainLab/backend/preprocessor/channel_selection.py:21: AttributeError
______________________________ test_export[epoch] ______________________________

target_str = 'epoch'
request = <FixtureRequest for <Function test_export[epoch]>>

    @pytest.mark.parametrize('target_str', ['raw', 'epoch'])
    def test_export(target_str, request):
        from unittest.mock import patch
    
>       target = request.getfixturevalue(target_str)

XBrainLab/tests/backend/preprocessor/test_preprocess.py:121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:549: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:640: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:1128: in execute
    result = ihook.pytest_fixture_setup(fixturedef=self, request=request)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:1196: in pytest_fixture_setup
    result = call_fixture_func(fixturefunc, request, kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:930: in call_fixture_func
    fixture_result = fixturefunc(**kwargs)
XBrainLab/tests/backend/preprocessor/test_preprocess.py:30: in epoch
    return Raw(path, mne_epoch)
XBrainLab/backend/load_data/raw.py:43: in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = <MagicMock name='mock.Epochs()' id='134904589852928'>
type_class = (<class 'conftest.MockBaseRaw'>, <class 'conftest.MockBaseEpochs'>)
message_name = 'mne_data'

    def validate_type(instance: object,
                      type_class: type | tuple[type],
                      message_name: str) -> None:
        """Validate the type of an instance.
    
        Args:
            instance: The instance to be validated.
            type_class: Acceptable type(s) of the instance.
                        Can be a single type or a tuple of types.
            message_name: The name of the instance to be displayed in the error message.
    
        Raises:
            TypeError: If the instance is not an instance of the acceptable type(s).
        """
        if not isinstance(type_class, (list, tuple)):
            type_class = (type_class, )
        if not isinstance(instance, type_class):
            if len(type_class) == 1:
                type_class = type_class[0]
                type_name = _get_type_name(type_class)
            else:
                type_name_list = [_get_type_name(c) for c in type_class]
                type_name = ' or '.join(type_name_list)
>           raise TypeError(
                f"{message_name} must be an instance of {type_name}, "
                f"got {type(instance)} instead.")
E           TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.

XBrainLab/backend/utils/check.py:31: TypeError
_____________________________ test_filtering[raw] ______________________________

target_str = 'raw'
request = <FixtureRequest for <Function test_filtering[raw]>>

    @pytest.mark.parametrize('target_str', ['raw', 'epoch'])
    def test_filtering(target_str, request):
        target = request.getfixturevalue(target_str)
        processor = preprocessor.Filtering([target])
        fs = 100
>       processor.data_preprocess(1, fs)

XBrainLab/tests/backend/preprocessor/test_preprocess.py:144: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/preprocessor/base.py:41: in data_preprocess
    self._data_preprocess(preprocessed_data, *args, **kargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.preprocessor.filtering.Filtering object at 0x7ab1ebd66ac0>
preprocessed_data = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ebd66730>
l_freq = 1, h_freq = 100, notch_freqs = None

    def _data_preprocess(self, preprocessed_data: Raw, l_freq: float, h_freq: float, notch_freqs=None):
>       preprocessed_data.get_mne().load_data()
E       AttributeError: 'MockBaseRaw' object has no attribute 'load_data'

XBrainLab/backend/preprocessor/filtering.py:24: AttributeError
____________________________ test_filtering[epoch] _____________________________

target_str = 'epoch'
request = <FixtureRequest for <Function test_filtering[epoch]>>

    @pytest.mark.parametrize('target_str', ['raw', 'epoch'])
    def test_filtering(target_str, request):
>       target = request.getfixturevalue(target_str)

XBrainLab/tests/backend/preprocessor/test_preprocess.py:141: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:549: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:640: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:1128: in execute
    result = ihook.pytest_fixture_setup(fixturedef=self, request=request)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:1196: in pytest_fixture_setup
    result = call_fixture_func(fixturefunc, request, kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:930: in call_fixture_func
    fixture_result = fixturefunc(**kwargs)
XBrainLab/tests/backend/preprocessor/test_preprocess.py:30: in epoch
    return Raw(path, mne_epoch)
XBrainLab/backend/load_data/raw.py:43: in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = <MagicMock name='mock.Epochs()' id='134904589852928'>
type_class = (<class 'conftest.MockBaseRaw'>, <class 'conftest.MockBaseEpochs'>)
message_name = 'mne_data'

    def validate_type(instance: object,
                      type_class: type | tuple[type],
                      message_name: str) -> None:
        """Validate the type of an instance.
    
        Args:
            instance: The instance to be validated.
            type_class: Acceptable type(s) of the instance.
                        Can be a single type or a tuple of types.
            message_name: The name of the instance to be displayed in the error message.
    
        Raises:
            TypeError: If the instance is not an instance of the acceptable type(s).
        """
        if not isinstance(type_class, (list, tuple)):
            type_class = (type_class, )
        if not isinstance(instance, type_class):
            if len(type_class) == 1:
                type_class = type_class[0]
                type_name = _get_type_name(type_class)
            else:
                type_name_list = [_get_type_name(c) for c in type_class]
                type_name = ' or '.join(type_name_list)
>           raise TypeError(
                f"{message_name} must be an instance of {type_name}, "
                f"got {type(instance)} instead.")
E           TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.

XBrainLab/backend/utils/check.py:31: TypeError
______________________________ test_resample[raw] ______________________________

target_str = 'raw', request = <FixtureRequest for <Function test_resample[raw]>>

    @pytest.mark.parametrize('target_str', ['raw', 'epoch'])
    def test_resample(target_str, request):
        target = request.getfixturevalue(target_str)
        processor = preprocessor.Resample([target])
        fs = 50
>       processor.data_preprocess(fs)

XBrainLab/tests/backend/preprocessor/test_preprocess.py:156: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/preprocessor/base.py:41: in data_preprocess
    self._data_preprocess(preprocessed_data, *args, **kargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.preprocessor.resample.Resample object at 0x7ab1ec2d1dc0>
preprocessed_data = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ec0d1e80>
sfreq = 50

    def _data_preprocess(self, preprocessed_data: Raw, sfreq: float):
>       preprocessed_data.get_mne().load_data()
E       AttributeError: 'MockBaseRaw' object has no attribute 'load_data'

XBrainLab/backend/preprocessor/resample.py:17: AttributeError
_____________________________ test_resample[epoch] _____________________________

target_str = 'epoch'
request = <FixtureRequest for <Function test_resample[epoch]>>

    @pytest.mark.parametrize('target_str', ['raw', 'epoch'])
    def test_resample(target_str, request):
>       target = request.getfixturevalue(target_str)

XBrainLab/tests/backend/preprocessor/test_preprocess.py:153: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:549: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:640: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:1128: in execute
    result = ihook.pytest_fixture_setup(fixturedef=self, request=request)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:1196: in pytest_fixture_setup
    result = call_fixture_func(fixturefunc, request, kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:930: in call_fixture_func
    fixture_result = fixturefunc(**kwargs)
XBrainLab/tests/backend/preprocessor/test_preprocess.py:30: in epoch
    return Raw(path, mne_epoch)
XBrainLab/backend/load_data/raw.py:43: in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = <MagicMock name='mock.Epochs()' id='134904589852928'>
type_class = (<class 'conftest.MockBaseRaw'>, <class 'conftest.MockBaseEpochs'>)
message_name = 'mne_data'

    def validate_type(instance: object,
                      type_class: type | tuple[type],
                      message_name: str) -> None:
        """Validate the type of an instance.
    
        Args:
            instance: The instance to be validated.
            type_class: Acceptable type(s) of the instance.
                        Can be a single type or a tuple of types.
            message_name: The name of the instance to be displayed in the error message.
    
        Raises:
            TypeError: If the instance is not an instance of the acceptable type(s).
        """
        if not isinstance(type_class, (list, tuple)):
            type_class = (type_class, )
        if not isinstance(instance, type_class):
            if len(type_class) == 1:
                type_class = type_class[0]
                type_name = _get_type_name(type_class)
            else:
                type_name_list = [_get_type_name(c) for c in type_class]
                type_name = ' or '.join(type_name_list)
>           raise TypeError(
                f"{message_name} must be an instance of {type_name}, "
                f"got {type(instance)} instead.")
E           TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.

XBrainLab/backend/utils/check.py:31: TypeError
______________________ test_epoch_wrong_events[TimeEpoch] ______________________

method = <class 'XBrainLab.backend.preprocessor.time_epoch.TimeEpoch'>
raw = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ebef5b80>

    @pytest.mark.parametrize('method', [preprocessor.TimeEpoch, preprocessor.WindowEpoch])
    def test_epoch_wrong_events(method, raw): # noqa: F811
        with pytest.raises(ValueError, match="No event markers found.*"):
>           method([raw])
E           Failed: DID NOT RAISE <class 'ValueError'>

XBrainLab/tests/backend/preprocessor/test_preprocess.py:187: Failed
_____________________ test_epoch_wrong_events[WindowEpoch] _____________________

method = <class 'XBrainLab.backend.preprocessor.window_epoch.WindowEpoch'>
raw = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ebd66af0>

    @pytest.mark.parametrize('method', [preprocessor.TimeEpoch, preprocessor.WindowEpoch])
    def test_epoch_wrong_events(method, raw): # noqa: F811
        with pytest.raises(ValueError, match="No event markers found.*"):
>           method([raw])
E           Failed: DID NOT RAISE <class 'ValueError'>

XBrainLab/tests/backend/preprocessor/test_preprocess.py:187: Failed
_______________________ test_time_epoch_without_baseline _______________________

annotated_raw = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ec06dd90>

    def test_time_epoch_without_baseline(annotated_raw):
        processor = preprocessor.TimeEpoch([annotated_raw])
>       processor.data_preprocess(
            baseline=None, selected_event_names=['a', 'b', 'c', 'd'], tmin=0, tmax=1
        )

XBrainLab/tests/backend/preprocessor/test_preprocess.py:221: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/preprocessor/base.py:41: in data_preprocess
    self._data_preprocess(preprocessed_data, *args, **kargs)
XBrainLab/backend/preprocessor/time_epoch.py:84: in _data_preprocess
    preprocessed_data.set_mne(data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ec06db50>
data = <MagicMock name='mock.Epochs()' id='134904589852928'>

    def set_mne(self, data: mne.io.BaseRaw | mne.BaseEpochs) -> None:
        """Set new mne data.
    
        Args:
            data: New mne data.
        """
        # set loaded event to new data
        if (
>           isinstance(data, mne.epochs.BaseEpochs) and
            self.raw_event_id
        ):
E       TypeError: isinstance() arg 2 must be a type or tuple of types

XBrainLab/backend/load_data/raw.py:133: TypeError
________________________ test_time_epoch_with_baseline _________________________

annotated_raw = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ec215b50>

    def test_time_epoch_with_baseline(annotated_raw):
        processor = preprocessor.TimeEpoch([annotated_raw])
>       processor.data_preprocess(
            baseline=(-1, 0),
            selected_event_names=['a', 'b', 'c', 'd'],
            tmin=0, tmax=1
        )

XBrainLab/tests/backend/preprocessor/test_preprocess.py:239: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/preprocessor/base.py:41: in data_preprocess
    self._data_preprocess(preprocessed_data, *args, **kargs)
XBrainLab/backend/preprocessor/time_epoch.py:84: in _data_preprocess
    preprocessed_data.set_mne(data)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ec03f250>
data = <MagicMock name='mock.Epochs()' id='134904589852928'>

    def set_mne(self, data: mne.io.BaseRaw | mne.BaseEpochs) -> None:
        """Set new mne data.
    
        Args:
            data: New mne data.
        """
        # set loaded event to new data
        if (
>           isinstance(data, mne.epochs.BaseEpochs) and
            self.raw_event_id
        ):
E       TypeError: isinstance() arg 2 must be a type or tuple of types

XBrainLab/backend/load_data/raw.py:133: TypeError
______________________________ test_window_epoch _______________________________

annotated_raw = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ec0e2550>

    def test_window_epoch(annotated_raw):
        events = np.array([[0, 0, 1]])
        event_id = {'a': 1}
        annotated_raw.set_event(events, event_id)
        processor = preprocessor.WindowEpoch([annotated_raw])
        processor.data_preprocess(duration=2, overlap=1)
        result = processor.get_preprocessed_data_list()[0]
        assert result.get_event_name_list_str() == 'a'
>       assert result.get_mne().get_data().shape == (9, 2, 2)
E       AssertionError: assert <MagicMock na...904586287808'> == (9, 2, 2)
E         
E         Full diff:
E         + <MagicMock name='mock.make_fixed_length_epochs().get_data().shape' id='134904586287808'>
E         - (
E         -     9,
E         -     2,
E         -     2,
E         - )

XBrainLab/tests/backend/preprocessor/test_preprocess.py:265: AssertionError
_______________________ test_normalization_z_score[raw] ________________________

target_str = 'raw'
request = <FixtureRequest for <Function test_normalization_z_score[raw]>>

    @pytest.mark.parametrize('target_str', ['raw', 'epoch'])
    def test_normalization_z_score(target_str, request):
        target = request.getfixturevalue(target_str)
        processor = preprocessor.Normalize([target])
>       processor.data_preprocess('z score')

XBrainLab/tests/backend/preprocessor/test_preprocess.py:284: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/preprocessor/base.py:41: in data_preprocess
    self._data_preprocess(preprocessed_data, *args, **kargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.preprocessor.normalize.Normalize object at 0x7ab1ec0ce310>
preprocessed_data = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ec0f96a0>
norm = 'z score'

    def _data_preprocess(self, preprocessed_data, norm: str):
>       preprocessed_data.get_mne().load_data()
E       AttributeError: 'MockBaseRaw' object has no attribute 'load_data'

XBrainLab/backend/preprocessor/normalize.py:17: AttributeError
______________________ test_normalization_z_score[epoch] _______________________

target_str = 'epoch'
request = <FixtureRequest for <Function test_normalization_z_score[epoch]>>

    @pytest.mark.parametrize('target_str', ['raw', 'epoch'])
    def test_normalization_z_score(target_str, request):
>       target = request.getfixturevalue(target_str)

XBrainLab/tests/backend/preprocessor/test_preprocess.py:282: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:549: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:640: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:1128: in execute
    result = ihook.pytest_fixture_setup(fixturedef=self, request=request)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:1196: in pytest_fixture_setup
    result = call_fixture_func(fixturefunc, request, kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:930: in call_fixture_func
    fixture_result = fixturefunc(**kwargs)
XBrainLab/tests/backend/preprocessor/test_preprocess.py:30: in epoch
    return Raw(path, mne_epoch)
XBrainLab/backend/load_data/raw.py:43: in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = <MagicMock name='mock.Epochs()' id='134904589852928'>
type_class = (<class 'conftest.MockBaseRaw'>, <class 'conftest.MockBaseEpochs'>)
message_name = 'mne_data'

    def validate_type(instance: object,
                      type_class: type | tuple[type],
                      message_name: str) -> None:
        """Validate the type of an instance.
    
        Args:
            instance: The instance to be validated.
            type_class: Acceptable type(s) of the instance.
                        Can be a single type or a tuple of types.
            message_name: The name of the instance to be displayed in the error message.
    
        Raises:
            TypeError: If the instance is not an instance of the acceptable type(s).
        """
        if not isinstance(type_class, (list, tuple)):
            type_class = (type_class, )
        if not isinstance(instance, type_class):
            if len(type_class) == 1:
                type_class = type_class[0]
                type_name = _get_type_name(type_class)
            else:
                type_name_list = [_get_type_name(c) for c in type_class]
                type_name = ' or '.join(type_name_list)
>           raise TypeError(
                f"{message_name} must be an instance of {type_name}, "
                f"got {type(instance)} instead.")
E           TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.

XBrainLab/backend/utils/check.py:31: TypeError
________________________ test_normalization_minmax[raw] ________________________

target_str = 'raw'
request = <FixtureRequest for <Function test_normalization_minmax[raw]>>

    @pytest.mark.parametrize('target_str', ['raw', 'epoch'])
    def test_normalization_minmax(target_str, request):
        target = request.getfixturevalue(target_str)
        processor = preprocessor.Normalize([target])
>       processor.data_preprocess('minmax')

XBrainLab/tests/backend/preprocessor/test_preprocess.py:304: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/preprocessor/base.py:41: in data_preprocess
    self._data_preprocess(preprocessed_data, *args, **kargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.preprocessor.normalize.Normalize object at 0x7ab1f8f20130>
preprocessed_data = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ebddb700>
norm = 'minmax'

    def _data_preprocess(self, preprocessed_data, norm: str):
>       preprocessed_data.get_mne().load_data()
E       AttributeError: 'MockBaseRaw' object has no attribute 'load_data'

XBrainLab/backend/preprocessor/normalize.py:17: AttributeError
_______________________ test_normalization_minmax[epoch] _______________________

target_str = 'epoch'
request = <FixtureRequest for <Function test_normalization_minmax[epoch]>>

    @pytest.mark.parametrize('target_str', ['raw', 'epoch'])
    def test_normalization_minmax(target_str, request):
>       target = request.getfixturevalue(target_str)

XBrainLab/tests/backend/preprocessor/test_preprocess.py:302: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:549: in getfixturevalue
    fixturedef = self._get_active_fixturedef(argname)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:640: in _get_active_fixturedef
    fixturedef.execute(request=subrequest)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:1128: in execute
    result = ihook.pytest_fixture_setup(fixturedef=self, request=request)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/pluggy/_hooks.py:512: in __call__
    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/pluggy/_manager.py:120: in _hookexec
    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/setuponly.py:36: in pytest_fixture_setup
    return (yield)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:1196: in pytest_fixture_setup
    result = call_fixture_func(fixturefunc, request, kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/site-packages/_pytest/fixtures.py:930: in call_fixture_func
    fixture_result = fixturefunc(**kwargs)
XBrainLab/tests/backend/preprocessor/test_preprocess.py:30: in epoch
    return Raw(path, mne_epoch)
XBrainLab/backend/load_data/raw.py:43: in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

instance = <MagicMock name='mock.Epochs()' id='134904589852928'>
type_class = (<class 'conftest.MockBaseRaw'>, <class 'conftest.MockBaseEpochs'>)
message_name = 'mne_data'

    def validate_type(instance: object,
                      type_class: type | tuple[type],
                      message_name: str) -> None:
        """Validate the type of an instance.
    
        Args:
            instance: The instance to be validated.
            type_class: Acceptable type(s) of the instance.
                        Can be a single type or a tuple of types.
            message_name: The name of the instance to be displayed in the error message.
    
        Raises:
            TypeError: If the instance is not an instance of the acceptable type(s).
        """
        if not isinstance(type_class, (list, tuple)):
            type_class = (type_class, )
        if not isinstance(instance, type_class):
            if len(type_class) == 1:
                type_class = type_class[0]
                type_name = _get_type_name(type_class)
            else:
                type_name_list = [_get_type_name(c) for c in type_class]
                type_name = ' or '.join(type_name_list)
>           raise TypeError(
                f"{message_name} must be an instance of {type_name}, "
                f"got {type(instance)} instead.")
E           TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.

XBrainLab/backend/utils/check.py:31: TypeError
___________________________ test_rereference_average ___________________________

mock_raw_data = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1f8eba520>

    def test_rereference_average(mock_raw_data):
        proc = Rereference([mock_raw_data])
    
        # Apply average reference
>       proc.data_preprocess(ref_channels='average')

XBrainLab/tests/backend/preprocessor/test_rereference.py:19: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/preprocessor/base.py:41: in data_preprocess
    self._data_preprocess(preprocessed_data, *args, **kargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.preprocessor.rereference.Rereference object at 0x7ab1f8eba5b0>
preprocessed_data = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1f8f20130>
ref_channels = 'average'

    def _data_preprocess(self, preprocessed_data: Raw, ref_channels):
>       preprocessed_data.get_mne().load_data()
E       AttributeError: 'MockBaseRaw' object has no attribute 'load_data'

XBrainLab/backend/preprocessor/rereference.py:20: AttributeError
______________________ test_rereference_specific_channel _______________________

mock_raw_data = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ebe34850>

    def test_rereference_specific_channel(mock_raw_data):
        proc = Rereference([mock_raw_data])
    
        # Use Cz (index 1) as reference
>       proc.data_preprocess(ref_channels=['Cz'])

XBrainLab/tests/backend/preprocessor/test_rereference.py:34: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/preprocessor/base.py:41: in data_preprocess
    self._data_preprocess(preprocessed_data, *args, **kargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.preprocessor.rereference.Rereference object at 0x7ab1ebe348b0>
preprocessed_data = <XBrainLab.backend.load_data.raw.Raw object at 0x7ab1ebe34310>
ref_channels = ['Cz']

    def _data_preprocess(self, preprocessed_data: Raw, ref_channels):
>       preprocessed_data.get_mne().load_data()
E       AttributeError: 'MockBaseRaw' object has no attribute 'load_data'

XBrainLab/backend/preprocessor/rereference.py:20: AttributeError
____________________ TestResample.test_resample_downsample _____________________

self = <preprocessor.test_resample.TestResample object at 0x7ab1f8edc9a0>
mock_raw = (<MagicMock spec='Raw' id='134904585866064'>, array([[1000,    0,    1],
       [5000,    0,    2]]), {'Event1': 1, 'Event2': 2})

    def test_resample_downsample(self, mock_raw):
        raw, events, event_id = mock_raw
        resample = Resample([raw])
        target_sfreq = 100.0 # Downsample by 10x
    
>       resample._data_preprocess(raw, sfreq=target_sfreq)

XBrainLab/tests/backend/preprocessor/test_resample.py:48: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.preprocessor.resample.Resample object at 0x7ab1ec2b4610>
preprocessed_data = <MagicMock spec='Raw' id='134904585866064'>, sfreq = 100.0

    def _data_preprocess(self, preprocessed_data: Raw, sfreq: float):
>       preprocessed_data.get_mne().load_data()
E       AttributeError: 'MockBaseRaw' object has no attribute 'load_data'

XBrainLab/backend/preprocessor/resample.py:17: AttributeError
_____________________ TestResample.test_resample_upsample ______________________

self = <preprocessor.test_resample.TestResample object at 0x7ab1f8edcb20>
mock_raw = (<MagicMock spec='Raw' id='134904586142480'>, array([[1000,    0,    1],
       [5000,    0,    2]]), {'Event1': 1, 'Event2': 2})

    def test_resample_upsample(self, mock_raw):
        raw, events, event_id = mock_raw
        resample = Resample([raw])
        target_sfreq = 2000.0 # Upsample by 2x
    
>       resample._data_preprocess(raw, sfreq=target_sfreq)

XBrainLab/tests/backend/preprocessor/test_resample.py:70: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.preprocessor.resample.Resample object at 0x7ab1ebe81fd0>
preprocessed_data = <MagicMock spec='Raw' id='134904586142480'>, sfreq = 2000.0

    def _data_preprocess(self, preprocessed_data: Raw, sfreq: float):
>       preprocessed_data.get_mne().load_data()
E       AttributeError: 'MockBaseRaw' object has no attribute 'load_data'

XBrainLab/backend/preprocessor/resample.py:17: AttributeError
_____________________ TestResample.test_resample_no_events _____________________

self = <preprocessor.test_resample.TestResample object at 0x7ab1f8edcd00>
mock_raw = (<MagicMock spec='Raw' id='134904587630000'>, array([[1000,    0,    1],
       [5000,    0,    2]]), {'Event1': 1, 'Event2': 2})

    def test_resample_no_events(self, mock_raw):
        raw, _, _ = mock_raw
        # Mock no events
        raw.get_event_list.return_value = (np.array([]), {})
    
        resample = Resample([raw])
>       resample._data_preprocess(raw, sfreq=100.0)

XBrainLab/tests/backend/preprocessor/test_resample.py:90: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.preprocessor.resample.Resample object at 0x7ab1ebdc0520>
preprocessed_data = <MagicMock spec='Raw' id='134904587630000'>, sfreq = 100.0

    def _data_preprocess(self, preprocessed_data: Raw, sfreq: float):
>       preprocessed_data.get_mne().load_data()
E       AttributeError: 'MockBaseRaw' object has no attribute 'load_data'

XBrainLab/backend/preprocessor/resample.py:17: AttributeError
____________________ TestTimeEpoch.test_time_epoch_success _____________________

self = <preprocessor.test_time_epoch.TestTimeEpoch object at 0x7ab1f8ee4370>
mock_raw = (<MagicMock spec='Raw' id='134904585348384'>, array([[1000,    0,    1],
       [5000,    0,    2]]), {'Event1': 1, 'Event2': 2})

    def test_time_epoch_success(self, mock_raw):
        raw, events, event_id = mock_raw
        time_epoch = TimeEpoch([raw])
    
        # Select Event1
        time_epoch._data_preprocess(
            raw,
            selected_event_names=['Event1'],
            tmin=-0.1,
            tmax=0.5,
            baseline=None
        )
    
        # Verify set_mne was called with Epochs
        args, _ = raw.set_mne.call_args
        new_mne = args[0]
>       assert isinstance(new_mne, mne.Epochs)
E       TypeError: isinstance() arg 2 must be a type or tuple of types

XBrainLab/tests/backend/preprocessor/test_time_epoch.py:56: TypeError
________________ TestTimeEpoch.test_time_epoch_duplicate_events ________________

self = <preprocessor.test_time_epoch.TestTimeEpoch object at 0x7ab1f8ee4700>
mock_raw = (<MagicMock spec='Raw' id='134904584698128'>, array([[1000,    0,    1],
       [5000,    0,    2]]), {'Event1': 1, 'Event2': 2})

    def test_time_epoch_duplicate_events(self, mock_raw):
        raw, _, event_id = mock_raw
    
        # Create duplicate events at same sample
        events = np.array([[1000, 0, 1], [1000, 0, 1]])
        raw.get_event_list.return_value = (events, event_id)
    
        time_epoch = TimeEpoch([raw])
    
        # Should not raise error due to event_repeated='drop'
        time_epoch._data_preprocess(
            raw,
            selected_event_names=['Event1'],
            tmin=-0.1,
            tmax=0.5,
            baseline=None
        )
    
        args, _ = raw.set_mne.call_args
        new_mne = args[0]
>       assert len(new_mne) == 1 # Duplicate dropped
E       AssertionError: assert 0 == 1
E        +  where 0 = len(<MagicMock name='mock.Epochs()' id='134904589852928'>)

XBrainLab/tests/backend/preprocessor/test_time_epoch.py:94: AssertionError
___________________________ test_train_record_getter ___________________________

export_mocker = (<MagicMock name='save' id='134904586468368'>, <MagicMock name='makedirs' id='134904587811664'>)
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebd4fa30>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebd4fd90>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebd4f640>

    def test_train_record_getter(
        export_mocker, dataset, training_option, model_holder # noqa: F811
    ):
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:40: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_________________________ test_train_record_create_dir _________________________

cleanup = None
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebd97820>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebd97880>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebd97be0>

    def test_train_record_create_dir(
        cleanup,
        dataset, training_option, model_holder # noqa: F811
    ):
        repeat = 0
        seed = set_seed(0)
>       model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:71: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_________________________ test_train_record_backup_dir _________________________

cleanup = None
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebeb0f40>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebeb0ee0>
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebeb0d60>

    def test_train_record_backup_dir(
        cleanup,
        dataset, training_option, model_holder # noqa: F811
    ):
        from unittest.mock import patch
        mkdir = os.makedirs
        with patch('shutil.move') as move_mock, \
             patch('os.makedirs') as make_dir_mock:
    
            repeat = 0
            seed = set_seed(0)
>           model = model_holder.get_model({})

XBrainLab/tests/backend/training/record/test_train.py:89: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/model_holder.py:37: in get_model
    model = self.target_model(**self.model_params_map, **args)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803737408'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e96d60>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
__________________________ test_option[kwargs8-False] __________________________

kwargs = {'gpu_idx': None, 'use_cpu': True}, has_error = False

    @pytest.mark.parametrize("kwargs, has_error", [
        ({'output_dir': None}, True),
        ({'optim': None}, True),
        ({'optim_params': None}, True),
    
        ({'use_cpu': None, 'gpu_idx': None}, True),
        ({'use_cpu': None, 'gpu_idx': 1}, True),
        ({'use_cpu': False, 'gpu_idx': None}, True),
        ({'use_cpu': False, 'gpu_idx': 1}, False),
        ({'use_cpu': False, 'gpu_idx': 'cuda:0'}, True),
        ({'use_cpu': True, 'gpu_idx': None}, False),
        ({'use_cpu': True, 'gpu_idx': 1}, False),
    
        ({'epoch': 10.5}, False),
        ({'epoch': 10}, False),
        ({'epoch': -5}, False),
        ({'epoch': "error"}, True),
        ({'epoch': None}, True),
        ({'bs': None}, True),
        ({'bs': "error"}, True),
        ({'lr': None}, True),
        ({'lr': "error"}, True),
        ({'checkpoint_epoch': None}, True),
        ({'checkpoint_epoch': 0}, False),
        ({'checkpoint_epoch': "error"}, True),
        ({'evaluation_option': None}, True),
        ({'repeat_num': None}, True),
        ({'repeat_num': "error"}, True),
    ])
    def test_option(kwargs, has_error):
        from unittest.mock import patch
        args = {
            'output_dir': 'ok',
            'optim': FakeOptim,
            'optim_params': {'a': 1, 'b': 2},
            'use_cpu': False,
            'gpu_idx': 0,
            'epoch': 10,
            'bs': 20,
            'lr': 0.01,
            'checkpoint_epoch': 10,
            'evaluation_option': TRAINING_EVALUATION.VAL_LOSS,
            'repeat_num': 5
        }
    
        for k in kwargs:
            args[k] = kwargs[k]
    
        with patch('torch.cuda.is_available', return_value=True), \
             patch('torch.cuda.device_count', return_value=2), \
             patch('torch.cuda.get_device_name', return_value='test_gpu'):
    
            if has_error:
                with pytest.raises(ValueError):
                    option = TrainingOption(**args)
                return
    
            option = TrainingOption(**args)
    
    
            assert option.get_output_dir() == 'ok'
            assert option.get_evaluation_option_repr() == "TRAINING_EVALUATION.VAL_LOSS"
            if args['use_cpu'] or (not args['use_cpu'] and torch.cuda.is_available()):
                assert option.get_device_name() == parse_device_name(
                    args['use_cpu'], args['gpu_idx']
                )
            if args['use_cpu']:
                assert option.get_device() == "cpu"
            else:
                assert option.get_device() == "cuda:" + str(args['gpu_idx'])
    
            assert option.get_optim_name() == "FakeOptim"
            assert option.get_optim_desc_str() == parse_optim_name(
                FakeOptim, args["optim_params"]
            )
    
>           model = FakeModel()

XBrainLab/tests/backend/training/test_option.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803528320'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e54d90>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
__________________________ test_option[kwargs9-False] __________________________

kwargs = {'gpu_idx': 1, 'use_cpu': True}, has_error = False

    @pytest.mark.parametrize("kwargs, has_error", [
        ({'output_dir': None}, True),
        ({'optim': None}, True),
        ({'optim_params': None}, True),
    
        ({'use_cpu': None, 'gpu_idx': None}, True),
        ({'use_cpu': None, 'gpu_idx': 1}, True),
        ({'use_cpu': False, 'gpu_idx': None}, True),
        ({'use_cpu': False, 'gpu_idx': 1}, False),
        ({'use_cpu': False, 'gpu_idx': 'cuda:0'}, True),
        ({'use_cpu': True, 'gpu_idx': None}, False),
        ({'use_cpu': True, 'gpu_idx': 1}, False),
    
        ({'epoch': 10.5}, False),
        ({'epoch': 10}, False),
        ({'epoch': -5}, False),
        ({'epoch': "error"}, True),
        ({'epoch': None}, True),
        ({'bs': None}, True),
        ({'bs': "error"}, True),
        ({'lr': None}, True),
        ({'lr': "error"}, True),
        ({'checkpoint_epoch': None}, True),
        ({'checkpoint_epoch': 0}, False),
        ({'checkpoint_epoch': "error"}, True),
        ({'evaluation_option': None}, True),
        ({'repeat_num': None}, True),
        ({'repeat_num': "error"}, True),
    ])
    def test_option(kwargs, has_error):
        from unittest.mock import patch
        args = {
            'output_dir': 'ok',
            'optim': FakeOptim,
            'optim_params': {'a': 1, 'b': 2},
            'use_cpu': False,
            'gpu_idx': 0,
            'epoch': 10,
            'bs': 20,
            'lr': 0.01,
            'checkpoint_epoch': 10,
            'evaluation_option': TRAINING_EVALUATION.VAL_LOSS,
            'repeat_num': 5
        }
    
        for k in kwargs:
            args[k] = kwargs[k]
    
        with patch('torch.cuda.is_available', return_value=True), \
             patch('torch.cuda.device_count', return_value=2), \
             patch('torch.cuda.get_device_name', return_value='test_gpu'):
    
            if has_error:
                with pytest.raises(ValueError):
                    option = TrainingOption(**args)
                return
    
            option = TrainingOption(**args)
    
    
            assert option.get_output_dir() == 'ok'
            assert option.get_evaluation_option_repr() == "TRAINING_EVALUATION.VAL_LOSS"
            if args['use_cpu'] or (not args['use_cpu'] and torch.cuda.is_available()):
                assert option.get_device_name() == parse_device_name(
                    args['use_cpu'], args['gpu_idx']
                )
            if args['use_cpu']:
                assert option.get_device() == "cpu"
            else:
                assert option.get_device() == "cuda:" + str(args['gpu_idx'])
    
            assert option.get_optim_name() == "FakeOptim"
            assert option.get_optim_desc_str() == parse_optim_name(
                FakeOptim, args["optim_params"]
            )
    
>           model = FakeModel()

XBrainLab/tests/backend/training/test_option.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803528320'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e54d90>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_________________________ test_option[kwargs10-False] __________________________

kwargs = {'epoch': 10.5}, has_error = False

    @pytest.mark.parametrize("kwargs, has_error", [
        ({'output_dir': None}, True),
        ({'optim': None}, True),
        ({'optim_params': None}, True),
    
        ({'use_cpu': None, 'gpu_idx': None}, True),
        ({'use_cpu': None, 'gpu_idx': 1}, True),
        ({'use_cpu': False, 'gpu_idx': None}, True),
        ({'use_cpu': False, 'gpu_idx': 1}, False),
        ({'use_cpu': False, 'gpu_idx': 'cuda:0'}, True),
        ({'use_cpu': True, 'gpu_idx': None}, False),
        ({'use_cpu': True, 'gpu_idx': 1}, False),
    
        ({'epoch': 10.5}, False),
        ({'epoch': 10}, False),
        ({'epoch': -5}, False),
        ({'epoch': "error"}, True),
        ({'epoch': None}, True),
        ({'bs': None}, True),
        ({'bs': "error"}, True),
        ({'lr': None}, True),
        ({'lr': "error"}, True),
        ({'checkpoint_epoch': None}, True),
        ({'checkpoint_epoch': 0}, False),
        ({'checkpoint_epoch': "error"}, True),
        ({'evaluation_option': None}, True),
        ({'repeat_num': None}, True),
        ({'repeat_num': "error"}, True),
    ])
    def test_option(kwargs, has_error):
        from unittest.mock import patch
        args = {
            'output_dir': 'ok',
            'optim': FakeOptim,
            'optim_params': {'a': 1, 'b': 2},
            'use_cpu': False,
            'gpu_idx': 0,
            'epoch': 10,
            'bs': 20,
            'lr': 0.01,
            'checkpoint_epoch': 10,
            'evaluation_option': TRAINING_EVALUATION.VAL_LOSS,
            'repeat_num': 5
        }
    
        for k in kwargs:
            args[k] = kwargs[k]
    
        with patch('torch.cuda.is_available', return_value=True), \
             patch('torch.cuda.device_count', return_value=2), \
             patch('torch.cuda.get_device_name', return_value='test_gpu'):
    
            if has_error:
                with pytest.raises(ValueError):
                    option = TrainingOption(**args)
                return
    
            option = TrainingOption(**args)
    
    
            assert option.get_output_dir() == 'ok'
            assert option.get_evaluation_option_repr() == "TRAINING_EVALUATION.VAL_LOSS"
            if args['use_cpu'] or (not args['use_cpu'] and torch.cuda.is_available()):
                assert option.get_device_name() == parse_device_name(
                    args['use_cpu'], args['gpu_idx']
                )
            if args['use_cpu']:
                assert option.get_device() == "cpu"
            else:
                assert option.get_device() == "cuda:" + str(args['gpu_idx'])
    
            assert option.get_optim_name() == "FakeOptim"
            assert option.get_optim_desc_str() == parse_optim_name(
                FakeOptim, args["optim_params"]
            )
    
>           model = FakeModel()

XBrainLab/tests/backend/training/test_option.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803528320'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e54d90>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_________________________ test_option[kwargs11-False] __________________________

kwargs = {'epoch': 10}, has_error = False

    @pytest.mark.parametrize("kwargs, has_error", [
        ({'output_dir': None}, True),
        ({'optim': None}, True),
        ({'optim_params': None}, True),
    
        ({'use_cpu': None, 'gpu_idx': None}, True),
        ({'use_cpu': None, 'gpu_idx': 1}, True),
        ({'use_cpu': False, 'gpu_idx': None}, True),
        ({'use_cpu': False, 'gpu_idx': 1}, False),
        ({'use_cpu': False, 'gpu_idx': 'cuda:0'}, True),
        ({'use_cpu': True, 'gpu_idx': None}, False),
        ({'use_cpu': True, 'gpu_idx': 1}, False),
    
        ({'epoch': 10.5}, False),
        ({'epoch': 10}, False),
        ({'epoch': -5}, False),
        ({'epoch': "error"}, True),
        ({'epoch': None}, True),
        ({'bs': None}, True),
        ({'bs': "error"}, True),
        ({'lr': None}, True),
        ({'lr': "error"}, True),
        ({'checkpoint_epoch': None}, True),
        ({'checkpoint_epoch': 0}, False),
        ({'checkpoint_epoch': "error"}, True),
        ({'evaluation_option': None}, True),
        ({'repeat_num': None}, True),
        ({'repeat_num': "error"}, True),
    ])
    def test_option(kwargs, has_error):
        from unittest.mock import patch
        args = {
            'output_dir': 'ok',
            'optim': FakeOptim,
            'optim_params': {'a': 1, 'b': 2},
            'use_cpu': False,
            'gpu_idx': 0,
            'epoch': 10,
            'bs': 20,
            'lr': 0.01,
            'checkpoint_epoch': 10,
            'evaluation_option': TRAINING_EVALUATION.VAL_LOSS,
            'repeat_num': 5
        }
    
        for k in kwargs:
            args[k] = kwargs[k]
    
        with patch('torch.cuda.is_available', return_value=True), \
             patch('torch.cuda.device_count', return_value=2), \
             patch('torch.cuda.get_device_name', return_value='test_gpu'):
    
            if has_error:
                with pytest.raises(ValueError):
                    option = TrainingOption(**args)
                return
    
            option = TrainingOption(**args)
    
    
            assert option.get_output_dir() == 'ok'
            assert option.get_evaluation_option_repr() == "TRAINING_EVALUATION.VAL_LOSS"
            if args['use_cpu'] or (not args['use_cpu'] and torch.cuda.is_available()):
                assert option.get_device_name() == parse_device_name(
                    args['use_cpu'], args['gpu_idx']
                )
            if args['use_cpu']:
                assert option.get_device() == "cpu"
            else:
                assert option.get_device() == "cuda:" + str(args['gpu_idx'])
    
            assert option.get_optim_name() == "FakeOptim"
            assert option.get_optim_desc_str() == parse_optim_name(
                FakeOptim, args["optim_params"]
            )
    
>           model = FakeModel()

XBrainLab/tests/backend/training/test_option.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803528320'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e54d90>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_________________________ test_option[kwargs12-False] __________________________

kwargs = {'epoch': -5}, has_error = False

    @pytest.mark.parametrize("kwargs, has_error", [
        ({'output_dir': None}, True),
        ({'optim': None}, True),
        ({'optim_params': None}, True),
    
        ({'use_cpu': None, 'gpu_idx': None}, True),
        ({'use_cpu': None, 'gpu_idx': 1}, True),
        ({'use_cpu': False, 'gpu_idx': None}, True),
        ({'use_cpu': False, 'gpu_idx': 1}, False),
        ({'use_cpu': False, 'gpu_idx': 'cuda:0'}, True),
        ({'use_cpu': True, 'gpu_idx': None}, False),
        ({'use_cpu': True, 'gpu_idx': 1}, False),
    
        ({'epoch': 10.5}, False),
        ({'epoch': 10}, False),
        ({'epoch': -5}, False),
        ({'epoch': "error"}, True),
        ({'epoch': None}, True),
        ({'bs': None}, True),
        ({'bs': "error"}, True),
        ({'lr': None}, True),
        ({'lr': "error"}, True),
        ({'checkpoint_epoch': None}, True),
        ({'checkpoint_epoch': 0}, False),
        ({'checkpoint_epoch': "error"}, True),
        ({'evaluation_option': None}, True),
        ({'repeat_num': None}, True),
        ({'repeat_num': "error"}, True),
    ])
    def test_option(kwargs, has_error):
        from unittest.mock import patch
        args = {
            'output_dir': 'ok',
            'optim': FakeOptim,
            'optim_params': {'a': 1, 'b': 2},
            'use_cpu': False,
            'gpu_idx': 0,
            'epoch': 10,
            'bs': 20,
            'lr': 0.01,
            'checkpoint_epoch': 10,
            'evaluation_option': TRAINING_EVALUATION.VAL_LOSS,
            'repeat_num': 5
        }
    
        for k in kwargs:
            args[k] = kwargs[k]
    
        with patch('torch.cuda.is_available', return_value=True), \
             patch('torch.cuda.device_count', return_value=2), \
             patch('torch.cuda.get_device_name', return_value='test_gpu'):
    
            if has_error:
                with pytest.raises(ValueError):
                    option = TrainingOption(**args)
                return
    
            option = TrainingOption(**args)
    
    
            assert option.get_output_dir() == 'ok'
            assert option.get_evaluation_option_repr() == "TRAINING_EVALUATION.VAL_LOSS"
            if args['use_cpu'] or (not args['use_cpu'] and torch.cuda.is_available()):
                assert option.get_device_name() == parse_device_name(
                    args['use_cpu'], args['gpu_idx']
                )
            if args['use_cpu']:
                assert option.get_device() == "cpu"
            else:
                assert option.get_device() == "cuda:" + str(args['gpu_idx'])
    
            assert option.get_optim_name() == "FakeOptim"
            assert option.get_optim_desc_str() == parse_optim_name(
                FakeOptim, args["optim_params"]
            )
    
>           model = FakeModel()

XBrainLab/tests/backend/training/test_option.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803528320'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e54d90>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_________________________ test_option[kwargs20-False] __________________________

kwargs = {'checkpoint_epoch': 0}, has_error = False

    @pytest.mark.parametrize("kwargs, has_error", [
        ({'output_dir': None}, True),
        ({'optim': None}, True),
        ({'optim_params': None}, True),
    
        ({'use_cpu': None, 'gpu_idx': None}, True),
        ({'use_cpu': None, 'gpu_idx': 1}, True),
        ({'use_cpu': False, 'gpu_idx': None}, True),
        ({'use_cpu': False, 'gpu_idx': 1}, False),
        ({'use_cpu': False, 'gpu_idx': 'cuda:0'}, True),
        ({'use_cpu': True, 'gpu_idx': None}, False),
        ({'use_cpu': True, 'gpu_idx': 1}, False),
    
        ({'epoch': 10.5}, False),
        ({'epoch': 10}, False),
        ({'epoch': -5}, False),
        ({'epoch': "error"}, True),
        ({'epoch': None}, True),
        ({'bs': None}, True),
        ({'bs': "error"}, True),
        ({'lr': None}, True),
        ({'lr': "error"}, True),
        ({'checkpoint_epoch': None}, True),
        ({'checkpoint_epoch': 0}, False),
        ({'checkpoint_epoch': "error"}, True),
        ({'evaluation_option': None}, True),
        ({'repeat_num': None}, True),
        ({'repeat_num': "error"}, True),
    ])
    def test_option(kwargs, has_error):
        from unittest.mock import patch
        args = {
            'output_dir': 'ok',
            'optim': FakeOptim,
            'optim_params': {'a': 1, 'b': 2},
            'use_cpu': False,
            'gpu_idx': 0,
            'epoch': 10,
            'bs': 20,
            'lr': 0.01,
            'checkpoint_epoch': 10,
            'evaluation_option': TRAINING_EVALUATION.VAL_LOSS,
            'repeat_num': 5
        }
    
        for k in kwargs:
            args[k] = kwargs[k]
    
        with patch('torch.cuda.is_available', return_value=True), \
             patch('torch.cuda.device_count', return_value=2), \
             patch('torch.cuda.get_device_name', return_value='test_gpu'):
    
            if has_error:
                with pytest.raises(ValueError):
                    option = TrainingOption(**args)
                return
    
            option = TrainingOption(**args)
    
    
            assert option.get_output_dir() == 'ok'
            assert option.get_evaluation_option_repr() == "TRAINING_EVALUATION.VAL_LOSS"
            if args['use_cpu'] or (not args['use_cpu'] and torch.cuda.is_available()):
                assert option.get_device_name() == parse_device_name(
                    args['use_cpu'], args['gpu_idx']
                )
            if args['use_cpu']:
                assert option.get_device() == "cpu"
            else:
                assert option.get_device() == "cuda:" + str(args['gpu_idx'])
    
            assert option.get_optim_name() == "FakeOptim"
            assert option.get_optim_desc_str() == parse_optim_name(
                FakeOptim, args["optim_params"]
            )
    
>           model = FakeModel()

XBrainLab/tests/backend/training/test_option.py:122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1092: in __call__
    return self._mock_call(*args, **kwargs)
/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1096: in _mock_call
    return self._execute_mock_call(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock spec='str' id='134904803528320'>, args = (), kwargs = {}
effect = <tuple_iterator object at 0x7ab1f8e54d90>

    def _execute_mock_call(self, /, *args, **kwargs):
        # separate from _increment_mock_call so that awaited functions are
        # executed separately from their call, also AsyncMock overrides this method
    
        effect = self.side_effect
        if effect is not None:
            if _is_exception(effect):
                raise effect
            elif not _callable(effect):
>               result = next(effect)
E               StopIteration

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:1153: StopIteration
_________________________________ test_trainer _________________________________

training_plan_holders = [<training.test_trainer.FakeTrainingPlanHolder object at 0x7ab1ec065100>, <training.test_trainer.FakeTrainingPlanHolder object at 0x7ab1ec00a280>]

    def test_trainer(training_plan_holders):
        from unittest.mock import patch
        trainer = Trainer(training_plan_holders)
        assert trainer.get_training_plan_holders() == training_plan_holders
        assert trainer.get_progress_text() == 'Pending'
        holder = training_plan_holders[-1]
    
        with patch.object(holder, 'set_interrupt') as interrupt_mock, \
             patch.object(holder, 'clear_interrupt') as clear_interrupt_mock:
    
            def interrupt():
                assert trainer.get_progress_text() == 'Interrupting'
            interrupt_mock.side_effect = interrupt
    
            trainer.set_interrupt()
>           interrupt_mock.assert_called_once()

XBrainLab/tests/backend/training/test_trainer.py:43: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock name='set_interrupt' id='134904586671728'>

    def assert_called_once(self):
        """assert that the mock was called only once.
        """
        if not self.call_count == 1:
            msg = ("Expected '%s' to have been called once. Called %s times.%s"
                   % (self._mock_name or 'mock',
                      self.call_count,
                      self._calls_repr()))
>           raise AssertionError(msg)
E           AssertionError: Expected 'set_interrupt' to have been called once. Called 0 times.

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:886: AssertionError
______________________ test_trainer_get_plan[Fake-test-1] ______________________

training_plan_holders = [<training.test_trainer.FakeTrainingPlanHolder object at 0x7ab1ebf741f0>, <training.test_trainer.FakeTrainingPlanHolder object at 0x7ab1ebf74e80>]
plan_name = 'Fake', real_plan_name = 'test', error_stage = 1

    @pytest.mark.parametrize(
        'plan_name, real_plan_name, error_stage',
        [
            ['Fake', 'test', 1],
            ['Fake0', 'test', 0],
            ['Fake1', 'test', 0],
            ['Fake1', 'tests', 2]
        ]
    )
    def test_trainer_get_plan(
        training_plan_holders, plan_name, real_plan_name, error_stage
    ):
        trainer = Trainer(training_plan_holders)
        if error_stage == 0:
            trainer.get_real_training_plan(plan_name, real_plan_name)
        else:
            error = '.*training plan.*' if error_stage == 1 else '.*real plan.*'
            with pytest.raises(ValueError, match=error):
>               trainer.get_real_training_plan(plan_name, real_plan_name)
E               AttributeError: 'Trainer' object has no attribute 'get_real_training_plan'

XBrainLab/tests/backend/training/test_trainer.py:138: AttributeError
_____________________ test_trainer_get_plan[Fake0-test-0] ______________________

training_plan_holders = [<training.test_trainer.FakeTrainingPlanHolder object at 0x7ab1ebda55e0>, <training.test_trainer.FakeTrainingPlanHolder object at 0x7ab1ebda52b0>]
plan_name = 'Fake0', real_plan_name = 'test', error_stage = 0

    @pytest.mark.parametrize(
        'plan_name, real_plan_name, error_stage',
        [
            ['Fake', 'test', 1],
            ['Fake0', 'test', 0],
            ['Fake1', 'test', 0],
            ['Fake1', 'tests', 2]
        ]
    )
    def test_trainer_get_plan(
        training_plan_holders, plan_name, real_plan_name, error_stage
    ):
        trainer = Trainer(training_plan_holders)
        if error_stage == 0:
>           trainer.get_real_training_plan(plan_name, real_plan_name)
E           AttributeError: 'Trainer' object has no attribute 'get_real_training_plan'

XBrainLab/tests/backend/training/test_trainer.py:134: AttributeError
_____________________ test_trainer_get_plan[Fake1-test-0] ______________________

training_plan_holders = [<training.test_trainer.FakeTrainingPlanHolder object at 0x7ab1ebededc0>, <training.test_trainer.FakeTrainingPlanHolder object at 0x7ab1ebeded60>]
plan_name = 'Fake1', real_plan_name = 'test', error_stage = 0

    @pytest.mark.parametrize(
        'plan_name, real_plan_name, error_stage',
        [
            ['Fake', 'test', 1],
            ['Fake0', 'test', 0],
            ['Fake1', 'test', 0],
            ['Fake1', 'tests', 2]
        ]
    )
    def test_trainer_get_plan(
        training_plan_holders, plan_name, real_plan_name, error_stage
    ):
        trainer = Trainer(training_plan_holders)
        if error_stage == 0:
>           trainer.get_real_training_plan(plan_name, real_plan_name)
E           AttributeError: 'Trainer' object has no attribute 'get_real_training_plan'

XBrainLab/tests/backend/training/test_trainer.py:134: AttributeError
_____________________ test_trainer_get_plan[Fake1-tests-2] _____________________

training_plan_holders = [<training.test_trainer.FakeTrainingPlanHolder object at 0x7ab1ec04adf0>, <training.test_trainer.FakeTrainingPlanHolder object at 0x7ab1ec0d8b20>]
plan_name = 'Fake1', real_plan_name = 'tests', error_stage = 2

    @pytest.mark.parametrize(
        'plan_name, real_plan_name, error_stage',
        [
            ['Fake', 'test', 1],
            ['Fake0', 'test', 0],
            ['Fake1', 'test', 0],
            ['Fake1', 'tests', 2]
        ]
    )
    def test_trainer_get_plan(
        training_plan_holders, plan_name, real_plan_name, error_stage
    ):
        trainer = Trainer(training_plan_holders)
        if error_stage == 0:
            trainer.get_real_training_plan(plan_name, real_plan_name)
        else:
            error = '.*training plan.*' if error_stage == 1 else '.*real plan.*'
            with pytest.raises(ValueError, match=error):
>               trainer.get_real_training_plan(plan_name, real_plan_name)
E               AttributeError: 'Trainer' object has no attribute 'get_real_training_plan'

XBrainLab/tests/backend/training/test_trainer.py:138: AttributeError
__________________ test_training_plan_holder_check_data[None] __________________

export_mocker = (<MagicMock name='save' id='134904585196304'>, <MagicMock name='makedirs' id='134904586656688'>)
model_holder = <XBrainLab.backend.training.model_holder.ModelHolder object at 0x7ab1ebf63ee0>
dataset = <XBrainLab.backend.dataset.dataset.Dataset object at 0x7ab1ebf63bb0>
training_option = <XBrainLab.backend.training.option.TrainingOption object at 0x7ab1ebf63040>
test_arg = None

    @pytest.mark.parametrize("test_arg", [
        'model_holder', 'dataset', 'option', 'saliency_params', None
    ])
    def test_training_plan_holder_check_data(
        export_mocker, model_holder, dataset, training_option, test_arg
    ):
        args = {
            'model_holder': model_holder,
            'dataset': dataset,
            'option': training_option,
            'saliency_params': {}
        }
        if test_arg is None:
>           holder = TrainingPlanHolder(**args)

XBrainLab/tests/backend/training/test_training_plan.py:166: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:241: in __init__
    seed = set_seed(seed=None)
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
----------------------------- Captured stdout call -----------------------------
No saliency parameter is set, using default parameters.
___________________________ test_test_model_metrics ____________________________

    def test_test_model_metrics():
        from XBrainLab.backend.training.training_plan import _test_model
    
        # Setup
        model = FakeModel()
        criterion = torch.nn.CrossEntropyLoss()
    
        # Create dummy data
        # 2 batches, batch size 2
        # Batch 1:
        #   Input: random
        #   Labels: [0, 1]
        #   Preds: [[10, 0, 0, 0], [0, 10, 0, 0]] -> Argmax: [0, 1] (Correct)
        # Batch 2:
        #   Input: random
        #   Labels: [2, 3]
        #   Preds: [[0, 0, 10, 0], [0, 10, 0, 0]] -> Argmax: [2, 1] (1 Correct, 1 Wrong)
    
        # Total: 4 samples, 3 correct -> Acc = 75%
    
        class MockDataset(torch.utils.data.Dataset):
            def __len__(self):
                return 4
            def __getitem__(self, idx):
                return torch.randn(CLASS_NUM), torch.tensor(idx)
    
        # Mock model output
        # We need to mock the model call to return specific predictions
        # But FakeModel is simple linear. Let's just mock the forward pass or use specific weights.
        # Easier: Mock the model object itself to return specific outputs
    
        mock_model = torch.nn.Linear(4, 4) # Dummy
    
        # Batch 1 outputs (indices 0, 1) -> Labels 0, 1
        out1 = torch.tensor([[10.0, 0.0, 0.0, 0.0], [0.0, 10.0, 0.0, 0.0]])
        # Batch 2 outputs (indices 2, 3) -> Labels 2, 3
        out2 = torch.tensor([[0.0, 0.0, 10.0, 0.0], [0.0, 10.0, 0.0, 0.0]]) # Last one wrong (pred 1, label 3)
    
        from unittest.mock import Mock
        mock_model = Mock()
        mock_model.eval.return_value = None
        mock_model.side_effect = [out1, out2]
    
        # DataLoader
        # We need a dataloader that yields 2 batches
        # Inputs don't matter as we mock model output
        inputs = torch.randn(2, 4)
        labels1 = torch.tensor([0, 1])
        labels2 = torch.tensor([2, 3])
    
        loader = [(inputs, labels1), (inputs, labels2)]
    
        # Run
>       result = _test_model(mock_model, loader, criterion)

XBrainLab/tests/backend/training/test_training_plan.py:570: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

model = <Mock id='134904587773696'>
dataLoader = [(<MagicMock name='mock.randn()' id='134904587266080'>, <MagicMock name='mock.tensor()' id='134904583278704'>), (<MagicMock name='mock.randn()' id='134904587266080'>, <MagicMock name='mock.tensor()' id='134904583278704'>)]
criterion = <MagicMock name='mock.nn.CrossEntropyLoss()' id='134904586430832'>

    def _test_model(
        model: torch.nn.Module,
        dataLoader: Data.DataLoader,
        criterion: torch.nn.Module
    ) -> dict[str, float]:
        """Test model on given data loader
    
        Args:
            model: Model to be tested
            dataLoader: Data loader
            criterion: Loss function
    
        Returns:
            Dictionary of test result, including loss, accuracy and auc
        """
        model.eval()
    
        running_loss = 0.0
        total_count = 0
        auc = 0
        correct = 0
        y_true, y_pred = None, None
        with torch.no_grad():
            for inputs, labels in dataLoader:
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                running_loss += loss.item()
    
>               correct += (outputs.argmax(axis=1) == labels).float().sum().item()
E               AttributeError: 'bool' object has no attribute 'float'

XBrainLab/backend/training/training_plan.py:49: AttributeError
_____________________________ test_to_holder[True] _____________________________

shuffle = True

    @pytest.mark.parametrize('shuffle', [True, False])
    def test_to_holder(shuffle):
        device = 'cpu'
        length = 3000
        X = np.arange(length).reshape(-1, 1)
        y = np.arange(length)
    
        bs = 128
        dataloader = to_holder(X, y, device, bs, shuffle)
    
        # Perform assertions
>       assert isinstance(dataloader, DataLoader)
E       TypeError: isinstance() arg 2 must be a type or tuple of types

XBrainLab/tests/backend/training/test_training_plan_test_model.py:25: TypeError
____________________________ test_to_holder[False] _____________________________

shuffle = False

    @pytest.mark.parametrize('shuffle', [True, False])
    def test_to_holder(shuffle):
        device = 'cpu'
        length = 3000
        X = np.arange(length).reshape(-1, 1)
        y = np.arange(length)
    
        bs = 128
        dataloader = to_holder(X, y, device, bs, shuffle)
    
        # Perform assertions
>       assert isinstance(dataloader, DataLoader)
E       TypeError: isinstance() arg 2 must be a type or tuple of types

XBrainLab/tests/backend/training/test_training_plan_test_model.py:25: TypeError
_______________________________ test_eval_model ________________________________

dataloader = <MagicMock name='mock.utils.data.DataLoader()' id='134904582072832'>
y = array([1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3])
full_y = array([0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3])

    def test_eval_model(dataloader, y, full_y):
        from unittest.mock import patch
        model = FakeModel()
        model.eval()
    
        saliency_params = {
            'SmoothGrad': {'nt_samples': 1, 'stdevs': 0.1},
            'SmoothGrad_Squared': {'nt_samples': 1, 'stdevs': 0.1},
            'VarGrad': {'nt_samples': 1, 'stdevs': 0.1}
        }
    
        with patch('XBrainLab.backend.training.record.eval.EvalRecord.__init__', return_value=None) as eval_record_mock, \
             patch.object(model, 'eval') as eval_model_mock:
    
>           result = _eval_model(model, dataloader, saliency_params)

XBrainLab/tests/backend/training/test_training_plan_test_model.py:139: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/training/training_plan.py:131: in _eval_model
    label_list = np.concatenate(label_list)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

args = ([],), kwargs = {}, relevant_args = []

>   ???
E   ValueError: need at least one array to concatenate

<__array_function__ internals>:180: ValueError
________________________________ test_set_seed _________________________________

    def test_set_seed():
>       result = seed.set_seed()

XBrainLab/tests/backend/utils/test_seed.py:8: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/utils/seed.py:24: in set_seed
    rs = RandomState(MT19937(SeedSequence(seed)))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

>   ???
E   TypeError: SeedSequence expects int or sequence of ints for entropy not <MagicMock name='mock.seed()' id='134904586580464'>

bit_generator.pyx:299: TypeError
____________________________ test_get_random_state _____________________________

    def test_get_random_state():
        result = seed.get_random_state()
        tuple_length = 3
        assert isinstance(result, tuple)
        assert len(result) == tuple_length
>       assert isinstance(result[0], torch.ByteTensor)
E       TypeError: isinstance() arg 2 must be a type or tuple of types

XBrainLab/tests/backend/utils/test_seed.py:18: TypeError
___________ test_map[True-VisualizerType.SaliencyMap-epochs0-2-True] ___________

absolute = True
epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8dea220>
n_class = 1
visualizer = <XBrainLab.backend.visualization.saliency_map.SaliencyMapViz object at 0x7ab1eb2fd100>
mask_out = True

    @pytest.mark.parametrize("absolute", [True, False])
    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("visualizer", get_abs_visualizer())
    @pytest.mark.parametrize("mask_out", [True, False])
    def test_map(absolute, epochs, n_class, visualizer, mask_out):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 4)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
        assert visualizer.get_plt("Gradient", absolute) is not None
>       assert sum([len(i.images) for i in visualizer.fig.axes]) == n_class
E       assert 0 == 1
E        +  where 0 = sum([0])

XBrainLab/tests/backend/visualization/test_visualizer.py:86: AssertionError
__________ test_map[True-VisualizerType.SaliencyMap-epochs0-2-False] ___________

absolute = False
epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8dea220>
n_class = 1
visualizer = <XBrainLab.backend.visualization.saliency_map.SaliencyMapViz object at 0x7ab1daee98b0>
mask_out = True

    @pytest.mark.parametrize("absolute", [True, False])
    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("visualizer", get_abs_visualizer())
    @pytest.mark.parametrize("mask_out", [True, False])
    def test_map(absolute, epochs, n_class, visualizer, mask_out):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 4)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
        assert visualizer.get_plt("Gradient", absolute) is not None
>       assert sum([len(i.images) for i in visualizer.fig.axes]) == n_class
E       assert 0 == 1
E        +  where 0 = sum([0])

XBrainLab/tests/backend/visualization/test_visualizer.py:86: AssertionError
___________ test_map[True-VisualizerType.SaliencyMap-epochs1-3-True] ___________

absolute = True
epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8def1c0>
n_class = 2
visualizer = <XBrainLab.backend.visualization.saliency_map.SaliencyMapViz object at 0x7ab1daeaf4c0>
mask_out = True

    @pytest.mark.parametrize("absolute", [True, False])
    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("visualizer", get_abs_visualizer())
    @pytest.mark.parametrize("mask_out", [True, False])
    def test_map(absolute, epochs, n_class, visualizer, mask_out):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 4)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
        assert visualizer.get_plt("Gradient", absolute) is not None
>       assert sum([len(i.images) for i in visualizer.fig.axes]) == n_class
E       assert 0 == 2
E        +  where 0 = sum([0])

XBrainLab/tests/backend/visualization/test_visualizer.py:86: AssertionError
__________ test_map[True-VisualizerType.SaliencyMap-epochs1-3-False] ___________

absolute = False
epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8def1c0>
n_class = 2
visualizer = <XBrainLab.backend.visualization.saliency_map.SaliencyMapViz object at 0x7ab1daeafca0>
mask_out = True

    @pytest.mark.parametrize("absolute", [True, False])
    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("visualizer", get_abs_visualizer())
    @pytest.mark.parametrize("mask_out", [True, False])
    def test_map(absolute, epochs, n_class, visualizer, mask_out):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 4)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
        assert visualizer.get_plt("Gradient", absolute) is not None
>       assert sum([len(i.images) for i in visualizer.fig.axes]) == n_class
E       assert 0 == 2
E        +  where 0 = sum([0])

XBrainLab/tests/backend/visualization/test_visualizer.py:86: AssertionError
___________ test_map[True-VisualizerType.SaliencyMap-epochs2-4-True] ___________

absolute = True
epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8d74670>
n_class = 3
visualizer = <XBrainLab.backend.visualization.saliency_map.SaliencyMapViz object at 0x7ab1d8da15e0>
mask_out = True

    @pytest.mark.parametrize("absolute", [True, False])
    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("visualizer", get_abs_visualizer())
    @pytest.mark.parametrize("mask_out", [True, False])
    def test_map(absolute, epochs, n_class, visualizer, mask_out):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 4)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
        assert visualizer.get_plt("Gradient", absolute) is not None
>       assert sum([len(i.images) for i in visualizer.fig.axes]) == n_class
E       assert 0 == 3
E        +  where 0 = sum([0])

XBrainLab/tests/backend/visualization/test_visualizer.py:86: AssertionError
__________ test_map[True-VisualizerType.SaliencyMap-epochs2-4-False] ___________

absolute = False
epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8d74670>
n_class = 3
visualizer = <XBrainLab.backend.visualization.saliency_map.SaliencyMapViz object at 0x7ab1d8d1ad00>
mask_out = True

    @pytest.mark.parametrize("absolute", [True, False])
    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("visualizer", get_abs_visualizer())
    @pytest.mark.parametrize("mask_out", [True, False])
    def test_map(absolute, epochs, n_class, visualizer, mask_out):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 4)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
        assert visualizer.get_plt("Gradient", absolute) is not None
>       assert sum([len(i.images) for i in visualizer.fig.axes]) == n_class
E       assert 0 == 3
E        +  where 0 = sum([0])

XBrainLab/tests/backend/visualization/test_visualizer.py:86: AssertionError
_________ test_map[True-VisualizerType.SaliencyTopoMap-epochs0-2-True] _________

absolute = True
epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8dea220>
n_class = 1
visualizer = <XBrainLab.backend.visualization.saliency_topomap.SaliencyTopoMapViz object at 0x7ab1d8d260a0>
mask_out = True

    @pytest.mark.parametrize("absolute", [True, False])
    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("visualizer", get_abs_visualizer())
    @pytest.mark.parametrize("mask_out", [True, False])
    def test_map(absolute, epochs, n_class, visualizer, mask_out):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 4)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
        assert visualizer.get_plt("Gradient", absolute) is not None
>       assert sum([len(i.images) for i in visualizer.fig.axes]) == n_class
E       assert 0 == 1
E        +  where 0 = sum([0])

XBrainLab/tests/backend/visualization/test_visualizer.py:86: AssertionError
________ test_map[True-VisualizerType.SaliencyTopoMap-epochs0-2-False] _________

absolute = False
epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8dea220>
n_class = 1
visualizer = <XBrainLab.backend.visualization.saliency_topomap.SaliencyTopoMapViz object at 0x7ab1d8c453a0>
mask_out = True

    @pytest.mark.parametrize("absolute", [True, False])
    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("visualizer", get_abs_visualizer())
    @pytest.mark.parametrize("mask_out", [True, False])
    def test_map(absolute, epochs, n_class, visualizer, mask_out):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 4)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
        assert visualizer.get_plt("Gradient", absolute) is not None
>       assert sum([len(i.images) for i in visualizer.fig.axes]) == n_class
E       assert 0 == 1
E        +  where 0 = sum([0])

XBrainLab/tests/backend/visualization/test_visualizer.py:86: AssertionError
_________ test_map[True-VisualizerType.SaliencyTopoMap-epochs1-3-True] _________

absolute = True
epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8def1c0>
n_class = 2
visualizer = <XBrainLab.backend.visualization.saliency_topomap.SaliencyTopoMapViz object at 0x7ab1ebff4670>
mask_out = True

    @pytest.mark.parametrize("absolute", [True, False])
    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("visualizer", get_abs_visualizer())
    @pytest.mark.parametrize("mask_out", [True, False])
    def test_map(absolute, epochs, n_class, visualizer, mask_out):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 4)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
        assert visualizer.get_plt("Gradient", absolute) is not None
>       assert sum([len(i.images) for i in visualizer.fig.axes]) == n_class
E       assert 0 == 2
E        +  where 0 = sum([0])

XBrainLab/tests/backend/visualization/test_visualizer.py:86: AssertionError
________ test_map[True-VisualizerType.SaliencyTopoMap-epochs1-3-False] _________

absolute = False
epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8def1c0>
n_class = 2
visualizer = <XBrainLab.backend.visualization.saliency_topomap.SaliencyTopoMapViz object at 0x7ab1ebbdc940>
mask_out = True

    @pytest.mark.parametrize("absolute", [True, False])
    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("visualizer", get_abs_visualizer())
    @pytest.mark.parametrize("mask_out", [True, False])
    def test_map(absolute, epochs, n_class, visualizer, mask_out):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 4)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
        assert visualizer.get_plt("Gradient", absolute) is not None
>       assert sum([len(i.images) for i in visualizer.fig.axes]) == n_class
E       assert 0 == 2
E        +  where 0 = sum([0])

XBrainLab/tests/backend/visualization/test_visualizer.py:86: AssertionError
_________ test_map[True-VisualizerType.SaliencyTopoMap-epochs2-4-True] _________

absolute = True
epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8d74670>
n_class = 3
visualizer = <XBrainLab.backend.visualization.saliency_topomap.SaliencyTopoMapViz object at 0x7ab1d8c80130>
mask_out = True

    @pytest.mark.parametrize("absolute", [True, False])
    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("visualizer", get_abs_visualizer())
    @pytest.mark.parametrize("mask_out", [True, False])
    def test_map(absolute, epochs, n_class, visualizer, mask_out):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 4)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
        assert visualizer.get_plt("Gradient", absolute) is not None
>       assert sum([len(i.images) for i in visualizer.fig.axes]) == n_class
E       assert 0 == 3
E        +  where 0 = sum([0])

XBrainLab/tests/backend/visualization/test_visualizer.py:86: AssertionError
________ test_map[True-VisualizerType.SaliencyTopoMap-epochs2-4-False] _________

absolute = False
epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8d74670>
n_class = 3
visualizer = <XBrainLab.backend.visualization.saliency_topomap.SaliencyTopoMapViz object at 0x7ab1ebd19730>
mask_out = True

    @pytest.mark.parametrize("absolute", [True, False])
    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("visualizer", get_abs_visualizer())
    @pytest.mark.parametrize("mask_out", [True, False])
    def test_map(absolute, epochs, n_class, visualizer, mask_out):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 4)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
        assert visualizer.get_plt("Gradient", absolute) is not None
>       assert sum([len(i.images) for i in visualizer.fig.axes]) == n_class
E       assert 0 == 3
E        +  where 0 = sum([0])

XBrainLab/tests/backend/visualization/test_visualizer.py:86: AssertionError
__________ test_map[False-VisualizerType.SaliencyMap-epochs0-2-True] ___________

absolute = True
epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8dea220>
n_class = 2
visualizer = <XBrainLab.backend.visualization.saliency_map.SaliencyMapViz object at 0x7ab1d8ac2130>
mask_out = False

    @pytest.mark.parametrize("absolute", [True, False])
    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("visualizer", get_abs_visualizer())
    @pytest.mark.parametrize("mask_out", [True, False])
    def test_map(absolute, epochs, n_class, visualizer, mask_out):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 4)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
        assert visualizer.get_plt("Gradient", absolute) is not None
>       assert sum([len(i.images) for i in visualizer.fig.axes]) == n_class
E       assert 1 == 2
E        +  where 1 = sum([1, 0])

XBrainLab/tests/backend/visualization/test_visualizer.py:86: AssertionError
__________ test_map[False-VisualizerType.SaliencyMap-epochs0-2-False] __________

absolute = False
epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8dea220>
n_class = 2
visualizer = <XBrainLab.backend.visualization.saliency_map.SaliencyMapViz object at 0x7ab1d8a24f70>
mask_out = False

    @pytest.mark.parametrize("absolute", [True, False])
    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("visualizer", get_abs_visualizer())
    @pytest.mark.parametrize("mask_out", [True, False])
    def test_map(absolute, epochs, n_class, visualizer, mask_out):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 4)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
        assert visualizer.get_plt("Gradient", absolute) is not None
>       assert sum([len(i.images) for i in visualizer.fig.axes]) == n_class
E       assert 1 == 2
E        +  where 1 = sum([1, 0])

XBrainLab/tests/backend/visualization/test_visualizer.py:86: AssertionError
__________ test_map[False-VisualizerType.SaliencyMap-epochs1-3-True] ___________

absolute = True
epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8def1c0>
n_class = 3
visualizer = <XBrainLab.backend.visualization.saliency_map.SaliencyMapViz object at 0x7ab1d89b3700>
mask_out = False

    @pytest.mark.parametrize("absolute", [True, False])
    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("visualizer", get_abs_visualizer())
    @pytest.mark.parametrize("mask_out", [True, False])
    def test_map(absolute, epochs, n_class, visualizer, mask_out):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 4)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
        assert visualizer.get_plt("Gradient", absolute) is not None
>       assert sum([len(i.images) for i in visualizer.fig.axes]) == n_class
E       assert 1 == 3
E        +  where 1 = sum([1, 0])

XBrainLab/tests/backend/visualization/test_visualizer.py:86: AssertionError
__________ test_map[False-VisualizerType.SaliencyMap-epochs1-3-False] __________

absolute = False
epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8def1c0>
n_class = 3
visualizer = <XBrainLab.backend.visualization.saliency_map.SaliencyMapViz object at 0x7ab1d88f1430>
mask_out = False

    @pytest.mark.parametrize("absolute", [True, False])
    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("visualizer", get_abs_visualizer())
    @pytest.mark.parametrize("mask_out", [True, False])
    def test_map(absolute, epochs, n_class, visualizer, mask_out):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 4)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
        assert visualizer.get_plt("Gradient", absolute) is not None
>       assert sum([len(i.images) for i in visualizer.fig.axes]) == n_class
E       assert 1 == 3
E        +  where 1 = sum([1, 0])

XBrainLab/tests/backend/visualization/test_visualizer.py:86: AssertionError
__________ test_map[False-VisualizerType.SaliencyMap-epochs2-4-True] ___________

absolute = True
epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8d74670>
n_class = 4
visualizer = <XBrainLab.backend.visualization.saliency_map.SaliencyMapViz object at 0x7ab1d8820580>
mask_out = False

    @pytest.mark.parametrize("absolute", [True, False])
    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("visualizer", get_abs_visualizer())
    @pytest.mark.parametrize("mask_out", [True, False])
    def test_map(absolute, epochs, n_class, visualizer, mask_out):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 4)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
        assert visualizer.get_plt("Gradient", absolute) is not None
>       assert sum([len(i.images) for i in visualizer.fig.axes]) == n_class
E       assert 1 == 4
E        +  where 1 = sum([1, 0])

XBrainLab/tests/backend/visualization/test_visualizer.py:86: AssertionError
__________ test_map[False-VisualizerType.SaliencyMap-epochs2-4-False] __________

absolute = False
epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8d74670>
n_class = 4
visualizer = <XBrainLab.backend.visualization.saliency_map.SaliencyMapViz object at 0x7ab1d8754e80>
mask_out = False

    @pytest.mark.parametrize("absolute", [True, False])
    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("visualizer", get_abs_visualizer())
    @pytest.mark.parametrize("mask_out", [True, False])
    def test_map(absolute, epochs, n_class, visualizer, mask_out):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 4)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
        assert visualizer.get_plt("Gradient", absolute) is not None
>       assert sum([len(i.images) for i in visualizer.fig.axes]) == n_class
E       assert 1 == 4
E        +  where 1 = sum([1, 0])

XBrainLab/tests/backend/visualization/test_visualizer.py:86: AssertionError
________ test_map[False-VisualizerType.SaliencyTopoMap-epochs0-2-True] _________

absolute = True
epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8dea220>
n_class = 2
visualizer = <XBrainLab.backend.visualization.saliency_topomap.SaliencyTopoMapViz object at 0x7ab1d86829a0>
mask_out = False

    @pytest.mark.parametrize("absolute", [True, False])
    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("visualizer", get_abs_visualizer())
    @pytest.mark.parametrize("mask_out", [True, False])
    def test_map(absolute, epochs, n_class, visualizer, mask_out):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 4)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
>       assert visualizer.get_plt("Gradient", absolute) is not None

XBrainLab/tests/backend/visualization/test_visualizer.py:85: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/visualization/base.py:39: in get_plt
    return self._get_plt(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.visualization.saliency_topomap.SaliencyTopoMapViz object at 0x7ab1d86829a0>
method = 'Gradient', absolute = True

    def _get_plt(self, method, absolute: bool) -> plt:
        positions = self.epoch_data.get_montage_position()
        chs = self.epoch_data.get_channel_names()
        label_number = self.epoch_data.get_label_number()
    
        rows = 1 if label_number <= self.MIN_LABEL_NUMBER_FOR_MULTI_ROW else 2
        cols = int(np.ceil(label_number / rows))
    
        for labelIndex in range(label_number):
            ax = plt.subplot(rows, cols, labelIndex + 1)
    
            saliency = self.get_saliency(method, labelIndex)
            # no test data for this label
            if len(saliency) == 0:
                continue
            kwargs = {'pos': positions[:, 0:2],
                        'ch_type': 'eeg',
                        'sensors': False,
                        'names': chs,
                        'axes': ax,
                        'show': False,
                        'extrapolate': 'local',
                        'outlines': 'head',
                        'sphere': (0.0, -0.02, 0.0, 0.12),
                        }
    
            if absolute:
                saliency = np.abs(saliency).mean(axis=0)
                cmap = 'Reds'
            else:
                saliency = saliency.mean(axis=0)
                cmap = 'coolwarm'
    
            # average over time
            data = saliency.mean(axis=1)
>           im, _ = mne.viz.plot_topomap(data=data, cmap=cmap, **kwargs)
E           ValueError: not enough values to unpack (expected 2, got 0)

XBrainLab/backend/visualization/saliency_topomap.py:49: ValueError
________ test_map[False-VisualizerType.SaliencyTopoMap-epochs0-2-False] ________

absolute = False
epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8dea220>
n_class = 2
visualizer = <XBrainLab.backend.visualization.saliency_topomap.SaliencyTopoMapViz object at 0x7ab1d8663ee0>
mask_out = False

    @pytest.mark.parametrize("absolute", [True, False])
    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("visualizer", get_abs_visualizer())
    @pytest.mark.parametrize("mask_out", [True, False])
    def test_map(absolute, epochs, n_class, visualizer, mask_out):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 4)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
>       assert visualizer.get_plt("Gradient", absolute) is not None

XBrainLab/tests/backend/visualization/test_visualizer.py:85: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/visualization/base.py:39: in get_plt
    return self._get_plt(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.visualization.saliency_topomap.SaliencyTopoMapViz object at 0x7ab1d8663ee0>
method = 'Gradient', absolute = False

    def _get_plt(self, method, absolute: bool) -> plt:
        positions = self.epoch_data.get_montage_position()
        chs = self.epoch_data.get_channel_names()
        label_number = self.epoch_data.get_label_number()
    
        rows = 1 if label_number <= self.MIN_LABEL_NUMBER_FOR_MULTI_ROW else 2
        cols = int(np.ceil(label_number / rows))
    
        for labelIndex in range(label_number):
            ax = plt.subplot(rows, cols, labelIndex + 1)
    
            saliency = self.get_saliency(method, labelIndex)
            # no test data for this label
            if len(saliency) == 0:
                continue
            kwargs = {'pos': positions[:, 0:2],
                        'ch_type': 'eeg',
                        'sensors': False,
                        'names': chs,
                        'axes': ax,
                        'show': False,
                        'extrapolate': 'local',
                        'outlines': 'head',
                        'sphere': (0.0, -0.02, 0.0, 0.12),
                        }
    
            if absolute:
                saliency = np.abs(saliency).mean(axis=0)
                cmap = 'Reds'
            else:
                saliency = saliency.mean(axis=0)
                cmap = 'coolwarm'
    
            # average over time
            data = saliency.mean(axis=1)
>           im, _ = mne.viz.plot_topomap(data=data, cmap=cmap, **kwargs)
E           ValueError: not enough values to unpack (expected 2, got 0)

XBrainLab/backend/visualization/saliency_topomap.py:49: ValueError
________ test_map[False-VisualizerType.SaliencyTopoMap-epochs1-3-True] _________

absolute = True
epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8def1c0>
n_class = 3
visualizer = <XBrainLab.backend.visualization.saliency_topomap.SaliencyTopoMapViz object at 0x7ab1d863ac40>
mask_out = False

    @pytest.mark.parametrize("absolute", [True, False])
    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("visualizer", get_abs_visualizer())
    @pytest.mark.parametrize("mask_out", [True, False])
    def test_map(absolute, epochs, n_class, visualizer, mask_out):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 4)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
>       assert visualizer.get_plt("Gradient", absolute) is not None

XBrainLab/tests/backend/visualization/test_visualizer.py:85: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/visualization/base.py:39: in get_plt
    return self._get_plt(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.visualization.saliency_topomap.SaliencyTopoMapViz object at 0x7ab1d863ac40>
method = 'Gradient', absolute = True

    def _get_plt(self, method, absolute: bool) -> plt:
        positions = self.epoch_data.get_montage_position()
        chs = self.epoch_data.get_channel_names()
        label_number = self.epoch_data.get_label_number()
    
        rows = 1 if label_number <= self.MIN_LABEL_NUMBER_FOR_MULTI_ROW else 2
        cols = int(np.ceil(label_number / rows))
    
        for labelIndex in range(label_number):
            ax = plt.subplot(rows, cols, labelIndex + 1)
    
            saliency = self.get_saliency(method, labelIndex)
            # no test data for this label
            if len(saliency) == 0:
                continue
            kwargs = {'pos': positions[:, 0:2],
                        'ch_type': 'eeg',
                        'sensors': False,
                        'names': chs,
                        'axes': ax,
                        'show': False,
                        'extrapolate': 'local',
                        'outlines': 'head',
                        'sphere': (0.0, -0.02, 0.0, 0.12),
                        }
    
            if absolute:
                saliency = np.abs(saliency).mean(axis=0)
                cmap = 'Reds'
            else:
                saliency = saliency.mean(axis=0)
                cmap = 'coolwarm'
    
            # average over time
            data = saliency.mean(axis=1)
>           im, _ = mne.viz.plot_topomap(data=data, cmap=cmap, **kwargs)
E           ValueError: not enough values to unpack (expected 2, got 0)

XBrainLab/backend/visualization/saliency_topomap.py:49: ValueError
________ test_map[False-VisualizerType.SaliencyTopoMap-epochs1-3-False] ________

absolute = False
epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8def1c0>
n_class = 3
visualizer = <XBrainLab.backend.visualization.saliency_topomap.SaliencyTopoMapViz object at 0x7ab1d85f4a30>
mask_out = False

    @pytest.mark.parametrize("absolute", [True, False])
    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("visualizer", get_abs_visualizer())
    @pytest.mark.parametrize("mask_out", [True, False])
    def test_map(absolute, epochs, n_class, visualizer, mask_out):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 4)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
>       assert visualizer.get_plt("Gradient", absolute) is not None

XBrainLab/tests/backend/visualization/test_visualizer.py:85: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/visualization/base.py:39: in get_plt
    return self._get_plt(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.visualization.saliency_topomap.SaliencyTopoMapViz object at 0x7ab1d85f4a30>
method = 'Gradient', absolute = False

    def _get_plt(self, method, absolute: bool) -> plt:
        positions = self.epoch_data.get_montage_position()
        chs = self.epoch_data.get_channel_names()
        label_number = self.epoch_data.get_label_number()
    
        rows = 1 if label_number <= self.MIN_LABEL_NUMBER_FOR_MULTI_ROW else 2
        cols = int(np.ceil(label_number / rows))
    
        for labelIndex in range(label_number):
            ax = plt.subplot(rows, cols, labelIndex + 1)
    
            saliency = self.get_saliency(method, labelIndex)
            # no test data for this label
            if len(saliency) == 0:
                continue
            kwargs = {'pos': positions[:, 0:2],
                        'ch_type': 'eeg',
                        'sensors': False,
                        'names': chs,
                        'axes': ax,
                        'show': False,
                        'extrapolate': 'local',
                        'outlines': 'head',
                        'sphere': (0.0, -0.02, 0.0, 0.12),
                        }
    
            if absolute:
                saliency = np.abs(saliency).mean(axis=0)
                cmap = 'Reds'
            else:
                saliency = saliency.mean(axis=0)
                cmap = 'coolwarm'
    
            # average over time
            data = saliency.mean(axis=1)
>           im, _ = mne.viz.plot_topomap(data=data, cmap=cmap, **kwargs)
E           ValueError: not enough values to unpack (expected 2, got 0)

XBrainLab/backend/visualization/saliency_topomap.py:49: ValueError
________ test_map[False-VisualizerType.SaliencyTopoMap-epochs2-4-True] _________

absolute = True
epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8d74670>
n_class = 4
visualizer = <XBrainLab.backend.visualization.saliency_topomap.SaliencyTopoMapViz object at 0x7ab1d85414c0>
mask_out = False

    @pytest.mark.parametrize("absolute", [True, False])
    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("visualizer", get_abs_visualizer())
    @pytest.mark.parametrize("mask_out", [True, False])
    def test_map(absolute, epochs, n_class, visualizer, mask_out):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 4)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
>       assert visualizer.get_plt("Gradient", absolute) is not None

XBrainLab/tests/backend/visualization/test_visualizer.py:85: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/visualization/base.py:39: in get_plt
    return self._get_plt(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.visualization.saliency_topomap.SaliencyTopoMapViz object at 0x7ab1d85414c0>
method = 'Gradient', absolute = True

    def _get_plt(self, method, absolute: bool) -> plt:
        positions = self.epoch_data.get_montage_position()
        chs = self.epoch_data.get_channel_names()
        label_number = self.epoch_data.get_label_number()
    
        rows = 1 if label_number <= self.MIN_LABEL_NUMBER_FOR_MULTI_ROW else 2
        cols = int(np.ceil(label_number / rows))
    
        for labelIndex in range(label_number):
            ax = plt.subplot(rows, cols, labelIndex + 1)
    
            saliency = self.get_saliency(method, labelIndex)
            # no test data for this label
            if len(saliency) == 0:
                continue
            kwargs = {'pos': positions[:, 0:2],
                        'ch_type': 'eeg',
                        'sensors': False,
                        'names': chs,
                        'axes': ax,
                        'show': False,
                        'extrapolate': 'local',
                        'outlines': 'head',
                        'sphere': (0.0, -0.02, 0.0, 0.12),
                        }
    
            if absolute:
                saliency = np.abs(saliency).mean(axis=0)
                cmap = 'Reds'
            else:
                saliency = saliency.mean(axis=0)
                cmap = 'coolwarm'
    
            # average over time
            data = saliency.mean(axis=1)
>           im, _ = mne.viz.plot_topomap(data=data, cmap=cmap, **kwargs)
E           ValueError: not enough values to unpack (expected 2, got 0)

XBrainLab/backend/visualization/saliency_topomap.py:49: ValueError
________ test_map[False-VisualizerType.SaliencyTopoMap-epochs2-4-False] ________

absolute = False
epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8d74670>
n_class = 4
visualizer = <XBrainLab.backend.visualization.saliency_topomap.SaliencyTopoMapViz object at 0x7ab1f8d93c40>
mask_out = False

    @pytest.mark.parametrize("absolute", [True, False])
    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("visualizer", get_abs_visualizer())
    @pytest.mark.parametrize("mask_out", [True, False])
    def test_map(absolute, epochs, n_class, visualizer, mask_out):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 4)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
>       assert visualizer.get_plt("Gradient", absolute) is not None

XBrainLab/tests/backend/visualization/test_visualizer.py:85: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/backend/visualization/base.py:39: in get_plt
    return self._get_plt(*args, **kwargs)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <XBrainLab.backend.visualization.saliency_topomap.SaliencyTopoMapViz object at 0x7ab1f8d93c40>
method = 'Gradient', absolute = False

    def _get_plt(self, method, absolute: bool) -> plt:
        positions = self.epoch_data.get_montage_position()
        chs = self.epoch_data.get_channel_names()
        label_number = self.epoch_data.get_label_number()
    
        rows = 1 if label_number <= self.MIN_LABEL_NUMBER_FOR_MULTI_ROW else 2
        cols = int(np.ceil(label_number / rows))
    
        for labelIndex in range(label_number):
            ax = plt.subplot(rows, cols, labelIndex + 1)
    
            saliency = self.get_saliency(method, labelIndex)
            # no test data for this label
            if len(saliency) == 0:
                continue
            kwargs = {'pos': positions[:, 0:2],
                        'ch_type': 'eeg',
                        'sensors': False,
                        'names': chs,
                        'axes': ax,
                        'show': False,
                        'extrapolate': 'local',
                        'outlines': 'head',
                        'sphere': (0.0, -0.02, 0.0, 0.12),
                        }
    
            if absolute:
                saliency = np.abs(saliency).mean(axis=0)
                cmap = 'Reds'
            else:
                saliency = saliency.mean(axis=0)
                cmap = 'coolwarm'
    
            # average over time
            data = saliency.mean(axis=1)
>           im, _ = mne.viz.plot_topomap(data=data, cmap=cmap, **kwargs)
E           ValueError: not enough values to unpack (expected 2, got 0)

XBrainLab/backend/visualization/saliency_topomap.py:49: ValueError
_____ test_eval_plot[VisualizerType.SaliencySpectrogramMap-True-epochs0-2] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8dea160>
n_class = 1, mask_out = True
visualizer = <XBrainLab.backend.visualization.saliency_spectrogram_map.SaliencySpectrogramMapViz object at 0x7ab1d84c4790>

    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("mask_out", [True, False])
    @pytest.mark.parametrize("visualizer", get_remaining_visualizer())
    def test_eval_plot(epochs, n_class, mask_out, visualizer):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 100)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
        assert visualizer.get_plt("Gradient") is not None
>       assert sum([len(i.images) for i in visualizer.fig.axes]) == n_class
E       assert 0 == 1
E        +  where 0 = sum([0])

XBrainLab/tests/backend/visualization/test_visualizer.py:116: AssertionError
_____ test_eval_plot[VisualizerType.SaliencySpectrogramMap-True-epochs1-3] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8d74550>
n_class = 2, mask_out = True
visualizer = <XBrainLab.backend.visualization.saliency_spectrogram_map.SaliencySpectrogramMapViz object at 0x7ab1d84887c0>

    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("mask_out", [True, False])
    @pytest.mark.parametrize("visualizer", get_remaining_visualizer())
    def test_eval_plot(epochs, n_class, mask_out, visualizer):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 100)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
        assert visualizer.get_plt("Gradient") is not None
>       assert sum([len(i.images) for i in visualizer.fig.axes]) == n_class
E       assert 0 == 2
E        +  where 0 = sum([0])

XBrainLab/tests/backend/visualization/test_visualizer.py:116: AssertionError
_____ test_eval_plot[VisualizerType.SaliencySpectrogramMap-True-epochs2-4] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8d7bb20>
n_class = 3, mask_out = True
visualizer = <XBrainLab.backend.visualization.saliency_spectrogram_map.SaliencySpectrogramMapViz object at 0x7ab1d840c2e0>

    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("mask_out", [True, False])
    @pytest.mark.parametrize("visualizer", get_remaining_visualizer())
    def test_eval_plot(epochs, n_class, mask_out, visualizer):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 100)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
        assert visualizer.get_plt("Gradient") is not None
>       assert sum([len(i.images) for i in visualizer.fig.axes]) == n_class
E       assert 0 == 3
E        +  where 0 = sum([0])

XBrainLab/tests/backend/visualization/test_visualizer.py:116: AssertionError
____ test_eval_plot[VisualizerType.SaliencySpectrogramMap-False-epochs0-2] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8dea160>
n_class = 2, mask_out = False
visualizer = <XBrainLab.backend.visualization.saliency_spectrogram_map.SaliencySpectrogramMapViz object at 0x7ab1d83ebe80>

    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("mask_out", [True, False])
    @pytest.mark.parametrize("visualizer", get_remaining_visualizer())
    def test_eval_plot(epochs, n_class, mask_out, visualizer):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 100)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
        assert visualizer.get_plt("Gradient") is not None
>       assert sum([len(i.images) for i in visualizer.fig.axes]) == n_class
E       assert 1 == 2
E        +  where 1 = sum([1, 0])

XBrainLab/tests/backend/visualization/test_visualizer.py:116: AssertionError
____ test_eval_plot[VisualizerType.SaliencySpectrogramMap-False-epochs1-3] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8d74550>
n_class = 3, mask_out = False
visualizer = <XBrainLab.backend.visualization.saliency_spectrogram_map.SaliencySpectrogramMapViz object at 0x7ab1d8323850>

    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("mask_out", [True, False])
    @pytest.mark.parametrize("visualizer", get_remaining_visualizer())
    def test_eval_plot(epochs, n_class, mask_out, visualizer):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 100)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
        assert visualizer.get_plt("Gradient") is not None
>       assert sum([len(i.images) for i in visualizer.fig.axes]) == n_class
E       assert 1 == 3
E        +  where 1 = sum([1, 0])

XBrainLab/tests/backend/visualization/test_visualizer.py:116: AssertionError
____ test_eval_plot[VisualizerType.SaliencySpectrogramMap-False-epochs2-4] _____

epochs = <XBrainLab.backend.dataset.epochs.Epochs object at 0x7ab1f8d7bb20>
n_class = 4, mask_out = False
visualizer = <XBrainLab.backend.visualization.saliency_spectrogram_map.SaliencySpectrogramMapViz object at 0x7ab1d8255280>

    @pytest.mark.parametrize("epochs, n_class", [
        (Epochs(get_preprocessed_data_list(2)), 2),
        (Epochs(get_preprocessed_data_list(3)), 3),
        (Epochs(get_preprocessed_data_list(4)), 4),
    ])
    @pytest.mark.parametrize("mask_out", [True, False])
    @pytest.mark.parametrize("visualizer", get_remaining_visualizer())
    def test_eval_plot(epochs, n_class, mask_out, visualizer):
        label = np.ones(10)
        output = np.ones((10, 2))
        gradient = {
            i: np.zeros((10, 2, 100)) for i in range(n_class)
        }
        if mask_out:
            gradient[0] = np.array([])
            n_class -= 1
        epochs.set_channels(ch_names, np.random.rand(len(ch_names), 3))
    
        # Create dummy data for new EvalRecord arguments
        gradient_input = gradient.copy()
        smoothgrad = gradient.copy()
        smoothgrad_sq = gradient.copy()
        vargrad = gradient.copy()
    
        eval_record = EvalRecord(label, output, gradient, gradient_input, smoothgrad, smoothgrad_sq, vargrad)
        visualizer = visualizer.value(eval_record, epochs)
        assert visualizer.get_plt("Gradient") is not None
>       assert sum([len(i.images) for i in visualizer.fig.axes]) == n_class
E       assert 1 == 4
E        +  where 1 = sum([1, 0])

XBrainLab/tests/backend/visualization/test_visualizer.py:116: AssertionError
____________________________ test_full_import_flow _____________________________

dataset_panel = <XBrainLab.ui.dashboard_panel.dataset.DatasetPanel object at 0x7ab1d81ecca0>
study = <XBrainLab.backend.study.Study object at 0x7ab1d818e190>

    def test_full_import_flow(dataset_panel, study):
        """
        Integration Test: Full Data Import and Label Application Flow
        1. Load GDF files from test_data_small
        2. Verify files are loaded into Study
        3. Simulate Import Label process
        4. Verify labels are correctly applied to events
        """
        print("\n[Integration] Starting Full Import Flow Test...")
    
        # --- Step 1: Load Data ---
        print(f"[Integration] Loading files from {TEST_DATA_DIR}...")
        loader = RawDataLoader()
        loaded_count = 0
    
        for filename in EXPECTED_FILES:
            filepath = os.path.join(TEST_DATA_DIR, filename)
            if os.path.exists(filepath):
                raw = load_gdf_file(filepath)
                if raw:
                    loader.append(raw)
                    loaded_count += 1
                    print(f"  Loaded: {filename}")
                else:
                    print(f"  Failed to load: {filename}")
            else:
                print(f"  File not found: {filepath}")
    
>       assert loaded_count > 0, "No files were loaded!"
E       AssertionError: No files were loaded!
E       assert 0 > 0

XBrainLab/tests/integration/test_ui_integration.py:72: AssertionError
---------------------------- Captured stdout setup -----------------------------
2026-01-05 17:08:28 - XBrainLab - INFO - Study initialized
------------------------------ Captured log setup ------------------------------
INFO     XBrainLab:study.py:49 Study initialized
----------------------------- Captured stdout call -----------------------------

[Integration] Starting Full Import Flow Test...
[Integration] Loading files from /mnt/data/lab/XBrainlab_with_agent/test_data_small...
2026-01-05 17:08:28 - XBrainLab - ERROR - Failed to load GDF file /mnt/data/lab/XBrainlab_with_agent/test_data_small/A01T.gdf: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
Traceback (most recent call last):
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw_data_loader.py", line 58, in load_gdf_file
    raw_wrapper = Raw(filepath, selected_data)
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw.py", line 43, in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/utils/check.py", line 31, in validate_type
    raise TypeError(
TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
  Failed to load: A01T.gdf
  File not found: /mnt/data/lab/XBrainlab_with_agent/test_data_small/A01E.gdf
2026-01-05 17:08:28 - XBrainLab - ERROR - Failed to load GDF file /mnt/data/lab/XBrainlab_with_agent/test_data_small/A02T.gdf: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
Traceback (most recent call last):
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw_data_loader.py", line 58, in load_gdf_file
    raw_wrapper = Raw(filepath, selected_data)
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw.py", line 43, in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/utils/check.py", line 31, in validate_type
    raise TypeError(
TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
  Failed to load: A02T.gdf
  File not found: /mnt/data/lab/XBrainlab_with_agent/test_data_small/A02E.gdf
2026-01-05 17:08:28 - XBrainLab - ERROR - Failed to load GDF file /mnt/data/lab/XBrainlab_with_agent/test_data_small/A03T.gdf: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
Traceback (most recent call last):
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw_data_loader.py", line 58, in load_gdf_file
    raw_wrapper = Raw(filepath, selected_data)
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw.py", line 43, in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/utils/check.py", line 31, in validate_type
    raise TypeError(
TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
  Failed to load: A03T.gdf
  File not found: /mnt/data/lab/XBrainlab_with_agent/test_data_small/A03E.gdf
------------------------------ Captured log call -------------------------------
ERROR    XBrainLab:raw_data_loader.py:62 Failed to load GDF file /mnt/data/lab/XBrainlab_with_agent/test_data_small/A01T.gdf: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
Traceback (most recent call last):
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw_data_loader.py", line 58, in load_gdf_file
    raw_wrapper = Raw(filepath, selected_data)
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw.py", line 43, in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/utils/check.py", line 31, in validate_type
    raise TypeError(
TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
ERROR    XBrainLab:raw_data_loader.py:62 Failed to load GDF file /mnt/data/lab/XBrainlab_with_agent/test_data_small/A02T.gdf: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
Traceback (most recent call last):
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw_data_loader.py", line 58, in load_gdf_file
    raw_wrapper = Raw(filepath, selected_data)
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw.py", line 43, in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/utils/check.py", line 31, in validate_type
    raise TypeError(
TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
ERROR    XBrainLab:raw_data_loader.py:62 Failed to load GDF file /mnt/data/lab/XBrainlab_with_agent/test_data_small/A03T.gdf: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
Traceback (most recent call last):
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw_data_loader.py", line 58, in load_gdf_file
    raw_wrapper = Raw(filepath, selected_data)
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw.py", line 43, in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/utils/check.py", line 31, in validate_type
    raise TypeError(
TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
___________________________ test_resample_and_epoch ____________________________

dataset_panel = <XBrainLab.ui.dashboard_panel.dataset.DatasetPanel object at 0x7ab1d81b33a0>
study = <XBrainLab.backend.study.Study object at 0x7ab1d81c0e50>

    def test_resample_and_epoch(dataset_panel, study):
        """
        Integration Test: Resample -> Epoch Flow
        Reproduce 'No event markers found' error.
        """
        print("\n[Integration] Starting Resample -> Epoch Test...")
    
        # --- Step 1: Load Data ---
        loader = RawDataLoader()
        loaded_count = 0
        for filename in EXPECTED_FILES:
            filepath = os.path.join(TEST_DATA_DIR, filename)
            if os.path.exists(filepath):
                raw = load_gdf_file(filepath)
                if raw:
                    loader.append(raw)
                    loaded_count += 1
    
>       assert loaded_count > 0
E       assert 0 > 0

XBrainLab/tests/integration/test_ui_integration.py:322: AssertionError
---------------------------- Captured stdout setup -----------------------------
2026-01-05 17:08:28 - XBrainLab - INFO - Study initialized
------------------------------ Captured log setup ------------------------------
INFO     XBrainLab:study.py:49 Study initialized
----------------------------- Captured stdout call -----------------------------

[Integration] Starting Resample -> Epoch Test...
2026-01-05 17:08:28 - XBrainLab - ERROR - Failed to load GDF file /mnt/data/lab/XBrainlab_with_agent/test_data_small/A01T.gdf: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
Traceback (most recent call last):
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw_data_loader.py", line 58, in load_gdf_file
    raw_wrapper = Raw(filepath, selected_data)
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw.py", line 43, in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/utils/check.py", line 31, in validate_type
    raise TypeError(
TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
2026-01-05 17:08:28 - XBrainLab - ERROR - Failed to load GDF file /mnt/data/lab/XBrainlab_with_agent/test_data_small/A02T.gdf: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
Traceback (most recent call last):
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw_data_loader.py", line 58, in load_gdf_file
    raw_wrapper = Raw(filepath, selected_data)
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw.py", line 43, in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/utils/check.py", line 31, in validate_type
    raise TypeError(
TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
2026-01-05 17:08:28 - XBrainLab - ERROR - Failed to load GDF file /mnt/data/lab/XBrainlab_with_agent/test_data_small/A03T.gdf: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
Traceback (most recent call last):
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw_data_loader.py", line 58, in load_gdf_file
    raw_wrapper = Raw(filepath, selected_data)
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw.py", line 43, in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/utils/check.py", line 31, in validate_type
    raise TypeError(
TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
------------------------------ Captured log call -------------------------------
ERROR    XBrainLab:raw_data_loader.py:62 Failed to load GDF file /mnt/data/lab/XBrainlab_with_agent/test_data_small/A01T.gdf: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
Traceback (most recent call last):
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw_data_loader.py", line 58, in load_gdf_file
    raw_wrapper = Raw(filepath, selected_data)
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw.py", line 43, in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/utils/check.py", line 31, in validate_type
    raise TypeError(
TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
ERROR    XBrainLab:raw_data_loader.py:62 Failed to load GDF file /mnt/data/lab/XBrainlab_with_agent/test_data_small/A02T.gdf: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
Traceback (most recent call last):
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw_data_loader.py", line 58, in load_gdf_file
    raw_wrapper = Raw(filepath, selected_data)
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw.py", line 43, in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/utils/check.py", line 31, in validate_type
    raise TypeError(
TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
ERROR    XBrainLab:raw_data_loader.py:62 Failed to load GDF file /mnt/data/lab/XBrainlab_with_agent/test_data_small/A03T.gdf: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
Traceback (most recent call last):
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw_data_loader.py", line 58, in load_gdf_file
    raw_wrapper = Raw(filepath, selected_data)
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw.py", line 43, in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/utils/check.py", line 31, in validate_type
    raise TypeError(
TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
________________________ test_resample_epoch_no_labels _________________________

dataset_panel = <XBrainLab.ui.dashboard_panel.dataset.DatasetPanel object at 0x7ab1d8155040>
study = <XBrainLab.backend.study.Study object at 0x7ab1d815f970>

    def test_resample_epoch_no_labels(dataset_panel, study):
        """
        Integration Test: Resample -> Epoch Flow (No Imported Labels)
        Verify that Resample correctly handles raw stim events and TimeEpoch can use them.
        """
        print("\n[Integration] Starting Resample -> Epoch (No Labels) Test...")
    
        # --- Step 1: Load Data ---
        loader = RawDataLoader()
        loaded_count = 0
        for filename in EXPECTED_FILES:
            filepath = os.path.join(TEST_DATA_DIR, filename)
            if os.path.exists(filepath):
                raw = load_gdf_file(filepath)
                if raw:
                    loader.append(raw)
                    loaded_count += 1
    
>       assert loaded_count > 0
E       assert 0 > 0

XBrainLab/tests/integration/test_ui_integration.py:413: AssertionError
---------------------------- Captured stdout setup -----------------------------
2026-01-05 17:08:28 - XBrainLab - INFO - Study initialized
------------------------------ Captured log setup ------------------------------
INFO     XBrainLab:study.py:49 Study initialized
----------------------------- Captured stdout call -----------------------------

[Integration] Starting Resample -> Epoch (No Labels) Test...
2026-01-05 17:08:28 - XBrainLab - ERROR - Failed to load GDF file /mnt/data/lab/XBrainlab_with_agent/test_data_small/A01T.gdf: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
Traceback (most recent call last):
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw_data_loader.py", line 58, in load_gdf_file
    raw_wrapper = Raw(filepath, selected_data)
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw.py", line 43, in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/utils/check.py", line 31, in validate_type
    raise TypeError(
TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
2026-01-05 17:08:28 - XBrainLab - ERROR - Failed to load GDF file /mnt/data/lab/XBrainlab_with_agent/test_data_small/A02T.gdf: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
Traceback (most recent call last):
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw_data_loader.py", line 58, in load_gdf_file
    raw_wrapper = Raw(filepath, selected_data)
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw.py", line 43, in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/utils/check.py", line 31, in validate_type
    raise TypeError(
TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
2026-01-05 17:08:28 - XBrainLab - ERROR - Failed to load GDF file /mnt/data/lab/XBrainlab_with_agent/test_data_small/A03T.gdf: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
Traceback (most recent call last):
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw_data_loader.py", line 58, in load_gdf_file
    raw_wrapper = Raw(filepath, selected_data)
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw.py", line 43, in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/utils/check.py", line 31, in validate_type
    raise TypeError(
TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
------------------------------ Captured log call -------------------------------
ERROR    XBrainLab:raw_data_loader.py:62 Failed to load GDF file /mnt/data/lab/XBrainlab_with_agent/test_data_small/A01T.gdf: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
Traceback (most recent call last):
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw_data_loader.py", line 58, in load_gdf_file
    raw_wrapper = Raw(filepath, selected_data)
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw.py", line 43, in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/utils/check.py", line 31, in validate_type
    raise TypeError(
TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
ERROR    XBrainLab:raw_data_loader.py:62 Failed to load GDF file /mnt/data/lab/XBrainlab_with_agent/test_data_small/A02T.gdf: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
Traceback (most recent call last):
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw_data_loader.py", line 58, in load_gdf_file
    raw_wrapper = Raw(filepath, selected_data)
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw.py", line 43, in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/utils/check.py", line 31, in validate_type
    raise TypeError(
TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
ERROR    XBrainLab:raw_data_loader.py:62 Failed to load GDF file /mnt/data/lab/XBrainlab_with_agent/test_data_small/A03T.gdf: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
Traceback (most recent call last):
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw_data_loader.py", line 58, in load_gdf_file
    raw_wrapper = Raw(filepath, selected_data)
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/load_data/raw.py", line 43, in __init__
    validate_type(mne_data, (mne.io.BaseRaw, mne.BaseEpochs), 'mne_data')
  File "/mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/utils/check.py", line 31, in validate_type
    raise TypeError(
TypeError: mne_data must be an instance of conftest.MockBaseRaw or conftest.MockBaseEpochs, got <class 'unittest.mock.MagicMock'> instead.
________________________ test_ui_refresh_on_tab_switch _________________________

qtbot = <pytestqt.qtbot.QtBot object at 0x7ab1d8157d30>
mock_study = <MagicMock id='134904253087216'>

    def test_ui_refresh_on_tab_switch(qtbot, mock_study):
        """Test that switching tabs triggers refresh_data on panels."""
        # Setup
>       window = MainWindow(mock_study)

XBrainLab/tests/integration/test_ui_refresh.py:16: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
XBrainLab/ui/main_window.py:94: in __init__
    self.init_panels()
XBrainLab/ui/main_window.py:285: in init_panels
    self.training_panel = TrainingPanel(self)
XBrainLab/ui/training/panel.py:124: in __init__
    self.init_ui()
XBrainLab/ui/training/panel.py:356: in init_ui
    self.update_summary()
XBrainLab/ui/training/panel.py:469: in update_summary
    model_name = self.study.model_holder.target_model.__name__
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <MagicMock name='mock.model_holder.target_model' id='134904115375072'>
name = '__name__'

    def __getattr__(self, name):
        if name in {'_mock_methods', '_mock_unsafe'}:
            raise AttributeError(name)
        elif self._mock_methods is not None:
            if name not in self._mock_methods or name in _all_magics:
                raise AttributeError("Mock object has no attribute %r" % name)
        elif _is_magic(name):
>           raise AttributeError(name)
E           AttributeError: __name__

/home/hxin/miniconda3/envs/XBrainLab/lib/python3.9/unittest/mock.py:632: AttributeError
=============================== warnings summary ===============================
XBrainLab/tests/backend/training/test_training_plan.py:315
XBrainLab/tests/backend/training/test_training_plan.py:315
  /mnt/data/lab/XBrainlab_with_agent/XBrainLab/tests/backend/training/test_training_plan.py:315: PytestUnknownMarkWarning: Unknown pytest.mark.timeout - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.timeout(10)

XBrainLab/tests/backend/training/test_training_plan.py:372
XBrainLab/tests/backend/training/test_training_plan.py:372
  /mnt/data/lab/XBrainlab_with_agent/XBrainLab/tests/backend/training/test_training_plan.py:372: PytestUnknownMarkWarning: Unknown pytest.mark.timeout - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.timeout(10)

XBrainLab/tests/backend/training/test_training_plan.py:389
XBrainLab/tests/backend/training/test_training_plan.py:389
  /mnt/data/lab/XBrainlab_with_agent/XBrainLab/tests/backend/training/test_training_plan.py:389: PytestUnknownMarkWarning: Unknown pytest.mark.timeout - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.timeout(10)

XBrainLab/tests/backend/training/test_training_plan.py:414
XBrainLab/tests/backend/training/test_training_plan.py:414
  /mnt/data/lab/XBrainlab_with_agent/XBrainLab/tests/backend/training/test_training_plan.py:414: PytestUnknownMarkWarning: Unknown pytest.mark.timeout - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.timeout(10)

XBrainLab/tests/backend/training/test_training_plan.py:425
XBrainLab/tests/backend/training/test_training_plan.py:425
  /mnt/data/lab/XBrainlab_with_agent/XBrainLab/tests/backend/training/test_training_plan.py:425: PytestUnknownMarkWarning: Unknown pytest.mark.timeout - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.timeout(10)

XBrainLab/tests/backend/training/test_training_plan.py:435
XBrainLab/tests/backend/training/test_training_plan.py:435
  /mnt/data/lab/XBrainlab_with_agent/XBrainLab/tests/backend/training/test_training_plan.py:435: PytestUnknownMarkWarning: Unknown pytest.mark.timeout - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.timeout(10)

XBrainLab/tests/backend/training/test_training_plan.py:450
XBrainLab/tests/backend/training/test_training_plan.py:450
  /mnt/data/lab/XBrainlab_with_agent/XBrainLab/tests/backend/training/test_training_plan.py:450: PytestUnknownMarkWarning: Unknown pytest.mark.timeout - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.timeout(10)

XBrainLab/tests/backend/training/test_training_plan.py:490
XBrainLab/tests/backend/training/test_training_plan.py:490
  /mnt/data/lab/XBrainlab_with_agent/XBrainLab/tests/backend/training/test_training_plan.py:490: PytestUnknownMarkWarning: Unknown pytest.mark.timeout - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.timeout(10)

XBrainLab/tests/backend/training/test_training_plan.py:505
XBrainLab/tests/backend/training/test_training_plan.py:505
  /mnt/data/lab/XBrainlab_with_agent/XBrainLab/tests/backend/training/test_training_plan.py:505: PytestUnknownMarkWarning: Unknown pytest.mark.timeout - is this a typo?  You can register custom marks to avoid this warning - for details, see https://docs.pytest.org/en/stable/how-to/mark.html
    @pytest.mark.timeout(10)

XBrainLab/tests/backend/training/test_training_plan.py: 52 warnings
XBrainLab/tests/backend/utils/test_seed.py: 1 warning
  /mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/utils/seed.py:16: DeprecationWarning: Seeding based on hashing is deprecated
  since Python 3.9 and will be removed in a subsequent version. The only 
  supported seed types are: None, int, float, str, bytes, and bytearray.
    random.seed(seed)

XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[False-VisualizerType.SaliencyTopoMap-epochs0-2-False]
  /mnt/data/lab/XBrainlab_with_agent/XBrainLab/backend/visualization/base.py:37: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.
    self.fig = plt.figure(figsize=self.figsize, dpi=self.dpi)

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
================================ tests coverage ================================
_______________ coverage: platform linux, python 3.9.25-final-0 ________________

Name                                                                Stmts   Miss  Cover
---------------------------------------------------------------------------------------
XBrainLab/__init__.py                                                   2      0   100%
XBrainLab/backend/__init__.py                                           0      0   100%
XBrainLab/backend/dataset/__init__.py                                   6      0   100%
XBrainLab/backend/dataset/data_splitter.py                             67      0   100%
XBrainLab/backend/dataset/dataset.py                                   79      0   100%
XBrainLab/backend/dataset/dataset_generator.py                        151      2    99%
XBrainLab/backend/dataset/epochs.py                                   248     17    93%
XBrainLab/backend/dataset/option.py                                    22      0   100%
XBrainLab/backend/evaluation/__init__.py                                2      0   100%
XBrainLab/backend/evaluation/metric.py                                  5      0   100%
XBrainLab/backend/load_data/__init__.py                                 8      0   100%
XBrainLab/backend/load_data/data_loader.py                             42      8    81%
XBrainLab/backend/load_data/event_loader.py                            47      8    83%
XBrainLab/backend/load_data/label_loader.py                            50     15    70%
XBrainLab/backend/load_data/raw.py                                    132     31    77%
XBrainLab/backend/load_data/raw_data_loader.py                         78     27    65%
XBrainLab/backend/model_base/EEGNet.py                                 40     33    18%
XBrainLab/backend/model_base/SCCNet.py                                 38     31    18%
XBrainLab/backend/model_base/ShallowConvNet.py                         41     34    17%
XBrainLab/backend/model_base/__init__.py                                4      0   100%
XBrainLab/backend/model_base/tests/__init__.py                          0      0   100%
XBrainLab/backend/model_base/tests/test_model_base.py                  13     13     0%
XBrainLab/backend/preprocessor/__init__.py                             12      0   100%
XBrainLab/backend/preprocessor/base.py                                 23      0   100%
XBrainLab/backend/preprocessor/channel_selection.py                    10      1    90%
XBrainLab/backend/preprocessor/edit_event.py                           59     39    34%
XBrainLab/backend/preprocessor/export.py                               26     19    27%
XBrainLab/backend/preprocessor/filtering.py                            21     15    29%
XBrainLab/backend/preprocessor/ica.py                                  23     15    35%
XBrainLab/backend/preprocessor/normalize.py                            28     22    21%
XBrainLab/backend/preprocessor/rereference.py                          10      4    60%
XBrainLab/backend/preprocessor/resample.py                             20     13    35%
XBrainLab/backend/preprocessor/time_epoch.py                           34      3    91%
XBrainLab/backend/preprocessor/window_epoch.py                         25      2    92%
XBrainLab/backend/study.py                                            172     12    93%
XBrainLab/backend/training/__init__.py                                  5      0   100%
XBrainLab/backend/training/model_holder.py                             16      0   100%
XBrainLab/backend/training/option.py                                  138      0   100%
XBrainLab/backend/training/record/__init__.py                           3      0   100%
XBrainLab/backend/training/record/eval.py                              63     18    71%
XBrainLab/backend/training/record/train.py                            234    160    32%
XBrainLab/backend/training/trainer.py                                  63      7    89%
XBrainLab/backend/training/training_plan.py                           426    312    27%
XBrainLab/backend/training/utils.py                                    22     15    32%
XBrainLab/backend/utils/__init__.py                                     3      0   100%
XBrainLab/backend/utils/check.py                                       26      0   100%
XBrainLab/backend/utils/filename_parser.py                             90      7    92%
XBrainLab/backend/utils/logger.py                                      24      1    96%
XBrainLab/backend/utils/mne_helper.py                                  11      6    45%
XBrainLab/backend/utils/seed.py                                        24      0   100%
XBrainLab/backend/visualization/__init__.py                             3      0   100%
XBrainLab/backend/visualization/base.py                                33      9    73%
XBrainLab/backend/visualization/plot_type.py                           14      0   100%
XBrainLab/backend/visualization/saliency_map.py                        29      0   100%
XBrainLab/backend/visualization/saliency_spectrogram_map.py            31      0   100%
XBrainLab/backend/visualization/saliency_topomap.py                    29      3    90%
XBrainLab/tests/__init__.py                                             0      0   100%
XBrainLab/tests/backend/dataset/__init__.py                             0      0   100%
XBrainLab/tests/backend/dataset/test_data_splitter.py                  58      0   100%
XBrainLab/tests/backend/dataset/test_dataset.py                       101     16    84%
XBrainLab/tests/backend/dataset/test_dataset_generator.py             453     23    95%
XBrainLab/tests/backend/dataset/test_epochs.py                        345     89    74%
XBrainLab/tests/backend/dataset/test_option.py                         22      0   100%
XBrainLab/tests/backend/load_data/__init__.py                           0      0   100%
XBrainLab/tests/backend/load_data/test_data_loader.py                  58     27    53%
XBrainLab/tests/backend/load_data/test_event_loader.py                 40     11    72%
XBrainLab/tests/backend/load_data/test_event_loader_strict.py          41     12    71%
XBrainLab/tests/backend/load_data/test_label_loader.py                 38      0   100%
XBrainLab/tests/backend/load_data/test_loaders.py                      45      0   100%
XBrainLab/tests/backend/load_data/test_raw.py                         233     80    66%
XBrainLab/tests/backend/load_data/test_raw_data_loader.py              40      0   100%
XBrainLab/tests/backend/preprocessor/__init__.py                        0      0   100%
XBrainLab/tests/backend/preprocessor/test_base.py                      35      0   100%
XBrainLab/tests/backend/preprocessor/test_filtering.py                 49     25    49%
XBrainLab/tests/backend/preprocessor/test_ica.py                       33      4    88%
XBrainLab/tests/backend/preprocessor/test_preprocess.py               199     98    51%
XBrainLab/tests/backend/preprocessor/test_rereference.py               26      8    69%
XBrainLab/tests/backend/preprocessor/test_resample.py                  56     15    73%
XBrainLab/tests/backend/preprocessor/test_time_epoch.py                55      2    96%
XBrainLab/tests/backend/training/__init__.py                            0      0   100%
XBrainLab/tests/backend/training/record/__init__.py                     0      0   100%
XBrainLab/tests/backend/training/record/test_eval.py                   48      0   100%
XBrainLab/tests/backend/training/record/test_train.py                 245    176    28%
XBrainLab/tests/backend/training/test_model_holder.py                  18      0   100%
XBrainLab/tests/backend/training/test_option.py                        76      2    97%
XBrainLab/tests/backend/training/test_trainer.py                       93      7    92%
XBrainLab/tests/backend/training/test_training_plan.py                356    222    38%
XBrainLab/tests/backend/training/test_training_plan_test_model.py      99     37    63%
XBrainLab/tests/backend/utils/__init__.py                               0      0   100%
XBrainLab/tests/backend/utils/test_check.py                            33      0   100%
XBrainLab/tests/backend/utils/test_filename_parser.py                  42      0   100%
XBrainLab/tests/backend/utils/test_logger.py                           44      0   100%
XBrainLab/tests/backend/utils/test_seed.py                             26      5    81%
XBrainLab/tests/backend/visualization/__init__.py                       0      0   100%
XBrainLab/tests/backend/visualization/test_base.py                     18      0   100%
XBrainLab/tests/backend/visualization/test_visualizer.py               81      2    98%
XBrainLab/tests/integration/__init__.py                                 0      0   100%
XBrainLab/tests/integration/test_ui_integration.py                    214    151    29%
XBrainLab/tests/integration/test_ui_refresh.py                         25     13    48%
XBrainLab/tests/test_study.py                                         228      0   100%
XBrainLab/tests/ui/__init__.py                                          0      0   100%
XBrainLab/tests/ui/test_main_window.py                                 33      1    97%
XBrainLab/tests/ui/test_training_panel_redesign.py                     93      2    98%
XBrainLab/tests/ui/test_workflow.py                                    27      1    96%
XBrainLab/ui/__init__.py                                                0      0   100%
XBrainLab/ui/agent_worker.py                                           22     13    41%
XBrainLab/ui/chat_panel.py                                             36     10    72%
XBrainLab/ui/dashboard_panel/__init__.py                                0      0   100%
XBrainLab/ui/dashboard_panel/dataset.py                               478    367    23%
XBrainLab/ui/dashboard_panel/import_label.py                          308    277    10%
XBrainLab/ui/dashboard_panel/info.py                                   93     64    31%
XBrainLab/ui/dashboard_panel/preprocess.py                            754    523    31%
XBrainLab/ui/dashboard_panel/smart_parser.py                          225    210     7%
XBrainLab/ui/dataset/__init__.py                                        0      0   100%
XBrainLab/ui/dataset/data_splitting.py                                205    182    11%
XBrainLab/ui/dataset/data_splitting_setting.py                        247    213    14%
XBrainLab/ui/dataset/split_chooser.py                                  34     28    18%
XBrainLab/ui/evaluation/__init__.py                                     0      0   100%
XBrainLab/ui/evaluation/confusion_matrix.py                            73     30    59%
XBrainLab/ui/evaluation/evaluation_table.py                            87     42    52%
XBrainLab/ui/evaluation/model_output.py                                52     46    12%
XBrainLab/ui/evaluation/panel.py                                      115     15    87%
XBrainLab/ui/load_data/__init__.py                                      0      0   100%
XBrainLab/ui/main_window.py                                           196     63    68%
XBrainLab/ui/services/label_import_service.py                          92     81    12%
XBrainLab/ui/training/__init__.py                                       0      0   100%
XBrainLab/ui/training/model_selection.py                              104     90    13%
XBrainLab/ui/training/panel.py                                        400    181    55%
XBrainLab/ui/training/test_only_setting.py                             55     45    18%
XBrainLab/ui/training/training_manager.py                             100     82    18%
XBrainLab/ui/training/training_setting.py                             216    192    11%
XBrainLab/ui/visualization/__init__.py                                  0      0   100%
XBrainLab/ui/visualization/export_saliency.py                          68     58    15%
XBrainLab/ui/visualization/model_summary.py                            42     34    19%
XBrainLab/ui/visualization/montage_picker.py                          105     91    13%
XBrainLab/ui/visualization/panel.py                                   161     48    70%
XBrainLab/ui/visualization/plot_3d_head.py                            119     98    18%
XBrainLab/ui/visualization/plot_abs_plot_figure.py                     20     20     0%
XBrainLab/ui/visualization/plot_abs_topo_plot_figure.py                10     10     0%
XBrainLab/ui/visualization/plot_eval_record_figure.py                  10     10     0%
XBrainLab/ui/visualization/saliency_3Dplot.py                          93     28    70%
XBrainLab/ui/visualization/saliency_map.py                             96     40    58%
XBrainLab/ui/visualization/saliency_setting.py                         91     82    10%
XBrainLab/ui/visualization/saliency_spectrogram.py                     91     40    56%
XBrainLab/ui/visualization/saliency_topomap.py                        103     46    55%
XBrainLab/ui/widget/__init__.py                                         2      0   100%
XBrainLab/ui/widget/card.py                                            28     28     0%
XBrainLab/ui/widget/placeholder.py                                     17     17     0%
XBrainLab/ui/widget/plot_figure_window.py                             119    103    13%
XBrainLab/ui/widget/single_plot_window.py                              68     50    26%
---------------------------------------------------------------------------------------
TOTAL                                                               11686   5488    53%
=========================== short test summary info ============================
FAILED XBrainLab/tests/backend/dataset/test_dataset.py::test_dataset_set_test_mask
FAILED XBrainLab/tests/backend/dataset/test_dataset.py::test_dataset_set_remaining_by_subject_idx
FAILED XBrainLab/tests/backend/dataset/test_dataset.py::test_dataset_intersection_with_subject_by_idx[0-24]
FAILED XBrainLab/tests/backend/dataset/test_dataset.py::test_dataset_get_data
FAILED XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_test[SplitByType.SESSION-pick_session]
FAILED XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_test[SplitByType.SESSION_IND-pick_session]
FAILED XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_test[SplitByType.SUBJECT-pick_subject]
FAILED XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_test[SplitByType.SUBJECT_IND-pick_subject]
FAILED XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_test[SplitByType.TRIAL-pick_trial]
FAILED XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_test[SplitByType.TRIAL_IND-pick_trial]
FAILED XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_validation[ValSplitByType.SESSION-pick_session]
FAILED XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_validation[ValSplitByType.SUBJECT-pick_subject]
FAILED XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_split_validation[ValSplitByType.TRIAL-pick_trial]
FAILED XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_handle_individual
FAILED XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_handle_individual_cross_validation
FAILED XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_handle_full
FAILED XBrainLab/tests/backend/dataset/test_dataset_generator.py::test_dataset_generator_handle_full_cross_validation
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_subject_attributes
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_session_attributes
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_label_attributes
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_by_mask
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_by_index
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_info - Ass...
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_generate_mask_target_partial
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[False-selected_num0]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[False-selected_num1]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[False-selected_num2]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[False-selected_num3]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[False-selected_num4]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[False-selected_num5]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[False-selected_num6]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[False-selected_num7]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[True-selected_num0]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[True-selected_num1]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[True-selected_num2]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[True-selected_num3]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[True-selected_num4]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[True-selected_num5]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[True-selected_num6]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick[True-selected_num7]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-0-expected0-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-1-expected1-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-2-expected2-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-3-expected3-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-4-expected4-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-5-expected5-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-6-expected6-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-7-expected7-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-8-expected8-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-9-expected9-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-10-expected10-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-11-expected11-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-12-expected12-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-13-expected13-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-14-expected14-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-15-expected15-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-16-expected16-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-17-expected17-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-18-expected18-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-19-expected19-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-20-expected20-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-21-expected21-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-22-expected22-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-23-expected23-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-24-expected24-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-25-expected25-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-26-expected26-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-27-expected27-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-28-expected28-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-29-expected29-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-30-expected30-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-31-expected31-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-32-expected32-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-33-expected33-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-34-expected34-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-35-expected35-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-36-expected36-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-37-expected37-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.KFOLD-1-expected38-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected39-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected40-1-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected41-2-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected42-6-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.0-expected43-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.1-expected44-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.2-expected45-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.30000000000000004-expected46-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.4-expected47-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.5-expected48-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.6000000000000001-expected49-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.7000000000000001-expected50-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.8-expected51-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.9-expected52-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-0-expected53-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-1-expected54-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-2-expected55-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-3-expected56-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-4-expected57-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-5-expected58-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-6-expected59-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-7-expected60-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-8-expected61-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-9-expected62-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-10-expected63-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-11-expected64-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-12-expected65-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-13-expected66-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-14-expected67-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-15-expected68-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-16-expected69-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-17-expected70-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-18-expected71-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-19-expected72-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-20-expected73-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-21-expected74-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-22-expected75-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-23-expected76-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-24-expected77-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-25-expected78-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-26-expected79-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-27-expected80-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-28-expected81-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-29-expected82-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-30-expected83-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-31-expected84-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-32-expected85-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-33-expected86-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-34-expected87-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-35-expected88-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-36-expected89-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.NUMBER-37-expected90-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.KFOLD-1-expected91-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected92-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected93-1-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected94-2-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected95-3-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected96-4-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.KFOLD-10-expected97-5-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.0-expected98-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.1-expected99-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.2-expected100-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.30000000000000004-expected101-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.4-expected102-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.5-expected103-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.6000000000000001-expected104-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.7000000000000001-expected105-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.8-expected106-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[None-SplitUnit.RATIO-0.9-expected107-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-0-expected0-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-1-expected1-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-2-expected2-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-3-expected3-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-4-expected4-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-5-expected5-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-6-expected6-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-7-expected7-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-8-expected8-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-9-expected9-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-10-expected10-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-11-expected11-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-12-expected12-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-13-expected13-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-14-expected14-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-15-expected15-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-16-expected16-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-17-expected17-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-18-expected18-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-19-expected19-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-20-expected20-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-21-expected21-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-22-expected22-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-23-expected23-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-24-expected24-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-25-expected25-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-26-expected26-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-27-expected27-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-28-expected28-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-29-expected29-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-30-expected30-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-31-expected31-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-32-expected32-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-33-expected33-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-34-expected34-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-35-expected35-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-36-expected36-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-37-expected37-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-1-expected38-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected39-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected40-1-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected41-2-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected42-6-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.0-expected43-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.1-expected44-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.2-expected45-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.30000000000000004-expected46-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.4-expected47-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.5-expected48-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.6000000000000001-expected49-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.7000000000000001-expected50-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.8-expected51-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.9-expected52-0-False]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-0-expected53-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-1-expected54-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-2-expected55-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-3-expected56-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-4-expected57-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-5-expected58-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-6-expected59-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-7-expected60-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-8-expected61-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-9-expected62-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-10-expected63-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-11-expected64-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-12-expected65-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-13-expected66-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-14-expected67-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-15-expected68-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-16-expected69-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-17-expected70-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-18-expected71-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-19-expected72-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-20-expected73-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-21-expected74-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-22-expected75-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-23-expected76-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-24-expected77-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-25-expected78-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-26-expected79-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-27-expected80-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-28-expected81-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-29-expected82-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-30-expected83-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-31-expected84-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-32-expected85-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-33-expected86-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-34-expected87-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-35-expected88-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-36-expected89-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.NUMBER-37-expected90-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-1-expected91-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected92-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected93-1-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected94-2-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected95-3-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected96-4-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.KFOLD-10-expected97-5-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.0-expected98-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.1-expected99-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.2-expected100-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.30000000000000004-expected101-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.4-expected102-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.5-expected103-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.6000000000000001-expected104-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.7000000000000001-expected105-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.8-expected106-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_by_trial[clean_mask1-SplitUnit.RATIO-0.9-expected107-0-True]
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_subject
FAILED XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_pick_session
FAILED XBrainLab/tests/backend/load_data/test_data_loader.py::test_raw_data_loader_append
FAILED XBrainLab/tests/backend/load_data/test_data_loader.py::test_raw_data_loader_append_error
FAILED XBrainLab/tests/backend/load_data/test_event_loader.py::test_create_event_from_1d_list
FAILED XBrainLab/tests/backend/load_data/test_event_loader_strict.py::test_event_loader_raw_no_events_raises_error
FAILED XBrainLab/tests/backend/load_data/test_event_loader_strict.py::test_event_loader_epochs_fallback_ok
FAILED XBrainLab/tests/backend/load_data/test_loaders.py::TestLoaders::test_load_bdf_file
FAILED XBrainLab/tests/backend/load_data/test_loaders.py::TestLoaders::test_load_brainvision_file
FAILED XBrainLab/tests/backend/load_data/test_loaders.py::TestLoaders::test_load_cnt_file
FAILED XBrainLab/tests/backend/load_data/test_loaders.py::TestLoaders::test_load_edf_file
FAILED XBrainLab/tests/backend/load_data/test_loaders.py::TestLoaders::test_load_fif_failure
FAILED XBrainLab/tests/backend/load_data/test_loaders.py::TestLoaders::test_load_fif_file
FAILED XBrainLab/tests/backend/load_data/test_raw.py::test_mne_raw_info - ass...
FAILED XBrainLab/tests/backend/load_data/test_raw.py::test_mne_raw_2_info - T...
FAILED XBrainLab/tests/backend/load_data/test_raw.py::test_raw_empty_event - ...
FAILED XBrainLab/tests/backend/load_data/test_raw.py::test_raw_set_event_on_empty_event
FAILED XBrainLab/tests/backend/load_data/test_raw.py::test_raw_stim_event - A...
FAILED XBrainLab/tests/backend/load_data/test_raw.py::test_raw_set_event_on_stim_event
FAILED XBrainLab/tests/backend/load_data/test_raw.py::test_set_mne_1[raw] - T...
FAILED XBrainLab/tests/backend/load_data/test_raw.py::test_set_mne_1[epoch]
FAILED XBrainLab/tests/backend/load_data/test_raw.py::test_set_mne_2[raw] - T...
FAILED XBrainLab/tests/backend/load_data/test_raw.py::test_set_mne_2[epoch]
FAILED XBrainLab/tests/backend/load_data/test_raw.py::test_set_mne_after_set_event_1[raw]
FAILED XBrainLab/tests/backend/load_data/test_raw.py::test_set_mne_after_set_event_1[epoch]
FAILED XBrainLab/tests/backend/load_data/test_raw.py::test_set_mne_after_set_event_2[raw]
FAILED XBrainLab/tests/backend/load_data/test_raw.py::test_set_mne_after_set_event_2[epoch]
FAILED XBrainLab/tests/backend/load_data/test_raw.py::test_set_mne_and_wipe_events_1[raw]
FAILED XBrainLab/tests/backend/load_data/test_raw.py::test_set_mne_and_wipe_events_1[epoch]
FAILED XBrainLab/tests/backend/load_data/test_raw.py::test_set_mne_and_wipe_events_2[raw]
FAILED XBrainLab/tests/backend/load_data/test_raw.py::test_set_mne_and_wipe_events_2[epoch]
FAILED XBrainLab/tests/backend/preprocessor/test_filtering.py::test_filtering_bandpass
FAILED XBrainLab/tests/backend/preprocessor/test_filtering.py::test_filtering_notch
FAILED XBrainLab/tests/backend/preprocessor/test_filtering.py::test_filtering_combined
FAILED XBrainLab/tests/backend/preprocessor/test_ica.py::test_ica_picard_missing_dependency
FAILED XBrainLab/tests/backend/preprocessor/test_ica.py::test_ica_fit_apply
FAILED XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_channel_selection[raw]
FAILED XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_channel_selection[epoch]
FAILED XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_export[raw]
FAILED XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_export[epoch]
FAILED XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_filtering[raw]
FAILED XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_filtering[epoch]
FAILED XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_resample[raw]
FAILED XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_resample[epoch]
FAILED XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_epoch_wrong_events[TimeEpoch]
FAILED XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_epoch_wrong_events[WindowEpoch]
FAILED XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_time_epoch_without_baseline
FAILED XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_time_epoch_with_baseline
FAILED XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_window_epoch
FAILED XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_normalization_z_score[raw]
FAILED XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_normalization_z_score[epoch]
FAILED XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_normalization_minmax[raw]
FAILED XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_normalization_minmax[epoch]
FAILED XBrainLab/tests/backend/preprocessor/test_rereference.py::test_rereference_average
FAILED XBrainLab/tests/backend/preprocessor/test_rereference.py::test_rereference_specific_channel
FAILED XBrainLab/tests/backend/preprocessor/test_resample.py::TestResample::test_resample_downsample
FAILED XBrainLab/tests/backend/preprocessor/test_resample.py::TestResample::test_resample_upsample
FAILED XBrainLab/tests/backend/preprocessor/test_resample.py::TestResample::test_resample_no_events
FAILED XBrainLab/tests/backend/preprocessor/test_time_epoch.py::TestTimeEpoch::test_time_epoch_success
FAILED XBrainLab/tests/backend/preprocessor/test_time_epoch.py::TestTimeEpoch::test_time_epoch_duplicate_events
FAILED XBrainLab/tests/backend/training/record/test_train.py::test_train_record_getter
FAILED XBrainLab/tests/backend/training/record/test_train.py::test_train_record_create_dir
FAILED XBrainLab/tests/backend/training/record/test_train.py::test_train_record_backup_dir
FAILED XBrainLab/tests/backend/training/test_option.py::test_option[kwargs8-False]
FAILED XBrainLab/tests/backend/training/test_option.py::test_option[kwargs9-False]
FAILED XBrainLab/tests/backend/training/test_option.py::test_option[kwargs10-False]
FAILED XBrainLab/tests/backend/training/test_option.py::test_option[kwargs11-False]
FAILED XBrainLab/tests/backend/training/test_option.py::test_option[kwargs12-False]
FAILED XBrainLab/tests/backend/training/test_option.py::test_option[kwargs20-False]
FAILED XBrainLab/tests/backend/training/test_trainer.py::test_trainer - Asser...
FAILED XBrainLab/tests/backend/training/test_trainer.py::test_trainer_get_plan[Fake-test-1]
FAILED XBrainLab/tests/backend/training/test_trainer.py::test_trainer_get_plan[Fake0-test-0]
FAILED XBrainLab/tests/backend/training/test_trainer.py::test_trainer_get_plan[Fake1-test-0]
FAILED XBrainLab/tests/backend/training/test_trainer.py::test_trainer_get_plan[Fake1-tests-2]
FAILED XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_check_data[None]
FAILED XBrainLab/tests/backend/training/test_training_plan.py::test_test_model_metrics
FAILED XBrainLab/tests/backend/training/test_training_plan_test_model.py::test_to_holder[True]
FAILED XBrainLab/tests/backend/training/test_training_plan_test_model.py::test_to_holder[False]
FAILED XBrainLab/tests/backend/training/test_training_plan_test_model.py::test_eval_model
FAILED XBrainLab/tests/backend/utils/test_seed.py::test_set_seed - TypeError:...
FAILED XBrainLab/tests/backend/utils/test_seed.py::test_get_random_state - Ty...
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[True-VisualizerType.SaliencyMap-epochs0-2-True]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[True-VisualizerType.SaliencyMap-epochs0-2-False]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[True-VisualizerType.SaliencyMap-epochs1-3-True]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[True-VisualizerType.SaliencyMap-epochs1-3-False]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[True-VisualizerType.SaliencyMap-epochs2-4-True]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[True-VisualizerType.SaliencyMap-epochs2-4-False]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[True-VisualizerType.SaliencyTopoMap-epochs0-2-True]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[True-VisualizerType.SaliencyTopoMap-epochs0-2-False]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[True-VisualizerType.SaliencyTopoMap-epochs1-3-True]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[True-VisualizerType.SaliencyTopoMap-epochs1-3-False]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[True-VisualizerType.SaliencyTopoMap-epochs2-4-True]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[True-VisualizerType.SaliencyTopoMap-epochs2-4-False]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[False-VisualizerType.SaliencyMap-epochs0-2-True]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[False-VisualizerType.SaliencyMap-epochs0-2-False]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[False-VisualizerType.SaliencyMap-epochs1-3-True]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[False-VisualizerType.SaliencyMap-epochs1-3-False]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[False-VisualizerType.SaliencyMap-epochs2-4-True]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[False-VisualizerType.SaliencyMap-epochs2-4-False]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[False-VisualizerType.SaliencyTopoMap-epochs0-2-True]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[False-VisualizerType.SaliencyTopoMap-epochs0-2-False]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[False-VisualizerType.SaliencyTopoMap-epochs1-3-True]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[False-VisualizerType.SaliencyTopoMap-epochs1-3-False]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[False-VisualizerType.SaliencyTopoMap-epochs2-4-True]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_map[False-VisualizerType.SaliencyTopoMap-epochs2-4-False]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_eval_plot[VisualizerType.SaliencySpectrogramMap-True-epochs0-2]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_eval_plot[VisualizerType.SaliencySpectrogramMap-True-epochs1-3]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_eval_plot[VisualizerType.SaliencySpectrogramMap-True-epochs2-4]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_eval_plot[VisualizerType.SaliencySpectrogramMap-False-epochs0-2]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_eval_plot[VisualizerType.SaliencySpectrogramMap-False-epochs1-3]
FAILED XBrainLab/tests/backend/visualization/test_visualizer.py::test_eval_plot[VisualizerType.SaliencySpectrogramMap-False-epochs2-4]
FAILED XBrainLab/tests/integration/test_ui_integration.py::test_full_import_flow
FAILED XBrainLab/tests/integration/test_ui_integration.py::test_resample_and_epoch
FAILED XBrainLab/tests/integration/test_ui_integration.py::test_resample_epoch_no_labels
FAILED XBrainLab/tests/integration/test_ui_refresh.py::test_ui_refresh_on_tab_switch
ERROR XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_generate_mask_target
ERROR XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_get_filtered_mask_pair
ERROR XBrainLab/tests/backend/dataset/test_epochs.py::test_epochs_update_mask_target
ERROR XBrainLab/tests/backend/load_data/test_event_loader.py::test_create_event_inconsistent
ERROR XBrainLab/tests/backend/load_data/test_raw.py::test_set_event_consistency
ERROR XBrainLab/tests/backend/load_data/test_raw.py::test_raw_annotation_event
ERROR XBrainLab/tests/backend/load_data/test_raw.py::test_raw_set_event_on_annotation_event
ERROR XBrainLab/tests/backend/load_data/test_raw.py::test_mne_epoch_info - Ty...
ERROR XBrainLab/tests/backend/load_data/test_raw.py::test_epoch - TypeError: ...
ERROR XBrainLab/tests/backend/load_data/test_raw.py::test_epoch_set_event - T...
ERROR XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_edit_event_name_epoch
ERROR XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_edit_event_id_epoch
ERROR XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_epoch_wrong_type[TimeEpoch]
ERROR XBrainLab/tests/backend/preprocessor/test_preprocess.py::test_epoch_wrong_type[WindowEpoch]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_append_record
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_append_record_with_step
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_append_record_with_large_array
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_append_record_with_small_array
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_update_smaller[val-loss-best_val_loss]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_update_smaller[test-loss-best_test_loss]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_update_larger[val-accuracy-best_val_accuracy]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_update_larger[val-auc-best_val_auc]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_update_larger[test-accuracy-best_test_accuracy]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_update_larger[test-auc-best_test_auc]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_update_eval
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_update_test
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_update_train
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_update_statistic
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_step
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_loss_figure-loss-True-True-True]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_loss_figure-loss-True-True-False]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_loss_figure-loss-True-False-True]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_loss_figure-loss-True-False-False]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_loss_figure-loss-False-True-True]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_loss_figure-loss-False-True-False]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_loss_figure-loss-False-False-True]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_loss_figure-loss-False-False-False]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_acc_figure-accuracy-True-True-True]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_acc_figure-accuracy-True-True-False]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_acc_figure-accuracy-True-False-True]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_acc_figure-accuracy-True-False-False]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_acc_figure-accuracy-False-True-True]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_acc_figure-accuracy-False-True-False]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_acc_figure-accuracy-False-False-True]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_acc_figure-accuracy-False-False-False]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_auc_figure-auc-True-True-True]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_auc_figure-auc-True-True-False]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_auc_figure-auc-True-False-True]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_auc_figure-auc-True-False-False]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_auc_figure-auc-False-True-True]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_auc_figure-auc-False-True-False]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_auc_figure-auc-False-False-True]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_line_figure[get_auc_figure-auc-False-False-False]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_lr_figure
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_test_confusion_figure
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_eval_record_getter[get_acc]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_eval_record_getter[get_auc]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_eval_record_getter[get_kappa]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_train_record_eval_record_getter[get_eval_record]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_export[accuracy-val]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_export[accuracy-test]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_export[auc-val]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_export[auc-test]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_export[loss-val]
ERROR XBrainLab/tests/backend/training/record/test_train.py::test_export[loss-test]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_loader
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_loader[val-test-test]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_loader[None-test-test]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_loader[val-None-val]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_loader[None-None-None]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_model[test-TRAINING_EVALUATION.VAL_LOSS-best_val_loss_model0]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_model[test-TRAINING_EVALUATION.VAL_LOSS-best_val_loss_model1]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_model[test-TRAINING_EVALUATION.TEST_AUC-best_test_auc_model0]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_model[test-TRAINING_EVALUATION.TEST_AUC-best_test_auc_model1]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_model[test-TRAINING_EVALUATION.TEST_ACC-best_test_accuracy_model0]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_model[test-TRAINING_EVALUATION.TEST_ACC-best_test_accuracy_model1]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_model[None-TRAINING_EVALUATION.VAL_LOSS-best_val_loss_model0]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_model[None-TRAINING_EVALUATION.VAL_LOSS-best_val_loss_model1]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_model[None-TRAINING_EVALUATION.TEST_AUC-best_test_auc_model0]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_model[None-TRAINING_EVALUATION.TEST_AUC-best_test_auc_model1]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_model[None-TRAINING_EVALUATION.TEST_ACC-best_test_accuracy_model0]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_model[None-TRAINING_EVALUATION.TEST_ACC-best_test_accuracy_model1]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.VAL_LOSS-val-test-test]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.VAL_LOSS-None-test-test]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.VAL_LOSS-val-None-val]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.VAL_LOSS-None-None-None]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.TEST_AUC-val-test-test]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.TEST_AUC-None-test-test]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.TEST_AUC-val-None-val]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.TEST_AUC-None-None-None]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.TEST_ACC-val-test-test]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.TEST_ACC-None-test-test]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.TEST_ACC-val-None-val]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.TEST_ACC-None-None-None]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.LAST_EPOCH-val-test-test]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.LAST_EPOCH-None-test-test]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.LAST_EPOCH-val-None-val]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[TRAINING_EVALUATION.LAST_EPOCH-None-None-None]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[None-val-test-test]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[None-None-test-test]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[None-val-None-val]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_pair_not_implemented[None-None-None-None]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_get_eval_model_by_lastest_model
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_set_interrupt
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_trivial_getter
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_one_epoch[True]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_one_epoch[False]
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_train_one_repeat
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_train_one_repeat_status
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_train_one_repeat_empty_training_data
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_train_one_repeat_eval
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_train_one_repeat_already_finished
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_train
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_train_status
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_train_error
ERROR XBrainLab/tests/backend/training/test_training_plan.py::test_training_plan_holder_init_error
ERROR XBrainLab/tests/backend/training/test_training_plan_test_model.py::test_test_model
==== 371 failed, 1531 passed, 1 xfailed, 72 warnings, 117 errors in 25.12s =====
