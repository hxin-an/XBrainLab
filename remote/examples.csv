input,output
perform standard preprocess,{"command": "Filtering", "parameters": {"l_freq": 0.5, "h_freq": 40.0}}, {"command": "Resample", "parameters": {"frequency": 125}}, {"command": "Normalize", "parameters": {"method": "z_score"}}
Filtering it and normalize, and export the data,{"command": "Filtering", "parameters": {"l_freq": 0.5, "h_freq": 62.5}}, {"command": "Normalize", "parameters": {"method": "z_score"}}, {"command": "Export", "parameters": {"path": "./processed_data"}}
perform standard preprocess and epoch with event 800,801,802,803,{"command": "Filtering", "parameters": {"l_freq": 0.5, "h_freq": 40.0}}, {"command": "Resample", "parameters": {"frequency": 125}}, {"command": "Normalize", "parameters": {"method": "z_score"}}, {"command": "Time Epoch", "parameters": {"event": [800,801,802,803], "start_time": -0.5, "end_time": 3}}
epoch data,{"issue": "Unable to epoch the data without event numbers, please provide more information for me."}
perform preprocess for me,{"command": "Filtering", "parameters": {"l_freq": 0.5, "h_freq": 40.0}}, {"command": "Resample", "parameters": {"frequency": 125}}, {"command": "Normalize", "parameters": {"method": "z_score"}}
epoch with event 800,801,802,{"command": "Time Epoch", "parameters": {"event": [800,801,802], "start_time": -0.5, "end_time": 3}}
epoch with event 100,200,300, and start at -0.5 end at 5,{"command": "Time Epoch", "parameters": {"event": [100,200,300], "start_time": -0.5, "end_time": 5}}
perform standard preprocess and epoch the data,{"command": "Filtering", "parameters": {"l_freq": 0.5, "h_freq": 40.0}}, {"command": "Resample", "parameters": {"frequency": 125}}, {"command": "Normalize", "parameters": {"method": "z_score"}}, {"issue": "Unable to epoch the data without event numbers, please provide more information for me."}
Filtering the data,{"command": "Filtering", "parameters": {"l_freq": 0.5, "h_freq": 40.0}}
normalize the data,{"command": "Normalize", "parameters": {"method": "z_score"}}
do,{"issue": "How can I help you, can you be more specific?"}
I want to split the data using trial,{"command": "Data splitting", "parameters": {"training_type": "full data", "testing_type": "By Trial", "validation_type": "By Trial", "cross_validation": "False"}}
standard data splitting,{"command": "Data splitting", "parameters": {"training_type": "full data", "testing_type": "By Session", "validation_type": "By Session", "cross_validation": "False"}}
Do model training,{"command": "Model Selection", "parameters": {"model": "SCCNet"}}, {"command": "Training Setting", "parameters": {"epoch" : 100, "batch size": 32, "learning rate": 0.001, "optimizer": "ADSG", "output directory": "./output_model", "checkpoint epoch": 10, "evaluation": "Best validation loss", "repeat" : 1}}, {"command": "Generate Training Plan"}
train the data,{"command": "Model Selection", "parameters": {"model": "SCCNet"}}, {"command": "Training Setting", "parameters": {"epoch" : 100, "batch size": 32, "learning rate": 0.001, "optimizer": "ADSG", "output directory": "./output_model", "checkpoint epoch": 10, "evaluation": "Best validation loss", "repeat" : 1}}, {"command": "Generate Training Plan"}
set the training stuff and start it,{"command": "Model Selection", "parameters": {"model": "SCCNet"}}, {"command": "Training Setting", "parameters": {"epoch" : 100, "batch size": 32, "learning rate": 0.001, "optimizer": "ADSG", "output directory": "./output_model", "checkpoint epoch": 10, "evaluation": "Best validation loss", "repeat" : 1}}, {"command": "Generate Training Plan"}
Can I check the training loss,{"command": "Training Manager", "parameters": {"plot": "show loss"}}
Can I check the training status,{"command": "Training Manager", "parameters": {"plot": "show accuracy"}}
I want to see training acc,{"command": "Training Manager", "parameters": {"plot": "show accuracy"}}
I want to see the AUC,{"command": "Performance Table", "parameters": {"type": "Area under ROC-curve"}}
I want to see model performance,{"command": "Performance Table", "parameters": {"type": "Accuracy (%)"}}
can I see the performance,{"command": "Performance Table", "parameters": {"type": "Accuracy (%)"}}
confusion matrix please,{"command": "Confusion Matrix"}
I want to see the confusion table,{"command": "Confusion Matrix"}
confusion matrix,{"command": "Confusion Matrix"}
Can you export the model,{"command": "Export Model"}
I want to see saliency map,{"command": "Saliency Map"}
I want to see topo map,{"command": "Saliency Topographic Map"}
3D saliency plot,{"command": "3D Saliency Plot"}
3D saliency plot of event LH,{"command": "3D Saliency Plot", "parameters": {"event": "LH"}}
Can I see model summary,{"command": "Model Summary"}
wanna check the model used,{"command": "Model Summary"}
i want to check the model used in training,{"command": "Model Summary"}
Clean the plots,{"command": "Clean Plots"}
perform filtering and resample,{"command": "Filtering", "parameters": {"l_freq": 0.5, "h_freq": 40.0}}, {"command": "Resample", "parameters": {"frequency": 125}}
resample the data to 200 Hz,{"command": "Resample", "parameters": {"frequency": 200}}
filter the data with high frequency 50 Hz,{"command": "Filtering", "parameters": {"h_freq": 50.0}}
normalize with min-max method,{"command": "Normalize", "parameters": {"method": "min_max"}}
preprocess the data and normalize using z-score,{"command": "Filtering", "parameters": {"l_freq": 0.5, "h_freq": 40.0}}, {"command": "Normalize", "parameters": {"method": "z_score"}}
perform time epoch with event 100,200 and start at -1, end at 2,{"command": "Time Epoch", "parameters": {"event": [100,200], "start_time": -1.0, "end_time": 2.0}}
filter the data with low frequency of 1 Hz,{"command": "Filtering", "parameters": {"l_freq": 1.0}}
epoch with event 600, start time -0.2, end time 1.5,{"command": "Time Epoch", "parameters": {"event": [600], "start_time": -0.2, "end_time": 1.5}}
do time epoch with events 50,51,52,{"command": "Time Epoch", "parameters": {"event": [50,51,52], "start_time": -0.5, "end_time": 3.0}}
split data by subject for training,{"command": "Data splitting", "parameters": {"training_type": "full data", "testing_type": "By Subject", "validation_type": "By Subject", "cross_validation": "False"}}
select SCCNet model for training,{"command": "Model Selection", "parameters": {"model": "SCCNet"}}
train the data with 50 epochs,{"command": "Training Setting", "parameters": {"epoch": 50, "batch size": 32, "learning rate": 0.001, "optimizer": "adam", "output directory": "./output_model", "checkpoint epoch": 5, "evaluation": "Best validation loss", "repeat": 1}}
perform confusion matrix,{"command": "Confusion Matrix"}
show me performance table with AUC,{"command": "Performance Table", "parameters": {"type": "Area under ROC-curve"}}
show me the training loss,{"command": "Training Manager", "parameters": {"plot": "show loss"}}
show me the model summary,{"command": "Model Summary"}
export the trained model,{"command": "Export Model", "parameters": {"path": "./exported_model"}}
clean all the plots,{"command": "Clean Plots"}
I want a saliency map,{"command": "Saliency Map"}
give me a 3D saliency plot for event RH,{"command": "3D Saliency Plot", "parameters": {"event": "RH"}}
filter and epoch with event 700,{"command": "Filtering", "parameters": {"l_freq": 0.5, "h_freq": 40.0}}, {"command": "Time Epoch", "parameters": {"event": [700], "start_time": -0.5, "end_time": 3.0}}
normalize using z-score, and split data by session,{"command": "Normalize", "parameters": {"method": "z_score"}}, {"command": "Data splitting", "parameters": {"training_type": "full data", "testing_type": "By Session", "validation_type": "By Session", "cross_validation": "False"}}
train the model using EEGNet,{"command": "Model Selection", "parameters": {"model": "EEGNet"}}
epoch with events 800, 802, 805,{"command": "Time Epoch", "parameters": {"event": [800,802,805], "start_time": -0.5, "end_time": 2.5}}
split data by trial and perform cross-validation,{"command": "Data splitting", "parameters": {"training_type": "full data", "testing_type": "By Trial", "validation_type": "By Trial", "cross_validation": "True"}}
train model using EEGNet with 200 epochs,{"command": "Model Selection", "parameters": {"model": "EEGNet"}}, {"command": "Training Setting", "parameters": {"epoch": 200, "batch size": 64, "learning rate": 0.001, "optimizer": "adam", "output directory": "./model_output", "checkpoint epoch": 20, "evaluation": "Best validation loss", "repeat": 1}}, {"command": "Generate Training Plan"}
generate training plan with 100 epochs,{"command": "Training Setting", "parameters": {"epoch": 100, "batch size": 64, "learning rate": 0.001, "optimizer": "adam", "output directory": "./model_output", "checkpoint epoch": 20, "evaluation": "Best validation loss", "repeat": 1}}, {"command": "Generate Training Plan"}
evaluate model with accuracy,{"command": "Performance Table", "parameters": {"type": "Accuracy (%)"}}
export model to ./model_directory,{"command": "Export Model", "parameters": {"path": "./model_directory"}}
show the confusion matrix for my model,{"command": "Confusion Matrix"}
train model with 150 epochs, batch size 16, and adam optimizer,{"command": "Training Setting", "parameters": {"epoch": 150, "batch size": 16, "learning rate": 0.001, "optimizer": "adam", "output directory": "./trained_model", "checkpoint epoch": 10, "evaluation": "Best validation loss", "repeat": 1}}, {"command": "Generate Training Plan"}
split data by session for validation,{"command": "Data splitting", "parameters": {"training_type": "full data", "testing_type": "By Session", "validation_type": "By Session", "cross_validation": "False"}}
export performance table with kappa value,{"command": "Performance Table", "parameters": {"type": "kappa value"}}
plot saliency map for visualization,{"command": "Saliency Map"}
show topographic map,{"command": "Saliency Topographic Map"}
generate 3D saliency plot,{"command": "3D Saliency Plot"}
give me the model summary after training,{"command": "Model Summary"}
visualize the saliency spectrogram,{"command": "Saliency spectrogram"}
show performance table for accuracy and export model,{"command": "Performance Table", "parameters": {"type": "Accuracy (%)"}}, {"command": "Export Model", "parameters": {"path": "./exported_model"}}
train the data using SCCNet with 50 epochs,{"command": "Model Selection", "parameters": {"model": "SCCNet"}}, {"command": "Training Setting", "parameters": {"epoch": 50, "batch size": 32, "learning rate": 0.0005, "optimizer": "adam", "output directory": "./output_model", "checkpoint epoch": 5, "evaluation": "Best validation loss", "repeat": 1}}, {"command": "Generate Training Plan"}
export model after training to ./final_model,{"command": "Export Model", "parameters": {"path": "./final_model"}}
clean up all the current plots,{"command": "Clean Plots"}
show AUC in performance table,{"command": "Performance Table", "parameters": {"type": "Area under ROC-curve"}}
export confusion matrix,{"command": "Confusion Matrix"}
plot 3D saliency plot for event RH,{"command": "3D Saliency Plot", "parameters": {"event": "RH"}}
show accuracy and AUC of training,{"command": "Training Manager", "parameters": {"plot": "show accuracy"}}, {"command": "Training Manager", "parameters": {"plot": "show auc"}}
train with 500 epochs and batch size of 64,{"command": "Training Setting", "parameters": {"epoch": 500, "batch size": 64, "learning rate": 0.0001, "optimizer": "adam", "output directory": "./final_model", "checkpoint epoch": 25, "evaluation": "Best validation loss", "repeat": 1}}, {"command": "Generate Training Plan"}
train the data,{"command": "Model Selection", "parameters": {"model": "EEGNet"}}, {"command": "Training Setting", "parameters": {"epoch": 100, "batch size": 32, "learning rate": 0.001, "optimizer": "adam", "output directory": "./trained_model", "checkpoint epoch": 10, "evaluation": "Best validation loss", "repeat": 1}}, {"command": "Generate Training Plan"}
train the model using SCCNet,{"command": "Model Selection", "parameters": {"model": "SCCNet"}}, {"command": "Training Setting", "parameters": {"epoch": 200, "batch size": 64, "learning rate": 0.0005, "optimizer": "adam", "output directory": "./output_model", "checkpoint epoch": 20, "evaluation": "Best validation loss", "repeat": 1}}, {"command": "Generate Training Plan"}
train with EEGNet for 300 epochs,{"command": "Model Selection", "parameters": {"model": "EEGNet"}}, {"command": "Training Setting", "parameters": {"epoch": 300, "batch size": 32, "learning rate": 0.001, "optimizer": "adam", "output directory": "./output_model", "checkpoint epoch": 50, "evaluation": "Best validation loss", "repeat": 1}}, {"command": "Generate Training Plan"}
give me the confusion matrix,{"command": "Confusion Matrix"}
show me the confusion matrix,{"command": "Confusion Matrix"}
I want to see the confusion matrix,{"command": "Confusion Matrix"}
show the performance table,{"command": "Performance Table", "parameters": {"type": "Accuracy (%)"}}
export the model,{"command": "Export Model", "parameters": {"path": "./exported_model"}}
show training loss,{"command": "Training Manager", "parameters": {"plot": "show loss"}}
show training accuracy,{"command": "Training Manager", "parameters": {"plot": "show accuracy"}}
display the AUC in performance table,{"command": "Performance Table", "parameters": {"type": "Area under ROC-curve"}}
visualize the saliency map,{"command": "Saliency Map"}
plot the saliency topographic map,{"command": "Saliency Topographic Map"}
plot 3D saliency map,{"command": "3D Saliency Plot"}
export the confusion matrix,{"command": "Confusion Matrix"}
give me the model summary,{"command": "Model Summary"}
clean all plots,{"command": "Clean Plots"}
show 3D saliency plot for event RH,{"command": "3D Saliency Plot", "parameters": {"event": "RH"}}
train the model with SCCNet and 150 epochs,{"command": "Model Selection", "parameters": {"model": "SCCNet"}}, {"command": "Training Setting", "parameters": {"epoch": 150, "batch size": 32, "learning rate": 0.001, "optimizer": "adam", "output directory": "./trained_model", "checkpoint epoch": 10, "evaluation": "Best validation loss", "repeat": 1}}, {"command": "Generate Training Plan"}
split data by session and perform training,{"command": "Data splitting", "parameters": {"training_type": "full data", "testing_type": "By Session", "validation_type": "By Session", "cross_validation": "False"}}, {"command": "Model Selection", "parameters": {"model": "EEGNet"}}, {"command": "Training Setting", "parameters": {"epoch": 100, "batch size": 32, "learning rate": 0.001, "optimizer": "adam", "output directory": "./trained_model", "checkpoint epoch": 10, "evaluation": "Best validation loss", "repeat": 1}}, {"command": "Generate Training Plan"}