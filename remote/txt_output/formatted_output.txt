abstract Electroencephalogram (EEG) measures the neuronal activities in the form of electric currents that are generated due to the synchronized activity by a group of specialized pyramidal cells inside the brain.
The study presents a brief comparison of various functional neuroimaging techniques, revealing the excellent neuroimaging capabilities of EEG signals such as high temporal resolution, inexpensiveness, portability, and non-invasiveness as compared to the other techniques such as positron emission tomography, magnetoencephalogram, functional magnetic resonance imaging, and transcranial magnetic stimulation.
Different types of frequency bands associated with the brain signals are also being summarized. The main purpose of this literature survey is to cover the maximum possible applications of EEG signals based on computer-aided technologies, ranging from the diagnosis of various neurological disorders such as epilepsy, major depressive disorder, alcohol use disorder, and dementia to the monitoring of other applications such as motor imagery, identity authentication, emotion recognition, sleep stage classification, eye state detection, and drowsiness monitoring. After reviewing them, the comparative analysis of the publicly available EEG datasets and other local data acquisition methods, preprocessing techniques, feature extraction methods, and the result analysis through the classification models and statistical tests has been presented. Then the research gaps and future directions in the present studies have been summarized with the aim to inspire the readers to explore more opportunities on the current topic. Finally, the survey has been completed with the brief description about the studies exploring the fusion of brain signals from multiple modalities.
 1. Introduction EEG transforms Electroencephalogram means it is the continuous recording of the electrical activity of the brain by placing the metal electrodes over the scalp. The neuronal cells spontaneously communicate with each other via generating the electrical currents and remain active all the time even if a person is sleeping or relaxing. The low cost, high flexibility, high temporal resolution, non-invasiveness, ease of use, portability and safe nature make EEG a powerful tool for the brain imaging task as compared to the other functional neuroimaging techniques such as positron emission tomography (PET), magnetoencephalogram (MEG), functional magnetic resonance imaging (fMRI), and transcranial magnetic stimulation (TMS).
Hans Berger (1873–1941), the German Physician [1] coined the term 'electroencephalogram' to define the electrical potentials occurring in the human brain. He took the first EEG readings from the patients with ‘‘palliative trepanations’’ or having some defects in the skull by making use of metal strips and galvanometer [2]. He was able to characterize the a (‘‘slower and larger’’) and b (‘‘faster and smaller’’) rhythms and concentrated on the changes occurring in the EEG patterns while associating with the mental attention and cerebral injuries. His findings opened the gateway for most of the applications that are presently based on the EEG signals as he observed that these brain signals were not irregular and inconsistent, instead electrical changes revealed some periodic patterns that help to deduce the occurrence of some activity, e.g. changing the state from sleep (slow, very low frequency, and high amplitude waves) to wakefulness (fast, high frequency, and low amplitude waves). He was also responsible for investigating the effects of anesthesia and epilepsy on the EEG recordings [1].
EEG can record only those potential changes that occur due to the synaptic transmissions. When the action potential reaches at the axon terminal, neurotransmitters are released at the synapses site [3], causing the exhibitory post synaptic graded potentials (EPSPs) or the inhibitory post synaptic graded potentials (IPSPs) [4,5] to occur atthe postsynaptic cells.
These potentials lead to the flow of ionic currents in the extracellular space of the cell membrane, thus generating the local field potentials with very small magnitudes. Research studies conclude that the detection of electric fields is possible only due to the synchronized activity by a group of few specialized pyramidal neurons that are present in the cortical regions of the brain [6,7]. The currents generated inside these cells do not cancel out the effect of each other due to their unique and stable orientation. The overall electric field becomes much stronger when the postsynaptic graded potentials for such group of neurons are summed up. This summation actually helps in the measurement of EEG signals.
Different types of rhythms such as theta, delta, alpha, beta, and gamma can be observed in the brain waves depending upon the different functional states of the brain. Any subtle changes in the frequency patterns of these waves help in the diagnosis of certain neurological disorders or to conclude the occurrence of some neuronal activity in response to some external stimuli. The slow brain waves indicate the deep sleep stage [8] in the humans or less power in alpha and theta bands [9] in all the regions (central, occipital, frontal, parietal, and temporal) are observed for the depressed patients when compared to the normal subjects.
EEG signals are non-linear and non-stationary in nature.
The small variations in the voltage fluctuations of the EEG measurements conclude the happening of some neuronal activity. So the visual inspection of these signals varies with the expertise experience. Moreover, the long EEG recordings require a lot of time for their manual review and sometimes the results may be inaccurate due to the presence of artifacts in the signals. So the processing and the analysis of these signals can be done with the help of computer-aided technologies in order to get fast and accurate results. The use of computer-aided technologies with EEG signals has gained a widespread popularity, especially in the diagnosis of various neurological and neuropsychiatric disorders such as epilepsy [10,11], major depressive disorder (MDD) [12,13], alcohol use disorder (AUD) [14,15], and dementia [16,17] such as Alzheimer, mild cognitive impairment (MCI), Parkinson, and dementia with Lewy bodies (DLB). EEG based application of Motor Imagery has opened a new gateway in the field of neuroprosthesis [18,19]. Apart from this, other research domains such as identity authentication [20,21], sleep stage classification [22], emotion recognition [23,24], eye state detection [25,26], and drowsiness monitoring [27] are getting prominent results with the use of physiological data such as EEG.
The EEG signal processing and analysis is basically performed in four steps: preprocessing the raw signals with the help of filtering or some other techniques, then extracting the most important information in the form of features from them, further applying the feature selection methods for more optimized results, and finally at the result analysis phase, the disease diagnosis or the recognition of the different functional states of the brain is made through the machine learning models or the statistical tests. So the main aim of this research study is to target the maximum number of EEG based research applications available in the literature and to perform the comparative analysis for:
(a) Different data collection methods in the form of publicly available EEG datasets and other local data acquisition studies.
(b) Various pre-processing methods such as down-sampling, artifact handling, and feature scaling.
(c) Different categories of features using various feature extraction methods.
(d) Post-processing methods such as feature selection and dimensionality reduction techniques.
(e) Result analysis methods in the form of classification algorithms and statistical tests.
The rest of the paper is organized as follows: the taxonomy of the proposed study is explained in Section 2, the brief comparison of the various functional neuroimaging techniques is provided in Section 3, different types of brain rhythms in Section 4, data collection process in Section 5, EEG signal processing and analysis in Section 6, then the other EEG based research studies with their findings are explained in Section 7, Section 8 summarizes the research gaps and the future directions in the given studies, then a brief description about the multi-modal fusion of brain signals has been given in Section 9, and finally the paper has been concluded with its future scope in Section 10. The list of acronyms and abbreviations as summarized in Table 21 are provided in Appendix A.
2. Taxonomy of the proposed study The main aim of the present study is to inspire the readers with the excellent neuroimaging capabilities of the EEG signals and how the computer-aided technologies are used to monitor the numerous applications by using a variety of signal processing and classification algorithms. The idea is to explode the market with the automated machine learning recognition systems based on brain signals. This analysis is completed in the following manner (as shown in Fig. 1): A total of 131 research papers have been surveyed to complete the current study. Except four, all the studies are from the years 1999 to 2019. 3 handbooks, 103 journal papers, 9 book chapters, 13 conference papers, 1 Ph.D. thesis, 1 web-link, and 1 tutorial file constitute the total number of studies. Apart from that, 15 web-links are included in the study for accessing the publicly available datasets for various applications. Further categorizing the studies on the basis of the explained topics – there are 12 research studies for the comparison of various functional neuroimaging techniques, 90 studies for the EEG applications based on computer-aided technologies, 16 studies for brain rhythms (out of 16, 8 are already included in the application studies), 5 studies based upon multi-modal fusion of brain signals, and the remaining 16 are based on the basic knowledge related to the EEG signals such as history, generation of electric currents inside the brain, types of artifacts, comparison of feature extraction methods, and nonlinear analysis studies for EEG signals. The main purpose of the presentliterature review is to targetthe maximum number of EEG applications and explore a variety of signal processing and classification algorithms used in those studies. Out of 90 application studies, 17 give the description about the public datasets that are available online and 73 are further categorized on the basis of applications for which the EEG signals are used – 14 are for epilepsy and seizures, 10 for depression, 9 for MI, 8 for emotion state recognition, 8 for eye state recognition, 6 for sleep stage classification, 5 for alcoholism, 5 for dementia, 3 for driver drowsiness, 2 for identity authentication, 1 for multi-class task recognition, and 4 for others (visual comfort level of images, BCI based spelling interface, autism, and one study based on reduced number of electrodes using the concept of ERP), the total actually makes 75 because two studies are based on multiple applications such as one study based on epilepsy with alcoholism and another on epilepsy with autism, so are counted twice. Also all the application studies are classified on the basis of source of datasets used - 38 are based upon using the publicly available datasets and 35 are acquiring data locally, out of total, 2 are based upon the both. So, this makes a total of 71 studies. Out of 73, the information about the datasets is not given in the two studies.
After reviewing all the studies, firstly a brief comparison of various functional neuroimaging techniques has been given, then the description about the different brain rhythms has been summarized briefly, and finally, the available EEG application studies based on computer-aided technologies are analysed from signal processing and classification perspective, with the target to extract the maximum information in the form of four stages- preprocessing techniques, categories of features, post-processing methods, and finally the result analysis using classification algorithms and statistical tests. For preprocessing stage, 44 studies are mentioned in Table 5 for artifact handling and 7 have been explained in separate section of preprocessing details for public datasets for artifact handling, 8 for downsampling (out of 8, 3 are based upon preprocessing for public datasets), and 8 in Table 6 for feature scaling. For feature extraction, 28 studies are based on statistical features (Table 8), 19 for spectral (Table 9), 21 for non-linear (Table 10), and 7 for functional-connectivity based features (Table 11). For postprocessing, 23 studies are mentioned in Table 12 using different types of feature selection techniques and 12 for dimensionality reduction in Table 13. For result analysis, 51 are based on the classification techniques (Table 16) and 14 on statistical tests (Table 17).
Apart from that, there are about 13 studies that have been chosen separately and explained in Table 18 with their important findings. These number of studies are also depicted in Fig. 3. There are 5 studies focusing on the multi-modal fusion of brain signals,that have been summarized in Table 20.
The idea is to make the readers aware that what level of research has already been done on EEG signals, from signal processing and classification perspective and how more number of opportunities can be explored on this topic.
3. Comparison of functional neuroimaging techniques Functional neuroimaging is a brain imaging method that encompasses a wide variety of technologies that are directly or indirectly used to investigate the functional information of the central nervous system. It is used to represent the metabolic and physiological processes occurring inside the brain. It includes various techniques: positron emission tomography (PET), magnetoencephalogram (MEG), functional magnetic resonance imaging (fMRI), electroencephalogram (EEG), and transcranial magnetic stimulation (TMS) [28–30]. These techniques are used to detect the various biomarkers that are helpful in the diagnosis of various neuropsychiatric and neurological disorders [31–34,29] such as Alzeihmer, Parkinson, alcoholism, schizophrenia, Huntington's disease, Tourette syndrome, stress and mood disorders, etc. This is done by identifying the dysfunctioning in the release of certain substances like serotonin, dopamine, etc. in the brain. The comparison of various functional neuroimaging techniques has been graphically represented through Fig. 2.
Comparison of functional neuroimaging techniques
(a) Measuring the neuronal activity indirectly/directly PET involves the generation of cross-sectional 2D and 3D images of the brain giving the measurement of radiations emitted by the ‘‘radiotracers’’ that are injected into the blood stream [31,32]. The use of tracers helps to map the blood flow differences in order to visually represent the pathological conditions and functions of the brain. fMRI aims at tracking the amount of blood oxygen levels in the brain [35] and gives information about the active brain regions during certain activities. It is performed by using a signal method called as BOLD (Blood Oxygenation Level Depredent signal) [33,29,36,32,30], i.e.
the variations occurring in the intensities of the signal as a result of changing oxygen levels in the blood due to the occurrence of some neuronal activity. In order to understand the complex brain functionality, the subjects are made to perform certain tasks in response to stimuli (visual, auditory and so on) while present in the scanner.
Thus, both fMRI and PET give an indirect measurement of the brain's electrical activities. MEG [36,30] is used to directly measure the brain functionality by recording the magnetic fields with the help of highly sensitive magnetometers called as SQUIDs (superconducting quantum interference devices). EEG directly records and interprets the electrical activity of the brain by using the metal electrodes placed over the scalp. The electric currents are generated by the synchronization of millions of active neurons. Then, TMS is also based upon the direct measurement of the neuronal activity by stimulating the nerves cells of the brain with the electric simulator. The functionality of the specific brain areas can be tested through the process of ‘‘virtual lesions’’ in which the disruptions to the different brain areas is made temporarily and in a reversible manner [37].
(b) Based on invasive/non-invasive In PET, it is required to inject a radioactive and positron emitting contrast elements into the subject's body, thus making it an invasive methodology while all other techniques are based upon non-invasive methodology.
(c) Based on spatial/temporal resolution fMRI has high temporal resolution than that of PET but less than that of EEG, MEG, and TMS [38,30,37]. fMRI and PET can never match the temporal resolution [36,38] of electrophysiological signals because it involves the indirect measurement of the brain activity through the hemodynamic changes. The temporal resolutions for the methods PET, fMRI, MEG, EEG, and TMS are of the order of >10 s [36,30,37], >1 s [36,30], <1 ms [36,30,37], <1 ms [36,30,37], and <1/2 s [37], respectively.
fMRI has the highest spatial resolution [30,35] (order of millimetres) than that of PET, MEG, EEG, and TMS, thus helps to do the good quality anatomy analysis of images.
MEG has high spatial resolution than EEG [30]. The spatial resolutions for the methods PET, fMRI, MEG, EEG, and TMS are of the order of 5–20 mm [37], 1–5 mm [36,37], >5 mm [37], >10 mm [37], and 5–10 mm [37], respectively.
MEG and EEG offer the highest temporal resolution than other techniques that is highly demanded in measuring the complex functional events occurring dynamically in the brain.
(d) Cost Except EEG and TMS, the other functional imaging techniques are very expensive [36,30]. Like for MEG, the strength of magnetic field inside the brain is very weak, so it is important to have magnetically shielded devices and rooms in which those are measured thus, making the MEG devices highly expensive (in millions of dollars) whereas EEG and TMS are comparatively inexpensive (in thousands).
(e) Portability EEG and TMS are portable techniques while PET, fMRI, and MEG have to be performed in some confined place [30].
Unlike PET and fMRI, EEG directly measures the electrical activity of the brain and does not require the subject to be exposed to any magnetic fields or injected with any radiotracers, thus making the EEG tests to be very safe. The excellent temporal resolution and the reasonable spatial resolutionmake EEG a perfect candidate for recording the complex neuronal activities occurring dynamically on a temporal scale of milliseconds [39]. Although MEG has comparable temporal resolution as that of EEG but it has its own limitations. MEG is insensitive to some of the sources that are radially oriented while EEG has higher sensitivity than MEG so itis equally able to detect all the source orientations very well. EEG has the capability to deeply analyse the sources while MEG detects the sources superficially. EEG is less expensive and portable in nature as compared to the other techniques except TMS. But TMS is having its own drawbacks such as, it is not suitable for studying the functions in the temporal lobe because the temporalis muscle is contracted painfully with the TMS stimulation [37] and secondly, headaches or seizures may occur if the safety measures are not followed while undergoing TMS [30]. Thus, the low cost, high flexibility, high temporal resolution, non-invasiveness, ease of use, portability, and high density recording capability make EEG a powerful tool for the brain imaging task, especially for studying the dynamically occurring complex processes of the brain.
4. Brain rhythms Due to the extremely complex patterns generated by the firing of billions of neurons, the signals consist of a mixture of various base frequencies. The researchers have classified those varied frequency ranges into some sub-groups, known as the frequency bands. Each of these frequency bands represents a different cognitive or attentional state of a brain.
The history of these waves [5,8] can be briefly traced as – in 1929, Berger introduced the term ‘‘alpha’’ and ‘‘beta’’ [1]. In 1934, Adrian and Matthews gave a significant contribution that the alpha rhythms of 10–12 Hz are dominant in the human brain when a person is in the resting state with his eyes closed and are mainly identified from the occipital region of the cerebral cortex [41]. In 1938, the term ‘‘gamma’’ was introduced by Jasper and Andrews with the frequencies of greater than 30–35 Hz. In 1936, Walter introduced the term ‘‘delta’’ for all those frequencies which lie below the alpha band. He also defined the frequency range of 4–7.5 Hz for ‘‘theta’’ waves. The idea of theta was clearly introduced in 1944 by Walter and Dovey [42]. The fuzzy upper and lower frequency limits are available for these frequency bands in the literature. So, various brain rhythms with their frequency ranges [8], regions of occurrence and characteristics [5,8,43,44] have been generalized in Table 1.
The other research studies have used some other variants of the above brain rhythms depending upon the requirement of certain frequency bands for the analysis of particular application. These are summarized in Table 2.
5. Data collection studies The different research applications based on EEG signals have either used the publicly available datasets or have themselves created their own datasets but have not released them publicly. So, the data collection process can be divided as: publicly available datasets and other locally collected data acquisition methods. These are shown in Fig. 3.
5.1. Publicly available EEG datasets Table 3 gives the description about the publicly available datasets including – the name with which that dataset is available online, their web links, number of classes in which the EEG signals have been distinguished, number of subjects involved in the experiments, devices used for collecting the EEG signals, and the sampling rate with which the data has been stored. The last column gives the references of different research studies that have used these datasets for different purposes such as alcoholism, eye state detection, epilepsy and seizure detection, motor imagery, emotion recognition, sleep stage classification, identity authentication, multi-task recognition, and drowsiness detection.
5.2. Local data acquisition studies Table 4 gives the description about the various data acquisition studies that have themselves created their own datasets and have not released them publicly. The description includespurpose of EEG data collection, details of subjects involved in the experiments, devices used, number of EEG channels used for data acquisition, sampling rate/recording time/electrode impedance (EI), state in which the data has been collected (can be relaxed or task based), references ofthe research studies that have carried that process. The reviewed studies for these locally collected datasets include the applications such as dementia, depression, motor imagery, emotion recognition, identity authentication, alcoholism, eyes state detection, driver drowsiness/fatigue detection, and multi-class task recognition.
6. EEG signal processing and analysis The dynamically changing functional states of the brain are easily captured in the small variations of the EEG readings.
Also, the EEG of the normal person differs from the abnormal one. So it is very important to identify those changes by applying a series of signal processing and analysis mechanisms with the help of computer-aided technologies. This is carried out in four stages – pre-processing, feature extraction, post-processing and result analysis. These are shown in Fig. 3.
The raw signals can be directly fed to the result analysis phase for classification or statistical analysis, i.e. any of the first three stages can be skipped in the processing mechanism depending upon the requirement of the application. Like in some of the research studies where the deep neural architectures are used for the data analysis, any feature extraction or feature selection is not required to be performed manually. Also in other cases, if the data is already pre-processed or the features are already extracted, especially for the publicly available datasets, then any of those steps can also be skipped. Again if the extracted feature set is small, then there is no need for post-processing that involves the feature selection or dimensionality reduction methods. Finally, at the result analysis phase,the classification or the statistical analysis is made with the aim of diagnosing some abnormality or recognizing the different functional states of the brain to monitor some application. The values inside the parenthesis in Fig. 3 gives the information about the number of application studies that have worked upon the corresponding techniques.
6.1. Pre-processing The pre-processing methods applied in the research studies can be broadly divided into three categories- downsampling, artifact handling and feature scaling, as explained below: (a) Downsampling The data collected by the different EEG devices is downsampled to certain ranges depending upon the requirement of an application. Downsampling to 16 Hz [105], 64 Hz [21], from 512 to 64 Hz [18], 256 to 16 Hz [104], and 2400 to 600 Hz [20] is done in the research studies depending upon the requirement of an application.
(b) Artifact handling Artifacts are not generated from the cortical activity but due to the errors originated from the experimental settings, environment noise or biological artifacts. The artifact signals can be broadly categorized into two classes depending upon their origin [40,115] [116]: (i) Technical or extrinsic artifacts: These arise due to the technical issues or some external factors in the data collecting environment such as due to the misplacement of electrodes, powerline interference (50–60 Hz) or the electromagnetic interference in the cables or other devices, etc., and (ii) Physiological or intrinsic artifacts: Different types of physiological signals generated inside the human body act as the artifacts during the EEG data collection process.
These include eye movements or blinks (or electrooculogram (EOG) artifacts), muscle activities (or electromyogram (EMG) artifacts), cardiac activities (or electrocardiogram (ECG) artifacts), etc. All these kinds of artifacts are generally handled by applying a variety of artifact removal/reduction methods. These have been tabulated in Table 5 – the type of artifact removaltechnique has been mentioned in the first column, while the rest of the columns denote the type of application in which the corresponding method has been applied for filtering. The symbol () denotes that the particular artifact removal method has not been used in any of the studied research papers.
(c) Feature scaling It is very important to scale the features ofthe datasetin order to exhibit the symmetrical behaviour. Normalization is one of the most commonly used feature scaling methods in the studied papers. The scaling is performed either on the raw/filtered values or on the extracted features. Table 6 gives the description about the feature scaling methods.
Pre-processing on publicly available datasets The pre-processing was also performed on some of the publicly available datasets during their data collection process before they were publicly released. These involve: i. In UCI dataset for alcohol, the trials with amplitudes greater than 73.3 mV, indicating extreme eye and body movements were discarded.
ii. In Bonn University dataset for epileptic seizure, only those segments of the collected data were chosen through the visual inspection that were free from the eye movement and muscle artifacts. Bandpass filters with frequency range 0.53-40Hz were also applied.
iii. In Bern Bercelona database for epilepsy, the signals with a sampling rate of 1024 Hz were downsampled to 512 Hz and then were filtered with Butterworth bandpass filters of 4th order with the frequency range of 0.5–150 Hz.
iv. For DEAP dataset for emotion recognition, a preprocessed form of the original data is also made available online by the authors in which the downsampling of data to 128Hz had been performed followed by the removal of EOG artifacts by blink source separation technique. Then the band pass filtering with frequency range of 4–45 Hz had been applied, followed by some segmentation and reordering steps. The pre-processed dataset can be acquired from the same web-link as mentioned in Table 3 for the original dataset.
v. For BCI Competition II Dataset-III, the readings for the electrode channels were filtered with the bandpass filter of frequency range 0.5–30 Hz.
vi. For BCI Competition III dataset-IVa, the sampling rate was 1000 Hz which was downsampled to 100 Hz. The signals were filtered with the band pass filter of frequency range 0.05–200 Hz.
vii. For autism dataset given by King Abdulaziz University, Saudi Arabia, band pass filters with frequency range 0.1– 60 Hz and notch filter at 60 Hz stop band frequency are used for preprocessing the data.
6.2. Feature extraction A number of feature extraction methods are used to perform time domain, frequency domain, and time-frequency domain analysis of the signals. Some of them are empirical mode decomposition (EMD), fast Fourier transform (FFT), wavelet transform (WT), wavelet packet decomposition (WPD), and so on. The feature extraction methods have been studied in three categories- spectral estimation methods, family of transforms, and time decomposition methods (see Fig. 4). A comparative analysis of different feature extraction methods has been briefly summarized in Table 7. Different types of band pass filters are also used to decompose the signals into various frequency sub-bands, from which then the features are extracted for more detailed analysis.
Four categories of features can be reviewed from the studied applications that are named as – statistical/wavelet, spectral, non-linear, and functional connectivity based features. These have been precisely summarized in Fig. 4. These features can be directly extracted from the raw or preprocessed signals. But for more deeper analysis, a number of feature extraction methods (as summarized in Table 7) are applied to obtain various detailed sub-bands that are used to extract the different types of features from them. A complete survey for different category of features using different feature extraction methods for various applications has been explained as: (a) Statistical/wavelet features Table 8 gives the description about the statistical/ wavelet features – the name of features, reference of the studies which have worked upon those features, name of the feature extraction methods (if applied), sub-bands from which the corresponding features have been extracted after applying the corresponding feature extraction method (if applied), and the purpose or the application of the EEG study. In some of the applications, no feature extraction method has been used, instead the raw or the preprocessed signals have been directly used for the result analysis, therefore, no sub-band divisions are performed for them.
(b) Spectral features The spectral analysis of the features can be done by using either parametric (Yuler-walker or Burg's Method) or non-parametric approach (Welch method with FFT) [118,55]. These features have been explained in Table 9 giving the information about the- name of the spectral parameters, any decomposition method if applied, name of the sub-bands from which the respective spectral features can be extracted, and the purpose of the study.
(c) Non-linear features Different categories of non-linear features [125,126] are available that are important to understand the nonlinear features and complex nature of the EEG signals.
Table 10 gives an explanation about those features ascategory of the non-linear features, name of the features extracted from the particular category, reference of the studies which have worked upon those features, name of the feature extraction methods (if applied), sub-bands from which the features have been extracted after applying the corresponding feature extraction method (if applied), and the purpose or the application of the EEG study. In some of the applications, no feature extraction method has been used, instead the raw or the preprocessed signals have been directly used for the result analysis, therefore, no sub-band divisions are performed for them.
(d) Functional connectivity based features By applying the network theory on the collected EEG data, the functional networks of the brain are constructed and the connectivity inside them is measured with the help of various features. The functional connectivity based metrics that are derived from the EEG data are described in Table 11, along with the application study and their references in which they are computed.
6.3. Postprocessing Post-processing can be done either through the feature selection methods or the dimensionality reduction methods.
(a) Feature selection A number of feature selection methods are available in the studied applications that aim to improve the quality of the result analysis phase. Table 12 shows the feature selection methods along with the application and reference of the study in which they have been used.
(b) Dimensionality Reduction EEG application studies using the different dimensionality reduction methods have been provided in Table 13.
6.4. Result analysis A variety of machine learning algorithms are used for the diagnosis of neurological disorders (such as epilepsy/seizure, MDD, AUD, etc.) or monitoring of other applications (such as emotion recognition, sleep stage classification, etc.) with the help of EEG signals. The machine learning classifiers such as supervised, unsupervised, deep learning neural architectures, and ensemble learning models are used for the classification purposes in various EEG research studies. Some important findings have also been concluded in the following subheading that have applied the statistical tests on the extracted features or other parameters for result analysis. The result analysis phase can be explained through classification models and statistical analysis as below: (a) Classification models The survey for classification algorithms for various EEG applications has been done into two parts: (a) Table 14 gives an idea to the readers about the extent the particular classification algorithm has been explored for various applications. Ist column gives the name of the classification algorithm, second column signifies the applications which have worked upon these algorithms, and the third gives the reference of the application study. The color coding for the Table 14 has been explained in Table 15 where each color signifies the type of an EEG application.
(b) Table 16 summarizes the details of the best performing algorithms in the corresponding application models that give automated decisions about their disorder, thus reducing the time of the patients as well as the doctors in hospitals. Even the prediction models can be developed using EEG signals that keep on monitoring the mental state of the person and depending upon the change in behaviour, a warning system can be generated that help the patients to reduce the risk of the disease. Suppose in one case, if the seizure attacks of a person can be predicted in advance, a lot of accidents or injuries can be prevented and in another case, the progression of the disease can also be measured like MCI can lead to the Alzeihmer if not taken seriously or normal stress can lead to MDD if not diagnosed in advance. In other applications too, the different functional states of the brain can be analysed by the automated systems based on EEG signals and help to design the applications such as authenticating the identity of the person, designing the warning systems to alert the drivers about their drowsy state and so on.
The BCI systems based on EEG signals can help the disabled people a lot to perform their daily tasks such as controlling their wheel chairs, closing or opening the doors of the lifts with their motor imaginary based brain signals, controlling the television screen in their houses or work environments to perform different tasks and so on. The various research gaps and the future directions have also been suggested by the authors in their studies based on different applications of EEG signals. These have been summarized in Table 19. The most common ones are: (a) The unavailability of larger datasets for most of the applications that restricts the validation of the models for practical use and restricts their feasibility for clinical use.
(b) The need of the hour is to develop the mobile, portable and cheap models that are computationally less intensive and requires less storage space.
(c) The model should be simple and consists of least number of EEG channels.
(d) The real time data is full of artifacts, so very efficient filtering techniques need to be proposed that help to reduce the noise and increase the performance of the models.
(e) A variety of feature extraction techniques and machine learning classifiers can be explored for different datasets. Deep learning and ensemble architectures can help to improve the accuracy of the models.
(f) Non-linear and functional connectivity features can be studied for various applications to understand the complexity of the EEG signals.
9. Multi-modal fusion of brain signals Integrating the brain signals from different neuroimaging modalities can give better understanding and analysis of neuronal activities. This fusion gives a more clear picture of the neuronal structure and functions and can help in finding the more accurate biomarkers for diagnosing various neurological and neuropsychiatric disorders. For an instance, EEG and fMRI as the single modalities may not give high spatial and temporal resolutions respectively. But their fusion can achieve both. Now-a-days, the fusion of data from multiple modalities is considered as a new research challenge because different modalities may represent the data in the form of uncommon patterns and with different orders and it is not easy to directly fuse them. In the present work, we have explored some of the research studies which have contributed in proposing the solutions for fusing the data from multiple modalities. These have been tabulated in Table 20.
10. Conclusion The functional neuroimaging capabilities such as excellent temporal resolution, non-invasiveness, inexpensiveness, and safe nature makes the study of EEG to be very crucial for understanding the dynamically changing complex processes ofthe brain. The varied frequency rhythms are associated with different functional states of the brain. Any minute changes in the frequencies of these rhythms can be well captured by the EEG signals. These signals are analysed with the help of computer-aided technologies with greater accuracies and speed.
The present study explores a number of data acquisition methods for wide variety of applications based on EEG signals.
A comparative analysis of the signal processing methods has been made that involves a number of pre-processing, feature extraction, and postprocessing techniques. Then, the result analysis stage is discussed, mainly focusing on the classification methods based upon various machine learning models.
From the studies, it can be concluded that every stage has its own crucial role in processing the raw EEG signals. Each of the stages- preprocessing, feature extraction, post-processing, and result analysis play a very significant role in processing the raw time-domain EEG signals for developing the computer-aided automated decision models. Pre-processing the raw signals at the first stage diminishes the unwanted frequency components and noise from the signals, thereby, enhancing the quality of the signals. At next stage, various feature extraction methods are adopted to represent the highdimensional EEG data in the form of most discriminating features, without this step, the performance of the decision model might get degraded. Then, if the data is still very high dimensional or suffers from a problem of overfitting, feature selection and reduction algorithms play their significant role, thereby reducing the burden on the computational resources and cost of the model. The signals are still of no use, unless they are not processed through the classification models (such as traditional algorithms or deep learning architectures) or the statistical tests for some decision making or deducing some findings through them. From the survey, it can be concluded that maximum number of studies are preprocessing the signals with the help of artifact handling methods, then for feature extraction studies, maximum studies have worked upon the statistical features and in future, there is a greater scope to work upon the functional connectivity based features, then post-processing is done with the aim to reduce the computational burden, for that, maximum studies are based upon selecting the most significant features with the help of various feature selection methods, and lastly, for the result analysis phase, maximum number of studies are focusing on the classification algorithms for developing the automated recognition systems for various applications.
It is very time consuming and tedious task to manually analyse the complex and non-stationary EEG signals and the analysis results vary a lot depending upon the expertise experience of the visualizers. So, now-a-days, a lot of research is going on analysis the EEG signals using various computeraided technologies that could automate the analysis task thereby giving fast and highly accurate results. From the survey, it can be concluded that these computer-based systems make use of various signal processing and machine learning schemes to automatically conclude the happening of some neuronal activity using EEG signals. Computer-based programming languages or softwares such as MATLAB, python, R, WEKA, and so on are used to implement these signal processing methods and machine learning techniques.
It can be concluded that EEG based computer-aided systems have shown their potential successfully in various research applications, covering the diagnosis of different neurological disorders such as epilepsy/seizure, alcohol related disorders, depression, and dementia to the monitoring of other applications including emotion recognition, identity authentication, sleep stage classification, eye state detection, motor imagery and drowsiness monitoring. Then, the future scope of the various studies has been summarized in order to inspire the readers to take the study of EEG signals based on computeraided technologies to more higher level of research. Finally, some of the research studies have been explored that focuses on the fusion of brain signals from multiple modalities.
In future, efforts will be made to explore more advanced applications on EEG signals and study a wide variety of signal processing and classification methods used in their analysis.
There are various applications that are least or not covered in the present study that are working upon EEG based computeraided methods in their analysis. Such as study of EEG signals for patients with neurological disorders like Huntington's disease, Schizophernia, Autism, Strokes, Rett syndrome, attention deficit hyperactivity disorder (ADHD), and sleep related disorders. Efforts will be made to cover the extent of research going on signal processing and classification methods used in these applications. It has been observed that maximum number of studies on EEG based diagnosis of epilepsy using computer-aided methods have worked upon a very small dataset containing the EEG signals for only 5 patients. So, in future, efforts will be made to collect the data for more number of epileptic patients from a renowned hospital to create huge and heterogeneous (data of patients with varying age, gender, and so on) dataset. Advanced signal processing methods and classification methods will be used to process these signals with the aim to get more validated results and higher classification accuracies. Next, to the best of our knowledge, it has been studied that no EEG dataset is publicly available for Major Depressive Disorder (MDD) that has led to the limited research on this field. As a part of future work, it has been planned to extend the work on EEG based depression diagnosis by creating the huge dataset of the patients and working towards their analysis using various signal processing and classification methods.